{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 - Word Embeddings Supplemental\n",
    "\n",
    "This notebook contains two additional word embedding possibilities.\n",
    "\n",
    "For this notebook we will be using the following packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "#Make sure you update it before starting this notebook\n",
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "import gensim#For word2vec, etc\n",
    "import requests #For downloading our datasets\n",
    "import nltk #For stop words and stemmers\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "import sklearn.metrics.pairwise #For cosine similarity\n",
    "import sklearn.manifold #For T-SNE\n",
    "import sklearn.decomposition #For PCA\n",
    "import copy\n",
    "\n",
    "#gensim uses a couple of deprecated features\n",
    "#we can't do anything about them so lets ignore them \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline\n",
    "\n",
    "import os #For looking through files\n",
    "import os.path #For managing file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "This notebook relies on a few data files that are not in the git repo due to their size please download and unzip [this](https://github.com/Computational-Content-Analysis-2018/Upcoming/raw/master/data/supplement.zip) (472MB) file in the data directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Score Function\n",
    "\n",
    "The score function is a simple calculation developed by [Matt Taddy](https://arxiv.org/pdf/1504.07295.pdf) to calculate the likelihood that a given text would have been generated by a word-embedding model by summing the inner product between each pair of the text's word vectors. \n",
    "\n",
    "Here, we explore this using a model trained with millions of resumes from the CareerBuilder website (we can't share the private resumes...but we can share a model built with them :-):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resume_model  = gensim.models.word2vec.Word2Vec.load('../data/supplement/resumeAll.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the vacabularies of this model by building a word-index map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = resume_model.index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just load the sample and take a look at it. The sentences in each job description are already tokenized and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hiringOrganization_organizationName</th>\n",
       "      <th>jobDescription</th>\n",
       "      <th>jobLocation_address_region</th>\n",
       "      <th>jobLocation_geo_latitude</th>\n",
       "      <th>jobLocation_geo_longitude</th>\n",
       "      <th>qualifications</th>\n",
       "      <th>responsibilities</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158844</td>\n",
       "      <td>Golfsmith International, Inc.</td>\n",
       "      <td>\"Sales Associate Tracking Code 220425-971 Job ...</td>\n",
       "      <td>California</td>\n",
       "      <td>33.91918</td>\n",
       "      <td>-118.41647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Ensure each Customer receives exceptional ser...</td>\n",
       "      <td>[[``, Sales, Associate, Tracking, Code, 220425...</td>\n",
       "      <td>[[sales, associate, tracking, code, job, descr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>257645</td>\n",
       "      <td>Intel</td>\n",
       "      <td>For PHY system engineering team within the Wir...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[For, PHY, system, engineering, team, within,...</td>\n",
       "      <td>[[for, phy, system, engineering, team, within,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107875</td>\n",
       "      <td>Florida Hospital</td>\n",
       "      <td>*RN Medical Oncology PCU Orlando - Nights* Flo...</td>\n",
       "      <td>Florida</td>\n",
       "      <td>28.53834</td>\n",
       "      <td>-81.37924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[*RN, Medical, Oncology, PCU, Orlando, -, Nig...</td>\n",
       "      <td>[[medical, oncology, pcu, orlando, florida, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202394</td>\n",
       "      <td>Hitachi Data Systems</td>\n",
       "      <td>Title: Specialist Sales Account Representative...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Title, :, Specialist, Sales, Account, Repres...</td>\n",
       "      <td>[[title, specialist, sales, account, represent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109675</td>\n",
       "      <td>Footprint Retail Services</td>\n",
       "      <td>**Footprint Retail Services** **Job Descriptio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A Merchandiser must complete all assigned merc...</td>\n",
       "      <td>[[**Footprint, Retail, Services**, **Job, Desc...</td>\n",
       "      <td>[[retail, job, title, retail, merchandiser, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>215973</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Position Purpose: Provide outstanding service ...</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>41.13060</td>\n",
       "      <td>-85.12886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provide outstanding service to ensure efficien...</td>\n",
       "      <td>[[Position, Purpose, :, Provide, outstanding, ...</td>\n",
       "      <td>[[position, purpose, provide, outstanding, ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>207524</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>The Asset Protection Specialist is primarily r...</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>40.21455</td>\n",
       "      <td>-74.61932</td>\n",
       "      <td>Must be eighteen years of age or older. Must p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[The, Asset, Protection, Specialist, is, prim...</td>\n",
       "      <td>[[the, asset, protection, specialist, is, prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64426</td>\n",
       "      <td>East West Bank</td>\n",
       "      <td># Job Description East West Bank is one of the...</td>\n",
       "      <td>California</td>\n",
       "      <td>34.06862</td>\n",
       "      <td>-118.02757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We are currently seeking a Customer Service Ce...</td>\n",
       "      <td>[[#, Job, Description, East, West, Bank, is, o...</td>\n",
       "      <td>[[job, description, east, west, bank, is, one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>245192</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Job Description IBM is seeking to hire a Senio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Job, Description, IBM, is, seeking, to, hire...</td>\n",
       "      <td>[[job, description, ibm, is, seeking, to, hire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202429</td>\n",
       "      <td>Hitachi Data Systems</td>\n",
       "      <td>Title: Field Solutions Engineer Location: New ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Job Functions;Specific duties in this role wil...</td>\n",
       "      <td>[[Title, :, Field, Solutions, Engineer, Locati...</td>\n",
       "      <td>[[title, field, solutions, engineer, location,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>269503</td>\n",
       "      <td>J&amp;J Family of Companies</td>\n",
       "      <td>Project Manager (m/w) - Government &amp; Public Af...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Project, Manager, (, m/w, ), -, Government, ...</td>\n",
       "      <td>[[project, manager, government, public, jansse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>139164</td>\n",
       "      <td>Genesis Healthcare</td>\n",
       "      <td>Certified Medicine Aide Area of Interest: Nurs...</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>39.10972</td>\n",
       "      <td>-95.08775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Receives report at the beginning of shift with...</td>\n",
       "      <td>[[Certified, Medicine, Aide, Area, of, Interes...</td>\n",
       "      <td>[[certified, medicine, aide, area, of, interes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>255915</td>\n",
       "      <td>Ingersoll Rand</td>\n",
       "      <td>**Description:** At Ingersoll Rand we're passi...</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>35.14953</td>\n",
       "      <td>-90.04898</td>\n",
       "      <td>Considerable knowledge of industry related sup...</td>\n",
       "      <td>Ingersoll Rand is a diverse and inclusive envi...</td>\n",
       "      <td>[[**Description, :, **, At, Ingersoll, Rand, w...</td>\n",
       "      <td>[[at, ingersoll, rand, we, passionate, about, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>173294</td>\n",
       "      <td>HamiltonConstructionCompany</td>\n",
       "      <td>\"Hamilton Construction,in businesssince 1939 a...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>44.04624</td>\n",
       "      <td>-123.02203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[``, Hamilton, Construction, ,, in, businesss...</td>\n",
       "      <td>[[hamilton, construction, in, businesssince, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>116855</td>\n",
       "      <td>G6 Hospitality</td>\n",
       "      <td>Business Unit: DirectEmployers Title: Manager ...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.83707</td>\n",
       "      <td>-97.08195</td>\n",
       "      <td>High School diploma or equivalent;Computer pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Business, Unit, :, DirectEmployers, Title, :...</td>\n",
       "      <td>[[business, unit, directemployers, title, mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40701</td>\n",
       "      <td>Dollar Tree</td>\n",
       "      <td>Auto req ID 41872BR Title ASSISTANT MANAGER Em...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>32.85791</td>\n",
       "      <td>-97.25474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Auto, req, ID, 41872BR, Title, ASSISTANT, MA...</td>\n",
       "      <td>[[auto, req, id, title, assistant, manager, em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>292406</td>\n",
       "      <td>Johns Hopkins Medicine</td>\n",
       "      <td>Johns Hopkins employs more than 20,000 people ...</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>39.29038</td>\n",
       "      <td>-76.61219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Johns, Hopkins, employs, more, than, 20,000,...</td>\n",
       "      <td>[[johns, hopkins, employs, more, than, people,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>358904</td>\n",
       "      <td>LHC Group</td>\n",
       "      <td>Job Description As a CNA, you will perform a v...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>34.74481</td>\n",
       "      <td>-87.66753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Your specific duties for this role will includ...</td>\n",
       "      <td>[[Job, Description, As, a, CNA, ,, you, will, ...</td>\n",
       "      <td>[[job, description, as, a, cna, you, will, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>126507</td>\n",
       "      <td>GE</td>\n",
       "      <td>2306307 **Business** GE Capital **Business Seg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Doswiadczenie w pracy na podobnym stanowisku;W...</td>\n",
       "      <td>Prowadzenie projektow zw\\. z rozwojem pracowni...</td>\n",
       "      <td>[[2306307, **Business**, GE, Capital, **Busine...</td>\n",
       "      <td>[[ge, capital, capital, international, bank, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90538</td>\n",
       "      <td>EY</td>\n",
       "      <td>Title: Greater China TAS Referrals (China Sout...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Title, :, Greater, China, TAS, Referrals, (,...</td>\n",
       "      <td>[[title, greater, china, tas, referrals, china...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59256</td>\n",
       "      <td>Dr Pepper Snapple Group</td>\n",
       "      <td>Merchandiser The Merchandiser is responsible f...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>29.76328</td>\n",
       "      <td>-95.36327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Merchandiser, The, Merchandiser, is, respons...</td>\n",
       "      <td>[[merchandiser, the, merchandiser, is, respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>85716</td>\n",
       "      <td>Eurofins Lancaster Laboratories</td>\n",
       "      <td>### Eurofins is the world leader in the food, ...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>39.55895</td>\n",
       "      <td>-84.30411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[#, #, #, Eurofins, is, the, world, leader, i...</td>\n",
       "      <td>[[eurofins, is, the, world, leader, in, the, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>203342</td>\n",
       "      <td>HMSHOST</td>\n",
       "      <td>\"**Having the right ingredients makes all the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Greets customers and takes food order provide...</td>\n",
       "      <td>[[``, **Having, the, right, ingredients, makes...</td>\n",
       "      <td>[[the, right, ingredients, makes, all, the, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>283327</td>\n",
       "      <td>Jewel-Osco</td>\n",
       "      <td>JOB: Retail Clerk  Liquor/Beer/Wine JOB OVERVI...</td>\n",
       "      <td>Montana</td>\n",
       "      <td>48.19579</td>\n",
       "      <td>-114.31291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sells, receives, stocks and may order beer/liq...</td>\n",
       "      <td>[[JOB, :, Retail, Clerk, Liquor/Beer/Wine, JOB...</td>\n",
       "      <td>[[job, retail, clerk, job, overview, provides,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>320876</td>\n",
       "      <td>KeyPoint Government Solutions</td>\n",
       "      <td>**Overview:** KeyPoint Government Solutions is...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[**Overview, :, **, KeyPoint, Government, Sol...</td>\n",
       "      <td>[[keypoint, government, solutions, is, current...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>311069</td>\n",
       "      <td>Kelly Services</td>\n",
       "      <td>**Strategic Sales Lead  Premier Brands and Con...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelors degree (MBA preferred) or equivalent...</td>\n",
       "      <td>This is a field based corporate sales position...</td>\n",
       "      <td>[[**Strategic, Sales, Lead, Premier, Brands, a...</td>\n",
       "      <td>[[sales, lead, premier, brands, and, consumer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>141835</td>\n",
       "      <td>Genesis Rehabilitation</td>\n",
       "      <td>Job Title: Occupational Therapist Area of Inte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Screens, examines and evaluates patients, incl...</td>\n",
       "      <td>[[Job, Title, :, Occupational, Therapist, Area...</td>\n",
       "      <td>[[job, title, occupational, therapist, area, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>202406</td>\n",
       "      <td>Hitachi Data Systems</td>\n",
       "      <td>Title: Pentaho-Sales Executive-Texas Location:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Title, :, Pentaho-Sales, Executive-Texas, Lo...</td>\n",
       "      <td>[[title, location, texas, the, regional, accou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>111597</td>\n",
       "      <td>Franciscan St. Eilzabeth Health</td>\n",
       "      <td>Title: Respiratory Therapy, Intern Location: X...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Title, :, Respiratory, Therapy, ,, Intern, L...</td>\n",
       "      <td>[[title, respiratory, therapy, intern, location]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>260448</td>\n",
       "      <td>Intel</td>\n",
       "      <td>The Influencer Sales Group Solution Architect ...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>45.52289</td>\n",
       "      <td>-122.98983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[The, Influencer, Sales, Group, Solution, Arc...</td>\n",
       "      <td>[[the, influencer, sales, group, solution, arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>197429</td>\n",
       "      <td>Hill-Rom</td>\n",
       "      <td>Title: Contract Svc Admin Location: United Sta...</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>42.78920</td>\n",
       "      <td>-85.51669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_ Other duties may be assigned:_</td>\n",
       "      <td>[[Title, :, Contract, Svc, Admin, Location, :,...</td>\n",
       "      <td>[[title, contract, svc, admin, location, unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>359233</td>\n",
       "      <td>LHC Group</td>\n",
       "      <td>Job Description The Occupational Therapist is ...</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>41.51337</td>\n",
       "      <td>-87.67421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Job, Description, The, Occupational, Therapi...</td>\n",
       "      <td>[[job, description, the, occupational, therapi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>5520</td>\n",
       "      <td>DCS Corporation</td>\n",
       "      <td>Systems Engineer - SE2-3678 Location: AL, Hunt...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>34.73037</td>\n",
       "      <td>-86.58610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Participate in preparation of technical and pr...</td>\n",
       "      <td>[[Systems, Engineer, -, SE2-3678, Location, :,...</td>\n",
       "      <td>[[systems, engineer, location, al, huntsville,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>205825</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>Position Purpose:Associates in Office/Store Su...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.12509</td>\n",
       "      <td>-72.74954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usually in a comfortable environment but with ...</td>\n",
       "      <td>[[Position, Purpose, :, Associates, in, Office...</td>\n",
       "      <td>[[position, purpose, associates, in, support, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>68546</td>\n",
       "      <td>Education Corporation of America</td>\n",
       "      <td># Description Education Corporation of America...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>33.52066</td>\n",
       "      <td>-86.80249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education Corporation of America owns and oper...</td>\n",
       "      <td>[[#, Description, Education, Corporation, of, ...</td>\n",
       "      <td>[[description, education, corporation, of, ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>141067</td>\n",
       "      <td>Genesis Rehabilitation</td>\n",
       "      <td>Job Title: Physical Therapist Area of Interest...</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>42.99564</td>\n",
       "      <td>-71.45479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Genesis Rehabilitation Services is looking for...</td>\n",
       "      <td>[[Job, Title, :, Physical, Therapist, Area, of...</td>\n",
       "      <td>[[job, title, physical, therapist, area, of, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>26925</td>\n",
       "      <td>Destination Hotels &amp; Resorts</td>\n",
       "      <td>Busser Property Paradise Point Resort &amp; Spa Co...</td>\n",
       "      <td>California</td>\n",
       "      <td>32.71533</td>\n",
       "      <td>-117.15726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Busser, Property, Paradise, Point, Resort, &amp;...</td>\n",
       "      <td>[[busser, property, paradise, point, resort, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>81637</td>\n",
       "      <td>Epic Health Services</td>\n",
       "      <td>Epic Health Services, Inc. is looking for Bili...</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>39.95373</td>\n",
       "      <td>-74.19792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provide skilled nursing care to pediatric and ...</td>\n",
       "      <td>[[Epic, Health, Services, ,, Inc., is, looking...</td>\n",
       "      <td>[[epic, health, services, is, looking, for, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>191317</td>\n",
       "      <td>Hewlett Packard Enterprise Company</td>\n",
       "      <td>Title: Software Engineer Location: China-Shang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Title, :, Software, Engineer, Location, :, C...</td>\n",
       "      <td>[[title, software, engineer, location, other, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>134395</td>\n",
       "      <td>Genesis Healthcare</td>\n",
       "      <td>Registered Nurse Area of Interest: Nursing - R...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.57509</td>\n",
       "      <td>-70.93005</td>\n",
       "      <td>Registered Nurse / RN Requirements:;Bachelor's...</td>\n",
       "      <td>Twin Oaks in Danvers MA is looking for a Per D...</td>\n",
       "      <td>[[Registered, Nurse, Area, of, Interest, :, Nu...</td>\n",
       "      <td>[[registered, nurse, area, of, interest, nursi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>177803</td>\n",
       "      <td>Harris Corporation</td>\n",
       "      <td>Description: Job Title: Electrical Engineer &amp;n...</td>\n",
       "      <td>Florida</td>\n",
       "      <td>28.03446</td>\n",
       "      <td>-80.58866</td>\n",
       "      <td>Master&amp;rsquo s degree in electrical engineerin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Description, :, Job, Title, :, Electrical, E...</td>\n",
       "      <td>[[description, job, title, electrical, enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>222835</td>\n",
       "      <td>Home Depot</td>\n",
       "      <td>\"Position Purpose: Cashiers play a critical cu...</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>36.72806</td>\n",
       "      <td>-108.21869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Usually in a comfortable environment but with ...</td>\n",
       "      <td>[[``, Position, Purpose, :, Cashiers, play, a,...</td>\n",
       "      <td>[[position, purpose, cashiers, play, a, critic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>12790</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Deloitte is one of the leading professional se...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>39.95234</td>\n",
       "      <td>-75.16379</td>\n",
       "      <td>Establishes deliverable structure and content ...</td>\n",
       "      <td>Job Responsibilities;In providing finance-rela...</td>\n",
       "      <td>[[Deloitte, is, one, of, the, leading, profess...</td>\n",
       "      <td>[[deloitte, is, one, of, the, leading, profess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>319987</td>\n",
       "      <td>Kettering Medical Center</td>\n",
       "      <td>Description Greets patients and visitors in a ...</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>39.68950</td>\n",
       "      <td>-84.16883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Description, Greets, patients, and, visitors...</td>\n",
       "      <td>[[description, greets, patients, and, visitors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>352211</td>\n",
       "      <td>Learning Care Group</td>\n",
       "      <td># Job Description Join our talented team, wher...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>33.42227</td>\n",
       "      <td>-111.82264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Join our talented team, where we inspire child...</td>\n",
       "      <td>[[#, Job, Description, Join, our, talented, te...</td>\n",
       "      <td>[[job, description, join, our, talented, team,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>233278</td>\n",
       "      <td>Humana</td>\n",
       "      <td>Role: Technology Architect Assignment: IT Loca...</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>38.25424</td>\n",
       "      <td>-85.75941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guide all aspects of design, implementation an...</td>\n",
       "      <td>[[Role, :, Technology, Architect, Assignment, ...</td>\n",
       "      <td>[[role, technology, architect, assignment, it,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>338881</td>\n",
       "      <td>Kronos Incorporated</td>\n",
       "      <td>* Observes and reports activities and incident...</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>36.32311</td>\n",
       "      <td>-86.71333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[*, Observes, and, reports, activities, and, ...</td>\n",
       "      <td>[[observes, and, reports, activities, and, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53773</td>\n",
       "      <td>Dominos Pizza</td>\n",
       "      <td>\"ABOUT THE JOB Do you know why Domino's Pizza ...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>29.76328</td>\n",
       "      <td>-95.36327</td>\n",
       "      <td>General job duties for all store team members;...</td>\n",
       "      <td>\"You must be 18 years of age and have a valid ...</td>\n",
       "      <td>[[``, ABOUT, THE, JOB, Do, you, know, why, Dom...</td>\n",
       "      <td>[[about, the, job, do, you, know, why, domino,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>158203</td>\n",
       "      <td>Golden Living</td>\n",
       "      <td>Registered Dietician at AseraCare Hospice work...</td>\n",
       "      <td>Texas</td>\n",
       "      <td>29.76328</td>\n",
       "      <td>-95.36327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Registered, Dietician, at, AseraCare, Hospic...</td>\n",
       "      <td>[[registered, dietician, at, aseracare, hospic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>156994</td>\n",
       "      <td>Golden Living</td>\n",
       "      <td>At Golden LivingCenters, we care for every pat...</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>44.08054</td>\n",
       "      <td>-103.23101</td>\n",
       "      <td>Currently licensed or registered in state of p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[At, Golden, LivingCenters, ,, we, care, for,...</td>\n",
       "      <td>[[at, golden, livingcenters, we, care, for, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>249542</td>\n",
       "      <td>ICF International</td>\n",
       "      <td>Energy Efficiency and Low Income Representativ...</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>42.27756</td>\n",
       "      <td>-83.74088</td>\n",
       "      <td>/ /;/ /</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Energy, Efficiency, and, Low, Income, Repres...</td>\n",
       "      <td>[[energy, efficiency, and, low, income, repres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>173219</td>\n",
       "      <td>Hallmark Health</td>\n",
       "      <td>Office Coordinator Geriatric Assessment Center...</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.41843</td>\n",
       "      <td>-71.10616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High School Diploma or equivalent. Bachelor's ...</td>\n",
       "      <td>[[Office, Coordinator, Geriatric, Assessment, ...</td>\n",
       "      <td>[[office, coordinator, geriatric, assessment, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>50969</td>\n",
       "      <td>Dominos Pizza</td>\n",
       "      <td>Customer Service Representative Are you ready ...</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>42.87111</td>\n",
       "      <td>-97.39728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Customer, Service, Representative, Are, you,...</td>\n",
       "      <td>[[customer, service, representative, are, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>331404</td>\n",
       "      <td>Kforce</td>\n",
       "      <td>Kforce has a client in Beaverton, Oregon (OR) ...</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>45.48706</td>\n",
       "      <td>-122.80371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Kforce, has, a, client, in, Beaverton, ,, Or...</td>\n",
       "      <td>[[kforce, has, a, client, in, beaverton, orego...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>322250</td>\n",
       "      <td>Kforce</td>\n",
       "      <td>Kforce has a client in Stamford, Connecticut (...</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>41.05343</td>\n",
       "      <td>-73.53873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Kforce, has, a, client, in, Stamford, ,, Con...</td>\n",
       "      <td>[[kforce, has, a, client, in, stamford, connec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>157791</td>\n",
       "      <td>Golden Living</td>\n",
       "      <td>Here at Golden LivingCenters, we rely on and t...</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>40.67667</td>\n",
       "      <td>-95.85917</td>\n",
       "      <td>High school diploma or equivalent;Must within ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Here, at, Golden, LivingCenters, ,, we, rely...</td>\n",
       "      <td>[[here, at, golden, livingcenters, we, rely, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>119835</td>\n",
       "      <td>GameStop</td>\n",
       "      <td>\"*Description* Description: SUMMARY At GameSto...</td>\n",
       "      <td>New York</td>\n",
       "      <td>40.68149</td>\n",
       "      <td>-73.39984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[``, *Description*, Description, :, SUMMARY, ...</td>\n",
       "      <td>[[description, summary, at, gamestop, we, refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>285609</td>\n",
       "      <td>Jewel-Osco</td>\n",
       "      <td>\"Updated 6/2011 JOB TITLE: Service Clerk (Bagg...</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>41.66892</td>\n",
       "      <td>-87.73866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provides prompt, efficient and friendly custom...</td>\n",
       "      <td>[[``, Updated, 6/2011, JOB, TITLE, :, Service,...</td>\n",
       "      <td>[[updated, job, title, service, clerk, bagger,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>89260</td>\n",
       "      <td>Express Scripts</td>\n",
       "      <td>\"Schedule: Full-time Job ID: 1500071I The Sale...</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>38.62727</td>\n",
       "      <td>-90.19789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o Proactive management of Houston entry &amp; comp...</td>\n",
       "      <td>[[``, Schedule, :, Full-time, Job, ID, :, 1500...</td>\n",
       "      <td>[[schedule, job, id, the, sales, coordinator, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>280096</td>\n",
       "      <td>JCPenney</td>\n",
       "      <td>Temp Support Specialist- Mall of Louisiana Loc...</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>30.45075</td>\n",
       "      <td>-91.15455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Executes the merchandise strategy You take the...</td>\n",
       "      <td>[[Temp, Support, Specialist-, Mall, of, Louisi...</td>\n",
       "      <td>[[temp, support, mall, of, louisiana, location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 hiringOrganization_organizationName  \\\n",
       "0       158844       Golfsmith International, Inc.   \n",
       "1       257645                               Intel   \n",
       "2       107875                    Florida Hospital   \n",
       "3       202394                Hitachi Data Systems   \n",
       "4       109675           Footprint Retail Services   \n",
       "5       215973                          Home Depot   \n",
       "6       207524                          Home Depot   \n",
       "7        64426                      East West Bank   \n",
       "8       245192                                 IBM   \n",
       "9       202429                Hitachi Data Systems   \n",
       "10      269503             J&J Family of Companies   \n",
       "11      139164                  Genesis Healthcare   \n",
       "12      255915                      Ingersoll Rand   \n",
       "13      173294         HamiltonConstructionCompany   \n",
       "14      116855                      G6 Hospitality   \n",
       "15       40701                         Dollar Tree   \n",
       "16      292406              Johns Hopkins Medicine   \n",
       "17      358904                           LHC Group   \n",
       "18      126507                                  GE   \n",
       "19       90538                                  EY   \n",
       "20       59256             Dr Pepper Snapple Group   \n",
       "21       85716     Eurofins Lancaster Laboratories   \n",
       "22      203342                             HMSHOST   \n",
       "23      283327                          Jewel-Osco   \n",
       "24      320876       KeyPoint Government Solutions   \n",
       "25      311069                      Kelly Services   \n",
       "26      141835              Genesis Rehabilitation   \n",
       "27      202406                Hitachi Data Systems   \n",
       "28      111597     Franciscan St. Eilzabeth Health   \n",
       "29      260448                               Intel   \n",
       "..         ...                                 ...   \n",
       "70      197429                            Hill-Rom   \n",
       "71      359233                           LHC Group   \n",
       "72        5520                     DCS Corporation   \n",
       "73      205825                          Home Depot   \n",
       "74       68546    Education Corporation of America   \n",
       "75      141067              Genesis Rehabilitation   \n",
       "76       26925        Destination Hotels & Resorts   \n",
       "77       81637                Epic Health Services   \n",
       "78      191317  Hewlett Packard Enterprise Company   \n",
       "79      134395                  Genesis Healthcare   \n",
       "80      177803                  Harris Corporation   \n",
       "81      222835                          Home Depot   \n",
       "82       12790                            Deloitte   \n",
       "83      319987            Kettering Medical Center   \n",
       "84      352211                 Learning Care Group   \n",
       "85      233278                              Humana   \n",
       "86      338881                 Kronos Incorporated   \n",
       "87       53773                       Dominos Pizza   \n",
       "88      158203                       Golden Living   \n",
       "89      156994                       Golden Living   \n",
       "90      249542                   ICF International   \n",
       "91      173219                     Hallmark Health   \n",
       "92       50969                       Dominos Pizza   \n",
       "93      331404                              Kforce   \n",
       "94      322250                              Kforce   \n",
       "95      157791                       Golden Living   \n",
       "96      119835                            GameStop   \n",
       "97      285609                          Jewel-Osco   \n",
       "98       89260                     Express Scripts   \n",
       "99      280096                            JCPenney   \n",
       "\n",
       "                                       jobDescription  \\\n",
       "0   \"Sales Associate Tracking Code 220425-971 Job ...   \n",
       "1   For PHY system engineering team within the Wir...   \n",
       "2   *RN Medical Oncology PCU Orlando - Nights* Flo...   \n",
       "3   Title: Specialist Sales Account Representative...   \n",
       "4   **Footprint Retail Services** **Job Descriptio...   \n",
       "5   Position Purpose: Provide outstanding service ...   \n",
       "6   The Asset Protection Specialist is primarily r...   \n",
       "7   # Job Description East West Bank is one of the...   \n",
       "8   Job Description IBM is seeking to hire a Senio...   \n",
       "9   Title: Field Solutions Engineer Location: New ...   \n",
       "10  Project Manager (m/w) - Government & Public Af...   \n",
       "11  Certified Medicine Aide Area of Interest: Nurs...   \n",
       "12  **Description:** At Ingersoll Rand we're passi...   \n",
       "13  \"Hamilton Construction,in businesssince 1939 a...   \n",
       "14  Business Unit: DirectEmployers Title: Manager ...   \n",
       "15  Auto req ID 41872BR Title ASSISTANT MANAGER Em...   \n",
       "16  Johns Hopkins employs more than 20,000 people ...   \n",
       "17  Job Description As a CNA, you will perform a v...   \n",
       "18  2306307 **Business** GE Capital **Business Seg...   \n",
       "19  Title: Greater China TAS Referrals (China Sout...   \n",
       "20  Merchandiser The Merchandiser is responsible f...   \n",
       "21  ### Eurofins is the world leader in the food, ...   \n",
       "22  \"**Having the right ingredients makes all the ...   \n",
       "23  JOB: Retail Clerk  Liquor/Beer/Wine JOB OVERVI...   \n",
       "24  **Overview:** KeyPoint Government Solutions is...   \n",
       "25  **Strategic Sales Lead  Premier Brands and Con...   \n",
       "26  Job Title: Occupational Therapist Area of Inte...   \n",
       "27  Title: Pentaho-Sales Executive-Texas Location:...   \n",
       "28  Title: Respiratory Therapy, Intern Location: X...   \n",
       "29  The Influencer Sales Group Solution Architect ...   \n",
       "..                                                ...   \n",
       "70  Title: Contract Svc Admin Location: United Sta...   \n",
       "71  Job Description The Occupational Therapist is ...   \n",
       "72  Systems Engineer - SE2-3678 Location: AL, Hunt...   \n",
       "73  Position Purpose:Associates in Office/Store Su...   \n",
       "74  # Description Education Corporation of America...   \n",
       "75  Job Title: Physical Therapist Area of Interest...   \n",
       "76  Busser Property Paradise Point Resort & Spa Co...   \n",
       "77  Epic Health Services, Inc. is looking for Bili...   \n",
       "78  Title: Software Engineer Location: China-Shang...   \n",
       "79  Registered Nurse Area of Interest: Nursing - R...   \n",
       "80  Description: Job Title: Electrical Engineer &n...   \n",
       "81  \"Position Purpose: Cashiers play a critical cu...   \n",
       "82  Deloitte is one of the leading professional se...   \n",
       "83  Description Greets patients and visitors in a ...   \n",
       "84  # Job Description Join our talented team, wher...   \n",
       "85  Role: Technology Architect Assignment: IT Loca...   \n",
       "86  * Observes and reports activities and incident...   \n",
       "87  \"ABOUT THE JOB Do you know why Domino's Pizza ...   \n",
       "88  Registered Dietician at AseraCare Hospice work...   \n",
       "89  At Golden LivingCenters, we care for every pat...   \n",
       "90  Energy Efficiency and Low Income Representativ...   \n",
       "91  Office Coordinator Geriatric Assessment Center...   \n",
       "92  Customer Service Representative Are you ready ...   \n",
       "93  Kforce has a client in Beaverton, Oregon (OR) ...   \n",
       "94  Kforce has a client in Stamford, Connecticut (...   \n",
       "95  Here at Golden LivingCenters, we rely on and t...   \n",
       "96  \"*Description* Description: SUMMARY At GameSto...   \n",
       "97  \"Updated 6/2011 JOB TITLE: Service Clerk (Bagg...   \n",
       "98  \"Schedule: Full-time Job ID: 1500071I The Sale...   \n",
       "99  Temp Support Specialist- Mall of Louisiana Loc...   \n",
       "\n",
       "   jobLocation_address_region  jobLocation_geo_latitude  \\\n",
       "0                  California                  33.91918   \n",
       "1                         NaN                       NaN   \n",
       "2                     Florida                  28.53834   \n",
       "3                         NaN                       NaN   \n",
       "4                         NaN                       NaN   \n",
       "5                     Indiana                  41.13060   \n",
       "6                  New Jersey                  40.21455   \n",
       "7                  California                  34.06862   \n",
       "8                         NaN                       NaN   \n",
       "9                         NaN                       NaN   \n",
       "10                        NaN                       NaN   \n",
       "11                     Kansas                  39.10972   \n",
       "12                  Tennessee                  35.14953   \n",
       "13                     Oregon                  44.04624   \n",
       "14                      Texas                  32.83707   \n",
       "15                      Texas                  32.85791   \n",
       "16                   Maryland                  39.29038   \n",
       "17                    Alabama                  34.74481   \n",
       "18                        NaN                       NaN   \n",
       "19                        NaN                       NaN   \n",
       "20                      Texas                  29.76328   \n",
       "21                       Ohio                  39.55895   \n",
       "22                        NaN                       NaN   \n",
       "23                    Montana                  48.19579   \n",
       "24                        NaN                       NaN   \n",
       "25                        NaN                       NaN   \n",
       "26                        NaN                       NaN   \n",
       "27                        NaN                       NaN   \n",
       "28                        NaN                       NaN   \n",
       "29                     Oregon                  45.52289   \n",
       "..                        ...                       ...   \n",
       "70                   Michigan                  42.78920   \n",
       "71                   Illinois                  41.51337   \n",
       "72                    Alabama                  34.73037   \n",
       "73              Massachusetts                  42.12509   \n",
       "74                    Alabama                  33.52066   \n",
       "75              New Hampshire                  42.99564   \n",
       "76                 California                  32.71533   \n",
       "77                 New Jersey                  39.95373   \n",
       "78                        NaN                       NaN   \n",
       "79              Massachusetts                  42.57509   \n",
       "80                    Florida                  28.03446   \n",
       "81                 New Mexico                  36.72806   \n",
       "82               Pennsylvania                  39.95234   \n",
       "83                       Ohio                  39.68950   \n",
       "84                    Arizona                  33.42227   \n",
       "85                   Kentucky                  38.25424   \n",
       "86                  Tennessee                  36.32311   \n",
       "87                      Texas                  29.76328   \n",
       "88                      Texas                  29.76328   \n",
       "89               South Dakota                  44.08054   \n",
       "90                   Michigan                  42.27756   \n",
       "91              Massachusetts                  42.41843   \n",
       "92               South Dakota                  42.87111   \n",
       "93                     Oregon                  45.48706   \n",
       "94                Connecticut                  41.05343   \n",
       "95                   Nebraska                  40.67667   \n",
       "96                   New York                  40.68149   \n",
       "97                   Illinois                  41.66892   \n",
       "98                   Missouri                  38.62727   \n",
       "99                  Louisiana                  30.45075   \n",
       "\n",
       "    jobLocation_geo_longitude  \\\n",
       "0                  -118.41647   \n",
       "1                         NaN   \n",
       "2                   -81.37924   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "5                   -85.12886   \n",
       "6                   -74.61932   \n",
       "7                  -118.02757   \n",
       "8                         NaN   \n",
       "9                         NaN   \n",
       "10                        NaN   \n",
       "11                  -95.08775   \n",
       "12                  -90.04898   \n",
       "13                 -123.02203   \n",
       "14                  -97.08195   \n",
       "15                  -97.25474   \n",
       "16                  -76.61219   \n",
       "17                  -87.66753   \n",
       "18                        NaN   \n",
       "19                        NaN   \n",
       "20                  -95.36327   \n",
       "21                  -84.30411   \n",
       "22                        NaN   \n",
       "23                 -114.31291   \n",
       "24                        NaN   \n",
       "25                        NaN   \n",
       "26                        NaN   \n",
       "27                        NaN   \n",
       "28                        NaN   \n",
       "29                 -122.98983   \n",
       "..                        ...   \n",
       "70                  -85.51669   \n",
       "71                  -87.67421   \n",
       "72                  -86.58610   \n",
       "73                  -72.74954   \n",
       "74                  -86.80249   \n",
       "75                  -71.45479   \n",
       "76                 -117.15726   \n",
       "77                  -74.19792   \n",
       "78                        NaN   \n",
       "79                  -70.93005   \n",
       "80                  -80.58866   \n",
       "81                 -108.21869   \n",
       "82                  -75.16379   \n",
       "83                  -84.16883   \n",
       "84                 -111.82264   \n",
       "85                  -85.75941   \n",
       "86                  -86.71333   \n",
       "87                  -95.36327   \n",
       "88                  -95.36327   \n",
       "89                 -103.23101   \n",
       "90                  -83.74088   \n",
       "91                  -71.10616   \n",
       "92                  -97.39728   \n",
       "93                 -122.80371   \n",
       "94                  -73.53873   \n",
       "95                  -95.85917   \n",
       "96                  -73.39984   \n",
       "97                  -87.73866   \n",
       "98                  -90.19789   \n",
       "99                  -91.15455   \n",
       "\n",
       "                                       qualifications  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6   Must be eighteen years of age or older. Must p...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12  Considerable knowledge of industry related sup...   \n",
       "13                                                NaN   \n",
       "14  High School diploma or equivalent;Computer pro...   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18  Doswiadczenie w pracy na podobnym stanowisku;W...   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "25  Bachelors degree (MBA preferred) or equivalent...   \n",
       "26                                                NaN   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "..                                                ...   \n",
       "70                                                NaN   \n",
       "71                                                NaN   \n",
       "72                                                NaN   \n",
       "73                                                NaN   \n",
       "74                                                NaN   \n",
       "75                                                NaN   \n",
       "76                                                NaN   \n",
       "77                                                NaN   \n",
       "78                                                NaN   \n",
       "79  Registered Nurse / RN Requirements:;Bachelor's...   \n",
       "80  Master&rsquo s degree in electrical engineerin...   \n",
       "81                                                NaN   \n",
       "82  Establishes deliverable structure and content ...   \n",
       "83                                                NaN   \n",
       "84                                                NaN   \n",
       "85                                                NaN   \n",
       "86                                                NaN   \n",
       "87  General job duties for all store team members;...   \n",
       "88                                                NaN   \n",
       "89  Currently licensed or registered in state of p...   \n",
       "90                                            / /;/ /   \n",
       "91                                                NaN   \n",
       "92                                                NaN   \n",
       "93                                                NaN   \n",
       "94                                                NaN   \n",
       "95  High school diploma or equivalent;Must within ...   \n",
       "96                                                NaN   \n",
       "97                                                NaN   \n",
       "98                                                NaN   \n",
       "99                                                NaN   \n",
       "\n",
       "                                     responsibilities  \\\n",
       "0   \"Ensure each Customer receives exceptional ser...   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4   A Merchandiser must complete all assigned merc...   \n",
       "5   Provide outstanding service to ensure efficien...   \n",
       "6                                                 NaN   \n",
       "7   We are currently seeking a Customer Service Ce...   \n",
       "8                                                 NaN   \n",
       "9   Job Functions;Specific duties in this role wil...   \n",
       "10                                                NaN   \n",
       "11  Receives report at the beginning of shift with...   \n",
       "12  Ingersoll Rand is a diverse and inclusive envi...   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17  Your specific duties for this role will includ...   \n",
       "18  Prowadzenie projektow zw\\. z rozwojem pracowni...   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22  \"Greets customers and takes food order provide...   \n",
       "23  Sells, receives, stocks and may order beer/liq...   \n",
       "24                                                NaN   \n",
       "25  This is a field based corporate sales position...   \n",
       "26  Screens, examines and evaluates patients, incl...   \n",
       "27                                                NaN   \n",
       "28                                                NaN   \n",
       "29                                                NaN   \n",
       "..                                                ...   \n",
       "70                   _ Other duties may be assigned:_   \n",
       "71                                                NaN   \n",
       "72  Participate in preparation of technical and pr...   \n",
       "73  Usually in a comfortable environment but with ...   \n",
       "74  Education Corporation of America owns and oper...   \n",
       "75  Genesis Rehabilitation Services is looking for...   \n",
       "76                                                NaN   \n",
       "77  Provide skilled nursing care to pediatric and ...   \n",
       "78                                                NaN   \n",
       "79  Twin Oaks in Danvers MA is looking for a Per D...   \n",
       "80                                                NaN   \n",
       "81  Usually in a comfortable environment but with ...   \n",
       "82  Job Responsibilities;In providing finance-rela...   \n",
       "83                                                NaN   \n",
       "84  Join our talented team, where we inspire child...   \n",
       "85  Guide all aspects of design, implementation an...   \n",
       "86                                                NaN   \n",
       "87  \"You must be 18 years of age and have a valid ...   \n",
       "88                                                NaN   \n",
       "89                                                NaN   \n",
       "90                                                NaN   \n",
       "91  High School Diploma or equivalent. Bachelor's ...   \n",
       "92                                                NaN   \n",
       "93                                                NaN   \n",
       "94                                                NaN   \n",
       "95                                                NaN   \n",
       "96                                                NaN   \n",
       "97  Provides prompt, efficient and friendly custom...   \n",
       "98  o Proactive management of Houston entry & comp...   \n",
       "99  Executes the merchandise strategy You take the...   \n",
       "\n",
       "                                      tokenized_sents  \\\n",
       "0   [[``, Sales, Associate, Tracking, Code, 220425...   \n",
       "1   [[For, PHY, system, engineering, team, within,...   \n",
       "2   [[*RN, Medical, Oncology, PCU, Orlando, -, Nig...   \n",
       "3   [[Title, :, Specialist, Sales, Account, Repres...   \n",
       "4   [[**Footprint, Retail, Services**, **Job, Desc...   \n",
       "5   [[Position, Purpose, :, Provide, outstanding, ...   \n",
       "6   [[The, Asset, Protection, Specialist, is, prim...   \n",
       "7   [[#, Job, Description, East, West, Bank, is, o...   \n",
       "8   [[Job, Description, IBM, is, seeking, to, hire...   \n",
       "9   [[Title, :, Field, Solutions, Engineer, Locati...   \n",
       "10  [[Project, Manager, (, m/w, ), -, Government, ...   \n",
       "11  [[Certified, Medicine, Aide, Area, of, Interes...   \n",
       "12  [[**Description, :, **, At, Ingersoll, Rand, w...   \n",
       "13  [[``, Hamilton, Construction, ,, in, businesss...   \n",
       "14  [[Business, Unit, :, DirectEmployers, Title, :...   \n",
       "15  [[Auto, req, ID, 41872BR, Title, ASSISTANT, MA...   \n",
       "16  [[Johns, Hopkins, employs, more, than, 20,000,...   \n",
       "17  [[Job, Description, As, a, CNA, ,, you, will, ...   \n",
       "18  [[2306307, **Business**, GE, Capital, **Busine...   \n",
       "19  [[Title, :, Greater, China, TAS, Referrals, (,...   \n",
       "20  [[Merchandiser, The, Merchandiser, is, respons...   \n",
       "21  [[#, #, #, Eurofins, is, the, world, leader, i...   \n",
       "22  [[``, **Having, the, right, ingredients, makes...   \n",
       "23  [[JOB, :, Retail, Clerk, Liquor/Beer/Wine, JOB...   \n",
       "24  [[**Overview, :, **, KeyPoint, Government, Sol...   \n",
       "25  [[**Strategic, Sales, Lead, Premier, Brands, a...   \n",
       "26  [[Job, Title, :, Occupational, Therapist, Area...   \n",
       "27  [[Title, :, Pentaho-Sales, Executive-Texas, Lo...   \n",
       "28  [[Title, :, Respiratory, Therapy, ,, Intern, L...   \n",
       "29  [[The, Influencer, Sales, Group, Solution, Arc...   \n",
       "..                                                ...   \n",
       "70  [[Title, :, Contract, Svc, Admin, Location, :,...   \n",
       "71  [[Job, Description, The, Occupational, Therapi...   \n",
       "72  [[Systems, Engineer, -, SE2-3678, Location, :,...   \n",
       "73  [[Position, Purpose, :, Associates, in, Office...   \n",
       "74  [[#, Description, Education, Corporation, of, ...   \n",
       "75  [[Job, Title, :, Physical, Therapist, Area, of...   \n",
       "76  [[Busser, Property, Paradise, Point, Resort, &...   \n",
       "77  [[Epic, Health, Services, ,, Inc., is, looking...   \n",
       "78  [[Title, :, Software, Engineer, Location, :, C...   \n",
       "79  [[Registered, Nurse, Area, of, Interest, :, Nu...   \n",
       "80  [[Description, :, Job, Title, :, Electrical, E...   \n",
       "81  [[``, Position, Purpose, :, Cashiers, play, a,...   \n",
       "82  [[Deloitte, is, one, of, the, leading, profess...   \n",
       "83  [[Description, Greets, patients, and, visitors...   \n",
       "84  [[#, Job, Description, Join, our, talented, te...   \n",
       "85  [[Role, :, Technology, Architect, Assignment, ...   \n",
       "86  [[*, Observes, and, reports, activities, and, ...   \n",
       "87  [[``, ABOUT, THE, JOB, Do, you, know, why, Dom...   \n",
       "88  [[Registered, Dietician, at, AseraCare, Hospic...   \n",
       "89  [[At, Golden, LivingCenters, ,, we, care, for,...   \n",
       "90  [[Energy, Efficiency, and, Low, Income, Repres...   \n",
       "91  [[Office, Coordinator, Geriatric, Assessment, ...   \n",
       "92  [[Customer, Service, Representative, Are, you,...   \n",
       "93  [[Kforce, has, a, client, in, Beaverton, ,, Or...   \n",
       "94  [[Kforce, has, a, client, in, Stamford, ,, Con...   \n",
       "95  [[Here, at, Golden, LivingCenters, ,, we, rely...   \n",
       "96  [[``, *Description*, Description, :, SUMMARY, ...   \n",
       "97  [[``, Updated, 6/2011, JOB, TITLE, :, Service,...   \n",
       "98  [[``, Schedule, :, Full-time, Job, ID, :, 1500...   \n",
       "99  [[Temp, Support, Specialist-, Mall, of, Louisi...   \n",
       "\n",
       "                                     normalized_sents  \n",
       "0   [[sales, associate, tracking, code, job, descr...  \n",
       "1   [[for, phy, system, engineering, team, within,...  \n",
       "2   [[medical, oncology, pcu, orlando, florida, ho...  \n",
       "3   [[title, specialist, sales, account, represent...  \n",
       "4   [[retail, job, title, retail, merchandiser, re...  \n",
       "5   [[position, purpose, provide, outstanding, ser...  \n",
       "6   [[the, asset, protection, specialist, is, prim...  \n",
       "7   [[job, description, east, west, bank, is, one,...  \n",
       "8   [[job, description, ibm, is, seeking, to, hire...  \n",
       "9   [[title, field, solutions, engineer, location,...  \n",
       "10  [[project, manager, government, public, jansse...  \n",
       "11  [[certified, medicine, aide, area, of, interes...  \n",
       "12  [[at, ingersoll, rand, we, passionate, about, ...  \n",
       "13  [[hamilton, construction, in, businesssince, a...  \n",
       "14  [[business, unit, directemployers, title, mana...  \n",
       "15  [[auto, req, id, title, assistant, manager, em...  \n",
       "16  [[johns, hopkins, employs, more, than, people,...  \n",
       "17  [[job, description, as, a, cna, you, will, per...  \n",
       "18  [[ge, capital, capital, international, bank, b...  \n",
       "19  [[title, greater, china, tas, referrals, china...  \n",
       "20  [[merchandiser, the, merchandiser, is, respons...  \n",
       "21  [[eurofins, is, the, world, leader, in, the, f...  \n",
       "22  [[the, right, ingredients, makes, all, the, di...  \n",
       "23  [[job, retail, clerk, job, overview, provides,...  \n",
       "24  [[keypoint, government, solutions, is, current...  \n",
       "25  [[sales, lead, premier, brands, and, consumer,...  \n",
       "26  [[job, title, occupational, therapist, area, o...  \n",
       "27  [[title, location, texas, the, regional, accou...  \n",
       "28  [[title, respiratory, therapy, intern, location]]  \n",
       "29  [[the, influencer, sales, group, solution, arc...  \n",
       "..                                                ...  \n",
       "70  [[title, contract, svc, admin, location, unite...  \n",
       "71  [[job, description, the, occupational, therapi...  \n",
       "72  [[systems, engineer, location, al, huntsville,...  \n",
       "73  [[position, purpose, associates, in, support, ...  \n",
       "74  [[description, education, corporation, of, ame...  \n",
       "75  [[job, title, physical, therapist, area, of, i...  \n",
       "76  [[busser, property, paradise, point, resort, s...  \n",
       "77  [[epic, health, services, is, looking, for, bi...  \n",
       "78  [[title, software, engineer, location, other, ...  \n",
       "79  [[registered, nurse, area, of, interest, nursi...  \n",
       "80  [[description, job, title, electrical, enginee...  \n",
       "81  [[position, purpose, cashiers, play, a, critic...  \n",
       "82  [[deloitte, is, one, of, the, leading, profess...  \n",
       "83  [[description, greets, patients, and, visitors...  \n",
       "84  [[job, description, join, our, talented, team,...  \n",
       "85  [[role, technology, architect, assignment, it,...  \n",
       "86  [[observes, and, reports, activities, and, inc...  \n",
       "87  [[about, the, job, do, you, know, why, domino,...  \n",
       "88  [[registered, dietician, at, aseracare, hospic...  \n",
       "89  [[at, golden, livingcenters, we, care, for, ev...  \n",
       "90  [[energy, efficiency, and, low, income, repres...  \n",
       "91  [[office, coordinator, geriatric, assessment, ...  \n",
       "92  [[customer, service, representative, are, you,...  \n",
       "93  [[kforce, has, a, client, in, beaverton, orego...  \n",
       "94  [[kforce, has, a, client, in, stamford, connec...  \n",
       "95  [[here, at, golden, livingcenters, we, rely, o...  \n",
       "96  [[description, summary, at, gamestop, we, refe...  \n",
       "97  [[updated, job, title, service, clerk, bagger,...  \n",
       "98  [[schedule, job, id, the, sales, coordinator, ...  \n",
       "99  [[temp, support, mall, of, louisiana, location...  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDF = pandas.read_csv('../data/supplement/SampleJobAds.csv', index_col = False)\n",
    "#We need to convert the last couple columns from strings to lists\n",
    "sampleDF['tokenized_sents'] = sampleDF['tokenized_sents'].apply(lambda x: eval(x))\n",
    "sampleDF['normalized_sents'] = sampleDF['normalized_sents'].apply(lambda x: eval(x))\n",
    "sampleDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to calculate the likelihood of each job description. The idea is borrowed from [Matt Taddy](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/deepir.ipynb), who shows how a document can be characterized as the inner product of the distance between its words. In other words, this analysis will show which job ads are most likely to find an appropriate pool of workers in the resume bank that generated our word embedding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adprob(ad, model):\n",
    "    sen_scores = model.score(ad, len(ad))\n",
    "    ad_score = sen_scores.mean()\n",
    "    return ad_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply this function to every job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleDF['likelihood'] = sampleDF['normalized_sents'].apply(lambda x: adprob(x, resume_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top 5 job descriptions that have the highest likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Engineering including below jobs: 1. Hardware designing of DCS 2. Software configurations, programming, testing of DCS/PLC 3. Testing and FAT 4. Installation and commissioning. 5. Material ordering, approvals of datasheets. 6. HSE compliance as per HSE directives of HON. BE / B. Tech - Instrumentation / Control / Electronics. **Job:** **Engineering* **Title:** *Systems Engineer* **Location:** *IND-MH-Pune* **Requisition ID:** *00302235*\n",
      "\n",
      "\n",
      "Like talking on the phone? Enjoy giving great customer service? Use those skills while working flexible,part time hours.\n",
      "\n",
      "\n",
      "*# Positions:* 2 *Location:* US - UT - Orem *Category:* Engineering\n",
      "\n",
      "\n",
      "Title: Respiratory Therapy, Intern Location: XX-XX-XX\n",
      "\n",
      "\n",
      "Title: Position Opening at Illinois Wesleyan University Location: US-IL-Bloomington\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ad in sampleDF.sort_values(by = 'likelihood', ascending = False)['jobDescription'][:5]:\n",
    "    print (ad + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the bottom 5 job descriptions that have the lowest likelihood to be matched by the resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Contract Svc Admin Location: United States\\-Michigan\\-Caledonia Other Locations: JOB SUMMARY: ESSENTIAL DUTIES AND RESPONSIBILITIES: _ Other duties may be assigned:_ Prepare GPO rebate data for upload into STARR system oEnsure accurate data loads oProcess data into required reports oEnsure that GPOs are paid accurately and timely Prepare Sales Tracing data for upload into STARR system oEnsure accurate data loads oProcess data into required reports Prepare Rebate data for upload into STARR system oEnsure accurate data loads oProcess data into required reports oEnsure that distributors are accurately taking rebates against open invoices Manage work flow throughout the sales contracting process Ensure compliance with contract policies and performance requirements Assist in the preparation of charts and sales reports and analytics for customers and Management oQuarterly Reports oSales Tracing Answers customers and internal sale/customer service staff questions regarding pricing Manage all Pricing requests for GPO assignments and requests Other projects and tasks as assigned EDUCATION, EXPERIENCE AND QUALIFICATIONS: 4 year college degree in Business preferred Experience in pricing administration Experience in corporate administration Excellent Verbal and Written Communication Skills Excellent Computer Skills oHands on knowledge of Sales tracings highly recommended oMicrosoft Excel, Word, and Outlook a must Proven track record of successful project management Excellent Interpersonal Skills Excellent Customer Service orientation and skills \\#CB JOB SUMMARY: ESSENTIAL DUTIES AND RESPONSIBILITIES: _ Other duties may be assigned:_ Prepare GPO rebate data for upload into STARR system oEnsure accurate data loads oProcess data into required reports oEnsure that GPOs are paid accurately and timely Prepare Sales Tracing data for upload into STARR system oEnsure accurate data loads oProcess data into required reports Prepare Rebate data for upload into STARR system oEnsure accurate data loads oProcess data into required reports oEnsure that distributors are accurately taking rebates against open invoices Manage work flow throughout the sales contracting process Ensure compliance with contract policies and performance requirements Assist in the preparation of charts and sales reports and analytics for customers and Management oQuarterly Reports oSales Tracing Answers customers and internal sale/customer service staff questions regarding pricing Manage all Pricing requests for GPO assignments and requests Other projects and tasks as assigned EDUCATION, EXPERIENCE AND QUALIFICATIONS: 4 year college degree in Business preferred Experience in pricing administration Experience in corporate administration Excellent Verbal and Written Communication Skills Excellent Computer Skills oHands on knowledge of Sales tracings highly recommended oMicrosoft Excel, Word, and Outlook a must Proven track record of successful project management Excellent Interpersonal Skills Excellent Customer Service orientation and skills\n",
      "\n",
      "\n",
      "Kforce has a client in Beaverton, Oregon (OR) that is seeking an IT Project Manager.Responsibilities: * Manages projects with a duration of typically 12 months or less, budget 1 mnl, multiple business functions, with a regional scope * Works with project sponsors and customers to define; business benefits, business requirements, and project scope * Manages change control against scope and its impacts to time, cost, and quality * Defines project schedule, manages task assignments, tracks work against schedule * Facilitates level of effort estimating and develops asset acquisition requirements * Tracks and reports on actuals against forecast * Provides guidance and direction on project methodology and best practices to standard project methodology * Defines and manages project success / delivery criteria and monitors and reports on the realization of project success against criteria set * Defines risk management plan, analyzes risk for criticality, probability, and impact * Develops risk mitigation strategies, assigns owner and actions * Lead meetings and project agenda * Bachelor's degree and minimum of 5 years directly relevant work experience; one of the following alternatives may be accepted: PhD or Law + 3 years; Masters + 4 years; Associate's degree + 6 years; High School diploma or equivalent + 7 years * 5 years of project / program management experience * Experience delivering regional projects * Experience with formal project management methodology * Experience with scheduling, calendaring, working with multiple teams, timelines and demands\n",
      "\n",
      "\n",
      "Auto req ID 41872BR Title ASSISTANT MANAGER Employment Status: PT State/Province: Texas City: Watauga Job Description Assistant Store Managersat Dollar Tree are responsible for the following: * Assisting in the realization of your stores maximum profit contribution * Protect all company assets * Maintain a high level of good customer service * Opening and closing the store * Creative problem solving in the areas of: * Associate Development * Maximizing Sales Potential * Controlling Expense and Shrink * Merchandise Display * Store Signage PlacementWhat we need from you: * A strong desire to grow within the company * Minimum of 3 years prior retail management experience * Background in hardlines or variety merchandise * Big box experience a plus * Strong productivity management ability in freight processing * Strong communication, interpersonal and written skills * Ability to work in a high energy team environment Dollar Tree is an equal opportunity employer.\n",
      "\n",
      "\n",
      "Job Description As a CNA, you will perform a variety of home care duties to enhance the health, well-being and quality of life for your patients. All routine nursing care and services will be done in accordance with each patient''s individual plan of care. Your specific duties for this role will include: * Providing personal care and assistance with activities of daily living (ADLs), including mobility transfer, walking, grooming, bathing, dressing or undressing, eating, or toileting * Performing incidental household services essential to the patient''s health care at home as necessary to prevent or postpone institutionalization * Reporting any unusual circumstance in the patient's condition or home environment to the primary RN or Team Leader * Completing a clinical note for each visit within required timeframes, which must be incorporated into the patient''s record * Participating in the in-services program and completing at least six hours of in-services every six months * Participating in the daily report * Adhering to and supports the agency's care management model * Participating in staff conference regarding patient care * Participating in QA/QI plan or process * Providing all care according to the aide plan of care and/or assignment sheet and in accordance to State Practice Act or related regulations * Recording and notifying RN or Team Leader of any variations from the established parameters or of any changes in the patient''s condition Required Skills * High School Diploma or equivalent * Excellent interpersonal and communication skills * Team player who will always step in to offer support * Enthusiasm, drive and reliability * Responsive and proactive approach to problem solving * Upbeat and positive personality * Commitment to providing the highest quality of care * Ability to interact with patients and their families in an empathetic and professional manner * Current state CNA certification * Current driver''s license, auto insurance, and access to a reliable vehicle * CPR certification, preferred Required Experience * 1 year nursing assistant experience, preferred Company Location Muscle Shoals AL HSP (72801) *Tracking Code:* 210387 *Job location:* Muscle Shoals, Alabama, United States *Position Type:* PRN\n",
      "\n",
      "\n",
      "Epic Health Services, Inc. is looking for Bilingual (Spanish) Registered Nurses (RN) and Licensed Practical Nurses (LPN) for Pediatric Private Duty Nursing in **Freehold**: **Job Responsibilities Include:** * Provide skilled nursing care to pediatric and adult patients in a home setting * Assess home health patients to identify the physical, psycho-social, and environmental needs * Implement/develop/document the plan of care to ensure quality and continuity of care for pediatric patient * Provide health education to patient and or caregiver * Provide effective communication to patient/family, team members, and other health care professionals **Job Requirements:** * Must have an active nurse license in the state of employment * Minimum 6 months of licensed hands-on experience in the past 36 months as a LPN or RN (excluding clinical rotations) * LPN or RN home health or private duty nursing preferred * Pediatric trach and vent experience preferred * Current CPR accredited by American Heart Association and/or American Red Cross (certificate must be healthcare provider or healthcare professional). **Benefits:** * Competitive Weekly Pay * Direct Deposit * Healthcare Benefits * 401K * Flexible Schedules * Paid Training *CB* *Business Sector:* Epic Health Services Inc. *Location:* NJ-Toms River *General Area:* Freehold, NJ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ad in sampleDF.sort_values(by = 'likelihood')['jobDescription'][:5]:\n",
    "    print (ad + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for phrases corresponding to job skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-14.355247"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adprob([[\"python\", \"programming\"]], resume_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.93109"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adprob([[\"basic\", \"programming\"]], resume_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic programming appears to be more likely in this pool of resumes than python programming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do some simple statistics. Unfortunately, we don't have a large sample here. Nevertheless, let's first look at the mean likelihood score of each hiring organization. Some organizations will do well to hire on CareerBuilder...while others will not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiringOrganization_organizationName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Honeywell</th>\n",
       "      <td>-25.974749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Legrand North America</th>\n",
       "      <td>-40.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Franciscan St. Eilzabeth Health</th>\n",
       "      <td>-43.167206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois Wesleyan University</th>\n",
       "      <td>-52.681591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gold's Gym</th>\n",
       "      <td>-75.230896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jewel-Osco</th>\n",
       "      <td>-80.965462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ingersoll Rand</th>\n",
       "      <td>-81.494949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiser Permanente</th>\n",
       "      <td>-85.523113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hallmark Health</th>\n",
       "      <td>-86.037094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr Pepper Snapple Group</th>\n",
       "      <td>-99.421326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Dynamics Mission Systems</th>\n",
       "      <td>-101.916016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emory Healthcare</th>\n",
       "      <td>-102.271820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genesis Rehabilitation</th>\n",
       "      <td>-105.064774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EY</th>\n",
       "      <td>-105.651237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hewlett Packard Enterprise Company</th>\n",
       "      <td>-106.875103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominos Pizza</th>\n",
       "      <td>-116.374700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Intel</th>\n",
       "      <td>-117.038742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>East West Bank</th>\n",
       "      <td>-119.060699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCS Corporation</th>\n",
       "      <td>-119.501137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ken Garff</th>\n",
       "      <td>-120.361084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMC</th>\n",
       "      <td>-121.622444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eurofins Lancaster Laboratories</th>\n",
       "      <td>-122.223595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kettering Medical Center</th>\n",
       "      <td>-122.765350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kronos Incorporated</th>\n",
       "      <td>-122.840622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCR ManorCare</th>\n",
       "      <td>-123.508369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golfsmith International, Inc.</th>\n",
       "      <td>-123.573792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kelly Services</th>\n",
       "      <td>-130.990227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBM</th>\n",
       "      <td>-131.666611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harris Corporation</th>\n",
       "      <td>-131.853256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deutsche Bank</th>\n",
       "      <td>-132.499237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laboratory Corporation of America</th>\n",
       "      <td>-145.438156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education Corporation of America</th>\n",
       "      <td>-146.955536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KPMG</th>\n",
       "      <td>-148.719376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kelle's Transport Service Inc</th>\n",
       "      <td>-159.437958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida Hospital</th>\n",
       "      <td>-162.604172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning Care Group</th>\n",
       "      <td>-167.503754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J&amp;J Family of Companies</th>\n",
       "      <td>-168.375862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICF International</th>\n",
       "      <td>-168.376930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GE</th>\n",
       "      <td>-169.097374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humana</th>\n",
       "      <td>-172.795746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Footprint Retail Services</th>\n",
       "      <td>-174.338989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Express Scripts</th>\n",
       "      <td>-177.804581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deloitte</th>\n",
       "      <td>-183.557471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Golden Living</th>\n",
       "      <td>-192.657858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eaton Corporation</th>\n",
       "      <td>-209.906540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPC - Genuine Parts Company</th>\n",
       "      <td>-212.211792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan Chase</th>\n",
       "      <td>-228.657349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hitachi Data Systems</th>\n",
       "      <td>-229.553279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination Hotels &amp; Resorts</th>\n",
       "      <td>-263.172791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HamiltonConstructionCompany</th>\n",
       "      <td>-324.117249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GameStop</th>\n",
       "      <td>-328.072083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Quinta Inns &amp; Suites</th>\n",
       "      <td>-343.545471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Home Depot</th>\n",
       "      <td>-357.972627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HMSHOST</th>\n",
       "      <td>-409.498688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LHC Group</th>\n",
       "      <td>-413.633423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G6 Hospitality</th>\n",
       "      <td>-468.545807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Epic Health Services</th>\n",
       "      <td>-527.781067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kforce</th>\n",
       "      <td>-762.142422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dollar Tree</th>\n",
       "      <td>-818.945801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hill-Rom</th>\n",
       "      <td>-2675.631592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      likelihood\n",
       "hiringOrganization_organizationName             \n",
       "Honeywell                             -25.974749\n",
       "Legrand North America                 -40.500500\n",
       "Franciscan St. Eilzabeth Health       -43.167206\n",
       "Illinois Wesleyan University          -52.681591\n",
       "Gold's Gym                            -75.230896\n",
       "Jewel-Osco                            -80.965462\n",
       "Ingersoll Rand                        -81.494949\n",
       "Kaiser Permanente                     -85.523113\n",
       "Hallmark Health                       -86.037094\n",
       "Dr Pepper Snapple Group               -99.421326\n",
       "General Dynamics Mission Systems     -101.916016\n",
       "Emory Healthcare                     -102.271820\n",
       "Genesis Rehabilitation               -105.064774\n",
       "EY                                   -105.651237\n",
       "Hewlett Packard Enterprise Company   -106.875103\n",
       "Dominos Pizza                        -116.374700\n",
       "Intel                                -117.038742\n",
       "East West Bank                       -119.060699\n",
       "DCS Corporation                      -119.501137\n",
       "Ken Garff                            -120.361084\n",
       "EMC                                  -121.622444\n",
       "Eurofins Lancaster Laboratories      -122.223595\n",
       "Kettering Medical Center             -122.765350\n",
       "Kronos Incorporated                  -122.840622\n",
       "HCR ManorCare                        -123.508369\n",
       "Golfsmith International, Inc.        -123.573792\n",
       "Kelly Services                       -130.990227\n",
       "IBM                                  -131.666611\n",
       "Harris Corporation                   -131.853256\n",
       "Deutsche Bank                        -132.499237\n",
       "...                                          ...\n",
       "Laboratory Corporation of America    -145.438156\n",
       "Education Corporation of America     -146.955536\n",
       "KPMG                                 -148.719376\n",
       "Kelle's Transport Service Inc        -159.437958\n",
       "Florida Hospital                     -162.604172\n",
       "Learning Care Group                  -167.503754\n",
       "J&J Family of Companies              -168.375862\n",
       "ICF International                    -168.376930\n",
       "GE                                   -169.097374\n",
       "Humana                               -172.795746\n",
       "Footprint Retail Services            -174.338989\n",
       "Express Scripts                      -177.804581\n",
       "Deloitte                             -183.557471\n",
       "Golden Living                        -192.657858\n",
       "Eaton Corporation                    -209.906540\n",
       "GPC - Genuine Parts Company          -212.211792\n",
       "JPMorgan Chase                       -228.657349\n",
       "Hitachi Data Systems                 -229.553279\n",
       "Destination Hotels & Resorts         -263.172791\n",
       "HamiltonConstructionCompany          -324.117249\n",
       "GameStop                             -328.072083\n",
       "La Quinta Inns & Suites              -343.545471\n",
       "Home Depot                           -357.972627\n",
       "HMSHOST                              -409.498688\n",
       "LHC Group                            -413.633423\n",
       "G6 Hospitality                       -468.545807\n",
       "Epic Health Services                 -527.781067\n",
       "Kforce                               -762.142422\n",
       "Dollar Tree                          -818.945801\n",
       "Hill-Rom                            -2675.631592\n",
       "\n",
       "[67 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDF.groupby(\"hiringOrganization_organizationName\")[['likelihood']].mean().sort_values('likelihood', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the mean likelihood of each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobLocation_address_region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>-40.500500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>-63.730721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>-67.623466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>-85.259682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>-93.188822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>-93.989101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>-94.109772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>-102.271820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>-103.527328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>-108.747134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>-122.494473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>-138.063202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>-147.725601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>-147.850291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>-151.947347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>-154.733734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>-159.437958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>-160.932640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>-170.760437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>-177.804581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>-180.824776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>-194.792297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>-200.726547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>-205.022661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>-209.906540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>-219.999863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>-237.326090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>-320.879336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>-328.072083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>-328.259613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>-349.076074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>-447.911438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>-453.519656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>-1449.594093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             likelihood\n",
       "jobLocation_address_region             \n",
       "Utah                         -40.500500\n",
       "Montana                      -63.730721\n",
       "Connecticut                  -67.623466\n",
       "Kansas                       -85.259682\n",
       "Tennessee                    -93.188822\n",
       "Illinois                     -93.989101\n",
       "New Hampshire                -94.109772\n",
       "Georgia                     -102.271820\n",
       "South Carolina              -103.527328\n",
       "North Carolina              -108.747134\n",
       "Ohio                        -122.494473\n",
       "Louisiana                   -138.063202\n",
       "Florida                     -147.725601\n",
       "California                  -147.850291\n",
       "Maryland                    -151.947347\n",
       "Arizona                     -154.733734\n",
       "Minnesota                   -159.437958\n",
       "Virginia                    -160.932640\n",
       "Wisconsin                   -170.760437\n",
       "Missouri                    -177.804581\n",
       "South Dakota                -180.824776\n",
       "Nebraska                    -194.792297\n",
       "Kentucky                    -200.726547\n",
       "Massachusetts               -205.022661\n",
       "Oklahoma                    -209.906540\n",
       "Pennsylvania                -219.999863\n",
       "New Jersey                  -237.326090\n",
       "Alabama                     -320.879336\n",
       "New York                    -328.072083\n",
       "Indiana                     -328.259613\n",
       "Texas                       -349.076074\n",
       "New Mexico                  -447.911438\n",
       "Oregon                      -453.519656\n",
       "Michigan                   -1449.594093"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleDF.groupby(\"jobLocation_address_region\")[['likelihood']].mean().sort_values('likelihood', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would increase the sample size if you want to do a more serious study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3a*</span>\n",
    "\n",
    "<span style=\"color:red\">**Do only 3a or 3b.** Construct cells immediately below this that calculate the scores for a small sample of documents from outside your corpus to identify which are *closest* to your corpus. Then calculate the scores for a few phrases or sentences to identify the ones most likely to have appeared in your corpus. Interrogate patterns associated with these document/phrase scores (e.g., which companies produced job ads most or least likely to find jobseekers in the resume corpus?) What do these patterns suggest about the boundaries of your corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this supplemental homework, I am going to introduce the White House Senator Press dataset into my analysis, and use the score function to identify which of the documents are closet to my corpus - Trump's 100-days tweets corpus. And them, I will also calculate the scores for phrases represents US-China relationship to see what kind of expressions are more likely to be appeared in Trump's tweets. At last, by comparing the score of the White House Senator Press and the Kennedy Senator Press, I will examine which senator press's discourse is more consistent with the discourse of Trump."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I will introduce the model that I trained with Trump's 100-days tweets data in Homework 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trumpDF = pandas.read_csv(\"../data/trump100days.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @jmichaelkell: To sum it up:\\r\\r1. Trump - ...</td>\n",
       "      <td>[[RT, @, jmichaelkell, :, To, sum, it, up, :, ...</td>\n",
       "      <td>[[rt, jmichaelkell, sum], [trump, sexual, pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @DrDavidDuke: Did John McCain wiretap Presi...</td>\n",
       "      <td>[[RT, @, DrDavidDuke, :, Did, John, McCain, wi...</td>\n",
       "      <td>[[rt, drdavidduke, john, mccain, wiretap, pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @PrisonPlanet: The Revolutionary Communist ...</td>\n",
       "      <td>[[RT, @, PrisonPlanet, :, The, Revolutionary, ...</td>\n",
       "      <td>[[rt, prisonplanet, revolutionary, communist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Team Trump shares tips on keeping their boss ...</td>\n",
       "      <td>[[``, Team, Trump, shares, tips, on, keeping, ...</td>\n",
       "      <td>[[team, trump, shares, tips, keeping, boss, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @larryelder: Rep. @MaxineWaters says Trump'...</td>\n",
       "      <td>[[RT, @, larryelder, :, Rep., @, MaxineWaters,...</td>\n",
       "      <td>[[rt, larryelder, maxinewaters, says, trump, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  RT @jmichaelkell: To sum it up:\\r\\r1. Trump - ...   \n",
       "1  RT @DrDavidDuke: Did John McCain wiretap Presi...   \n",
       "2  RT @PrisonPlanet: The Revolutionary Communist ...   \n",
       "3  \"Team Trump shares tips on keeping their boss ...   \n",
       "4  RT @larryelder: Rep. @MaxineWaters says Trump'...   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0  [[RT, @, jmichaelkell, :, To, sum, it, up, :, ...   \n",
       "1  [[RT, @, DrDavidDuke, :, Did, John, McCain, wi...   \n",
       "2  [[RT, @, PrisonPlanet, :, The, Revolutionary, ...   \n",
       "3  [[``, Team, Trump, shares, tips, on, keeping, ...   \n",
       "4  [[RT, @, larryelder, :, Rep., @, MaxineWaters,...   \n",
       "\n",
       "                                    normalized_sents  \n",
       "0  [[rt, jmichaelkell, sum], [trump, sexual, pred...  \n",
       "1  [[rt, drdavidduke, john, mccain, wiretap, pres...  \n",
       "2  [[rt, prisonplanet, revolutionary, communist, ...  \n",
       "3  [[team, trump, shares, tips, keeping, boss, di...  \n",
       "4  [[rt, larryelder, maxinewaters, says, trump, c...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trumpDF['tokenized_sents'] = trumpDF['text'].apply(lambda x: \n",
    "                                                               [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "trumpDF['normalized_sents'] = trumpDF['tokenized_sents'].apply(lambda x: \n",
    "                                                                           [lucem_illud.normalizeTokens(s, \n",
    "                                                                                           stopwordLst = lucem_illud.stop_words_basic, \n",
    "                                                                                           stemmer = None) \n",
    "                                                                            for s in x])\n",
    "\n",
    "trumpDF[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump2W2V = gensim.models.word2vec.Word2Vec(trumpDF['normalized_sents'].sum(),hs=1,negative=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump2_model = trump2W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the vacabularies of this model by building a word-index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = trump2_model.wv.index2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a sample of documents from the White House Senator Press Releasing Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whSampleDF = pandas.read_csv('../data/whReleasesTraining.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>download_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>targetSenator</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Apr2007Whitehouse123.txt</td>\n",
       "      <td>raw/Whitehouse/10Apr2007Whitehouse123.txt</td>\n",
       "      <td>SEN. WHITEHOUSE SHARES WESTERLY GIRL'S STORY I...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[SEN., WHITEHOUSE, SHARES, WESTERLY, GIRL, 'S,...</td>\n",
       "      <td>[whitehous, share, wester, girl, stori, push, ...</td>\n",
       "      <td>-26.037243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Apr2008Whitehouse2.txt</td>\n",
       "      <td>raw/Whitehouse/10Apr2008Whitehouse2.txt</td>\n",
       "      <td>SEN. WHITEHOUSE SAYS PRESIDENT BUSH MUST BEGIN...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[SEN., WHITEHOUSE, SAYS, PRESIDENT, BUSH, MUST...</td>\n",
       "      <td>[whitehous, say, presid, bush, must, begin, br...</td>\n",
       "      <td>-24.361807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Apr2008Whitehouse3.txt</td>\n",
       "      <td>raw/Whitehouse/10Apr2008Whitehouse3.txt</td>\n",
       "      <td>EPA MUST REVIEW LEGAL PROCESS TO ROOT OUT POLI...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[EPA, MUST, REVIEW, LEGAL, PROCESS, TO, ROOT, ...</td>\n",
       "      <td>[epa, must, review, legal, process, root, poli...</td>\n",
       "      <td>-25.960718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       download_url  \\\n",
       "0           0  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1           1  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "2           2  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "\n",
       "                                            html_url  \\\n",
       "0  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "1  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "2  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "\n",
       "                         name                                       path  \\\n",
       "0  10Apr2007Whitehouse123.txt  raw/Whitehouse/10Apr2007Whitehouse123.txt   \n",
       "1    10Apr2008Whitehouse2.txt    raw/Whitehouse/10Apr2008Whitehouse2.txt   \n",
       "2    10Apr2008Whitehouse3.txt    raw/Whitehouse/10Apr2008Whitehouse3.txt   \n",
       "\n",
       "                                                text targetSenator  \\\n",
       "0  SEN. WHITEHOUSE SHARES WESTERLY GIRL'S STORY I...    Whitehouse   \n",
       "1  SEN. WHITEHOUSE SAYS PRESIDENT BUSH MUST BEGIN...    Whitehouse   \n",
       "2  EPA MUST REVIEW LEGAL PROCESS TO ROOT OUT POLI...    Whitehouse   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [SEN., WHITEHOUSE, SHARES, WESTERLY, GIRL, 'S,...   \n",
       "1  [SEN., WHITEHOUSE, SAYS, PRESIDENT, BUSH, MUST...   \n",
       "2  [EPA, MUST, REVIEW, LEGAL, PROCESS, TO, ROOT, ...   \n",
       "\n",
       "                                   normalized_tokens  likelihood  \n",
       "0  [whitehous, share, wester, girl, stori, push, ...  -26.037243  \n",
       "1  [whitehous, say, presid, bush, must, begin, br...  -24.361807  \n",
       "2  [epa, must, review, legal, process, root, poli...  -25.960718  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whSampleDF[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>download_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>targetSenator</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Apr2007Whitehouse123.txt</td>\n",
       "      <td>raw/Whitehouse/10Apr2007Whitehouse123.txt</td>\n",
       "      <td>SEN. WHITEHOUSE SHARES WESTERLY GIRL'S STORY I...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[SEN., WHITEHOUSE, SHARES, WESTERLY, GIRL, 'S,...</td>\n",
       "      <td>[whitehous, share, wester, girl, stori, push, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>28Feb2007Whitehouse143.txt</td>\n",
       "      <td>raw/Whitehouse/28Feb2007Whitehouse143.txt</td>\n",
       "      <td>SEN. WHITEHOUSE PROTESTS FIRINGS OF FEDERAL PR...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[SEN., WHITEHOUSE, PROTESTS, FIRINGS, OF, FEDE...</td>\n",
       "      <td>[whitehous, protest, fire, feder, prosecutor, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                       download_url  \\\n",
       "0             0  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "100         100  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "\n",
       "                                              html_url  \\\n",
       "0    https://github.com/lintool/GrimmerSenatePressR...   \n",
       "100  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "\n",
       "                           name                                       path  \\\n",
       "0    10Apr2007Whitehouse123.txt  raw/Whitehouse/10Apr2007Whitehouse123.txt   \n",
       "100  28Feb2007Whitehouse143.txt  raw/Whitehouse/28Feb2007Whitehouse143.txt   \n",
       "\n",
       "                                                  text targetSenator  \\\n",
       "0    SEN. WHITEHOUSE SHARES WESTERLY GIRL'S STORY I...    Whitehouse   \n",
       "100  SEN. WHITEHOUSE PROTESTS FIRINGS OF FEDERAL PR...    Whitehouse   \n",
       "\n",
       "                                        tokenized_text  \\\n",
       "0    [SEN., WHITEHOUSE, SHARES, WESTERLY, GIRL, 'S,...   \n",
       "100  [SEN., WHITEHOUSE, PROTESTS, FIRINGS, OF, FEDE...   \n",
       "\n",
       "                                     normalized_tokens  \n",
       "0    [whitehous, share, wester, girl, stori, push, ...  \n",
       "100  [whitehous, protest, fire, feder, prosecutor, ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whSampleDF['tokenized_text'] = whSampleDF['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "whSampleDF['normalized_tokens'] = whSampleDF['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, \n",
    "                                                                                                                            stopwordLst = lucem_illud.stop_words_basic, \n",
    "                                                                                                                            stemmer = lucem_illud.stemmer_basic))\n",
    "whSampleDF[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to calculate the likelihood of each senator press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adprob(ad, model):\n",
    "    sen_scores = model.score(ad, len(ad))\n",
    "    ad_score = sen_scores.mean()\n",
    "    return ad_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to every documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whSampleDF['likelihood'] = whSampleDF['normalized_tokens'].apply(lambda x: adprob(x, trump2_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the top 5 documents that have the highest likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEN. WHITEHOUSE ISSUES STATEMENT PRAISES SENATE PASSAGE OF IRAQ BILL SETTING GOAL FOR REDEPLOYMENT\n",
      "  Sen. Sheldon Whitehouse (D-R.I.) today released the following statement:  \n",
      "   \"Today, once again, the Senate has demonstrated our commitment to a new direction in Iraq - and once again, America is waiting to see whether this President will heed the calls of the people he serves to change course and bring our troops home. \n",
      "   \"I was proud to vote today for a measure that not only ensures our troops have the resources they need, but also requires President Bush to take action to begin a redeployment and sets a goal for when that redeployment will be complete. \n",
      "   \"I urge the President to listen to the Congress and the American people, and to sign this bill into law. If he does not, he will once again have failed our soldiers, our nation, and our future.\"\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "SEN. WHITEHOUSE RAISES AWARENESS OF TAX RELIEF FOR WORKING FAMILIES\n",
      "  With the income tax filing deadline just two weeks away, on Tuesday, April 3, 2007, Sen. Sheldon Whitehouse (D-R.I.) joined the John Hope Settlement House and representatives from the IRS to offer free tax preparation assistance and advice to working families. The event was driven by an effort to raise awareness of the Earned Income Tax Credit, which last year went unclaimed by more than 13,000 eligible Rhode Islanders.  \n",
      "   \"Working families have earned these tax credits,\" Whitehouse said. \"At a time when the Bush administration seems more focused on cutting taxes for millionaires than providing real tax relief for working families, it's important that low-income taxpayers in our state know that programs like the EITC exist to help them.\" \n",
      "   The IRS estimates that 76,000-79,000 Rhode Islanders were eligible for the EITC last year, a benefit worth up to $4,536 for a family with two or more children this year. According to the IRS, 64,981 tax filers in Rhode Island claimed the credit in the 2005 tax year, for a total tax benefit of $116 million. Nationally, the IRS estimated that 20% of people who may qualify for the EITC are not aware of the credit. In 2005, 22 million taxpayers received $41 billion in benefits from the EITC, making it one of the largest tax relief programs for American workers. \n",
      "   The John Hope Settlement House is part of a Rhode Island coalition that provides volunteer tax preparation assistance at eight venues across the state. The service is funded by both the United Way and the Casey Foundation. The program assisted 1,600 EITC filers last year and hopes to exceed that total this year. This year's filing deadline is April 17. \n",
      "   Senator Whitehouse, a strong advocate for working families, recently joined Senator Charles Schumer (D-N.Y.) to unveil legislation designed to offer real tax relief to middle class families. The tax relief package consisted of four components, designed to help families during times of need: expansion of the child tax credit, relief from the individual Alternative Minimum Tax (AMT), simplification and expansion of higher education tax credits, and a new elder-care credit for families caring for aging loved ones.\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "SEN. WHITEHOUSE ISSUES STATEMENT ON FIFTH ANNIVERSARY OF WAR IN IRAQ\n",
      "  U.S. Senator Sheldon Whitehouse (D-R.I.) commented today on the fifth anniversary of the beginning of the war in Iraq. \n",
      "   \"Tomorrow, March 19, marks the end of the fifth year that American troops have spent fighting in Iraq. Hundreds of thousands of brave men and women have endured month after month in a strange land, thousands of miles from home and family. Tens of thousands of them have returned home wounded. Nearly four thousand have given their lives. They and their families are in our prayers, today and every day.\n",
      "   \"Our troops have served this nation with courage and honor, and now, it's time to start bringing them home. President Bush took our country to war on false pretenses, without a plan to win the peace. His administration's misjudgments and poor decisions have cost our nation trillions of dollars, sapped the strength of our armed forces, hurt our standing in the international community, and distracted us from the urgent tasks of dismantling al Qaeda and dealing with a resurgent Taliban. Meanwhile, they have done little to alleviate the human suffering of the Iraqi people.\n",
      "   \"It's clear this President will do nothing to end this endless war. I will continue to push, as Rhode Islanders have urged me to do, for a redeployment of U.S. forces from Iraq, and I join millions of Americans working to see that our next President will seek a new direction.\"\n",
      "   Whitehouse, a member of the Senate Select Committee on Intelligence, visited Iraq a year ago.\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "SEN. WHITEHOUSE ISSUES STATEMENT ON SENATE VOTE ON IRAQ ESCALATION\n",
      "  Sen. Sheldon Whitehouse (D-RI) released the following statement following today's Senate vote:  \n",
      "   \"I'm proud that the Democratic leadership brought up this critical vote today. Importantly, the outcome was 56 seeking to vote against the President's escalation of troop levels in Iraq, to 34 seeking to block that vote. 56 to 34 is a strong message. \n",
      "   \"Yesterday, I spoke again on the Senate floor, and read from a few of the thousands of messages I have received from Rhode Islanders calling on us to bring our troops home. It's troublingly clear the President isn't listening, but the Democrats in the Senate are. We will keep pressure on this administration to change course in Iraq. \n",
      "   \"If the President does not offer the new direction Americans demand, we will.\"\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "SEN. WHITEHOUSE: SENATE MUST DEBATE PRESIDENT'S ESCALATION PLAN\n",
      "  On the eve of a critical U.S. Senate vote on the President's plan to escalate the war in Iraq, Sen. Sheldon Whitehouse (D-RI) took to the Senate floor for the second time to call for a serious and meaningful debate on the President's proposal and what it means for the nation.\n",
      "  \"People all across America are speaking to all of us, and it is time for us to listen and to show that we have heard and to start to bring our soldiers home,\" said Whitehouse, reading from a few of the thousands of letters, emails, and calls his office has received from Rhode Islanders in the last six weeks. \"The President has not heard these voices. He wants to send tens of thousands more troops to Iraq. He calls this a surge. We consider it a grave mistake.\" \n",
      "   Whitehouse addressed the Senate for the first time ten days ago, to protest a series of parliamentary maneuvers intended to block debate on legislation disapproving of the President's plan to send tens of thousands more troops to Iraq.  \n",
      "   The Senate will vote tomorrow on a procedural motion necessary to move to a debate on the war. \n",
      "   Whitehouse's remarks, as delivered, are below. \n",
      "   Mr. WHITEHOUSE. Thank you, Mr. President. \n",
      "   Mr. President, I rise today to speak on behalf of thousands of Rhode Islanders who have talked with me about the need for a new direction in Iraq and the need to bring our troops home. \n",
      "   I speak on behalf of the veterans' families who traveled here to Washington to speak to me about their memories of war and the need for this one to end. \n",
      "   I speak on behalf of the brave men and women serving in Iraq who have sacrificed so much and whose families anxiously await their return. \n",
      "   I speak on behalf of mothers I met who felt they had to buy body armor for their sons and daughters headed for Iraq because they could not trust this administration to provide what was needed. \n",
      "   The Senate may have been muzzled in recent days, but Rhode Islanders certainly have not been. More than 2,000 of them have reached out to my office in frustration, in anger, and in concern -- and in the hope that this new Democratic Senate will listen to them and hear them, as this administration will not. \n",
      "   I want to share some of what they have written me: \n",
      "   I was at Michael Weidemann's funeral. \n",
      "   Mr. President, Michael was a 23-year-old Army sergeant from Newport, killed in an IED blast in Anbar Province last November. \n",
      "   The letter continues: \n",
      "   Please, if nothing else, take care of things, so that we do not have to go through what we went through at that funeral. Michael and my son...were in the JROTC together....He is on his second tour of Iraq. Please, don't make yesterday a dress rehearsal for me. I want my son to come home, safely. \n",
      "   From Johnston, Rhode Island: \n",
      "   My son...is presently serving in Iraq and on his second tour of duty there....The President's plan ignores the American people who voted for change in November, and who continue to demand we bring our troops home....The people made their voice heard, and if the President isn't going to listen, the Democratic Congress will. The President's policies have failed! \n",
      "   From Portsmouth, Rhode Island: \n",
      "   President Bush has ignored the advice of experience, lied to us all, lacked any plan and seems to be expecting his successor to solve the problems. It is our only hope that you, as a member of Congress, can work toward bringing our troops home soon. \n",
      "   From Kingston: \n",
      "   I am appalled at the loss of life -- today it was reported 20 more service people were killed. The Kurds are deserting rather than fight in Baghdad....We are not just losing people, we are losing big money. We have seven grandchildren. What kind of debt are we placing on those future generations? \n",
      "   From Warwick: \n",
      "   We never should have begun this war, let's now have the sense to end it, not prolong it. Please do whatever you can to stop the president's initiative to increase our military presence in Iraq...., to spend even more money waging a war that your constituents have indicated they no longer support. \n",
      "   From North Kingstown: \n",
      "   We are looking to you to do whatever is in your power to stop the U.S. escalation of troops in Iraq. I and many in our nation feel this will only make a bad situation worse, widen what is essentially a civil war and lead to further casualties and costs without contributing towards a political solution....We are counting on you and your colleagues on both sides of the aisle to stand up and be counted and forge a bipartisan solution to end this war. \n",
      "   And finally, a woman from Cumberland forwarded me a message she sent to President Bush: \n",
      "   My nephew...is in the 82nd Airborne serving our country in Iraq. He is the bravest person I have ever known, along with all the other men and women serving this country. I am proud to be an American! Please, please, on behalf of my family and the families of all U.S. troops -- bring them home now! \n",
      "   Mr. President, these voices will not be unfamiliar to anyone in this body. In every State, we have heard similar voices. You have heard them in Colorado, Mr. President. My friend, Senator Sanders, has heard them in Vermont. People all across America are speaking to all of us, and it is time for us to listen and to show that we have heard and to start to bring our soldiers home. \n",
      "   The President has not heard these voices. He wants to send tens of thousands more troops to Iraq. He calls this a surge. We consider it a grave mistake. \n",
      "   Tomorrow, our vote can stop the parliamentary maneuvers that have stalled us, and this great deliberative body can begin to debate the most pressing question of this day. \n",
      "   Let's talk for a moment about that question. The other side wishes to debate every question, any question -- any question but the escalation by this President of our troops in Iraq by over 21,000 men and women. But this question we want to debate is not a question selected by Democrats for political reasons. It is possible here to choose self-serving questions and to force a debate on those questions just to make a political point. But we have not done that. \n",
      "   This question, whether to escalate the war in Iraq, is not an invention of the Democratic Party. It is not an invention of the Senate. It is President Bush, who proposed to send tens of thousands more troops into harm's way and to escalate this conflict, who has presented this question. This question is what was presented to us by President George W. Bush, and by him alone, and it is the pressing question of today. \n",
      "   For weeks, we on this side of the aisle have emphasized and reemphasized our strong commitment to having a real debate -- a debate to a vote -- to telling the American people where we stand and to casting our votes on the precise question the President of the United States has presented to America. But we have been impeded, obstructed, maneuvered away from this critical question. \n",
      "   The other side argues that to dispute this President's judgment is to fail to support the troops -- even though that judgment has failed the troops and has failed our country and has left us with few good options. But that is a false choice, Mr. President. And this hour demands better of this institution. \n",
      "   There are ways to accomplish the change America demands, and that reason and good conscience dictate. For instance, I believe that rather than send a single additional American soldier into the sands and marshes of Iraq, this President can announce clearly and unequivocally that our troops will be redeployed from Iraq and will soon come home. \n",
      "   The most powerful motivating force at our country's disposal today is the prospect of our redeployment out of Iraq. Let me repeat that. The most powerful motivating force at our country's disposal today is the prospect of redeployment out of Iraq. Using this power wisely, deftly, and thoughtfully would accomplish three critical objectives that, as I have said, would make great strides toward security in Iraq and stability in the region. \n",
      "   First, a clear statement of our intent to redeploy our troops from Iraq would eliminate the sense there that we are an Army of occupation. This in turn would quiet the nationalist sentiment of the Iraqi people, now aroused against us. Many Iraqis are now so opposed to our presence they think killing American soldiers is acceptable. \n",
      "   Second, without America's intervening presence, the world community would have to face directly the consequences of the situation in Iraq. The prospect of our departure would compel the world to take a more active role to work together with America to bring peace and stability to the region. We cannot continue as we are now, in every meaningful way completely alone. \n",
      "   Third, Iraq's neighbors will be obliged to assume greater responsibility for averting the risk of a Sunni-Shiite conflict igniting in Iraq and spreading beyond Iraq's borders. Without us in Iraq as a police force for a civil war, neighboring nations will have an enlivened incentive to avert a wider war. \n",
      "   Finally, the Bush administration's preoccupation with Iraq leaves us weakened in our capability to address other obligations around the world, from the changing situation in North Korea, to the ongoing battle for Afghanistan, to the serious threat posed by Iran's nuclear program. \n",
      "   Mr. President, these are serious matters, and they deserve the serious and sustained attention of the Senate. I hope tomorrow's vote will allow us to bring this question that attention. \n",
      "   Mr. President, I will support that vote tomorrow. I ask other Senators, who hear our fellow Americans' genuine and sincere concern about our national interest, will do the same. \n",
      "   I will support not only the resolution disapproving of the President's escalation plan and supporting our troops, but also other, stronger measures that will follow, and that will continue to put pressure on this administration to finally bring our troops home. \n",
      "   Thank you, Mr. President. I yield the floor.\n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ad in whSampleDF.sort_values(by = 'likelihood', ascending = False)['text'][:5]:\n",
    "    print (ad + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the bottom 5 documents that have the lowest likelihood to be matched by Trump's tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEN. WHITEHOUSE MEETS HOPKINTON, WEST GREENWICH HIGH SCHOOL STUDENTS\n",
      "  Sen. Sheldon Whitehouse (D-RI) met Thursday with two high school students visiting Washington as part of their participation in the National Young Leaders Conference (NYLC). \n",
      "   Theresa Fuller of Hopkinton, a sophomore at Chariho Regional High School, and Geoffrey Swann of West Greenwich, a junior at Exeter West Greenwich High School, had been in Washington as part of their six-day program since Tuesday. The program is designed to give students a better understanding of their roles as citizens and leaders in a democracy. \n",
      "   \"Visiting Washington and speaking with me and their other representatives in Congress will, hopefully, develop a further interest in public affairs,\" said Whitehouse. \"I appreciate the efforts of these young Rhode Islanders to learn more about their government.\" \n",
      "   The students had an opportunity to see Senator Whitehouse questioning Treasury Secretary Henry Paulson at a Budget Committee hearing, and shared their Washington site-seeing itinerary. \n",
      "   The NYLC program is sponsored by the Congressional Youth Leadership Council (CYLC), a non-partisan, non-profit educational organization. Since its inception in 1985, more than 200,000 young people have participated in CYLC's programs.\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "SEN. WHITEHOUSE MEETS CUMBERLAND STUDENT RECOGNIZED AT NATIONAL SCIENCE COMPETITION\n",
      "  U.S. Senator Sheldon Whitehouse (D-R.I.) met this week with Providence College student Joshua Malouin of Cumberland, R.I., whose project on cellular biology could have implications for cancer research. Malouin, a sophomore biology student, was one of 80 students selected by the Council on Undergraduate Research (CUR) to participate in a poster session on Capitol Hill.  \n",
      "   \"I want to applaud Joshua for his outstanding achievement,\" Whitehouse said. \"I believe investment in education and science research should be a national priority.\" \n",
      "   More than 400 students from around the country submitted entries to the competition, which culminated with the poster display in the Rayburn House Office Building. CUR is a professional society that promotes the participation of undergraduate college students in scientific and engineering research. The organization was founded in 1978 by chemists from private liberal arts colleges to provide information about research being conducted in academia. Today there are nearly 3,000 members and 492 participating colleges and universities. \n",
      "   This year's competition coincides with the Senate's passage of the bipartisan America COMPETES (Creating Opportunities to Meaningfully Promote Excellence in Technology, Education, and Science) Act that encourages science innovators throughout the federal government to promote education and science research. Whitehouse voted to support the measure. A member of the Senate Budget Committee, Whitehouse has also supported significant increases in funding for education and the National Institutes of Health (NIH).\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "CONGRESS PASSES SEN. WHITEHOUSE HEALTH IT MEASURE IN 2008 BUDGET BLUEPRINT\n",
      "  As the nation recognizes National Health IT Week 2007, Congress today approved a fiscal 2008 budget resolution that included a measure proposed by U.S. Senators Sheldon Whitehouse (D-R.I.) and Debbie Stabenow (D-Mich.) to support health information technology and accepted best practices in clinical settings. \n",
      "   \"Health information technology is a crucial piece of the health care puzzle,\" said Whitehouse. \"I am encouraged - and proud - that this budget will provide this critical support for the adoption of modern health information technology and accepted best practices in clinical settings.\" \n",
      "   Whitehouse, a member of the Senate Budget Committee, joined Stabenow during the committee's consideration of the budget in March to introduce a deficit-neutral reserve fund to provide incentives for the adoption of health information technology within the medical community, and payments based on adherence to clinical protocols identified as best practices. \n",
      "   The reserve fund will allow the chairman of the Budget Committee to adjust funding levels within Congress's overall budget to allow for increased spending on health IT and best practices, so long as that spending does not increase the deficit. The Budget Committee approved the amendment unanimously. \n",
      "   Up to 100,000 lives are lost in the United States each year due to avoidable medical errors. Electronic medical records can reduce mistakes such as adverse drug events by automating and standardizing procedures; improving the coordination of chronic care and bio-surveillance; and making hospitals and physicians' offices more efficient. \n",
      "   Currently, only 25 percent of hospitals and 20 percent of physician offices utilize electronic medical records. The RAND Corporation has estimated that widespread implementation of effective electronic medical record systems could save $81 billion or more annually. \n",
      "   Whitehouse is a cosponsor of a Senate resolution, passed Tuesday by unanimous consent, recognizing the value of information technology in health care and officially designating the week beginning May 14, 2007 as National Health Information Technology Week (S. Res. 202). The week provides a forum for public and private organizations who support health information technology to gather, share ideas, and communicate with members of Congress in an effort to raise awareness about the importance of health IT.\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "SEN. WHITEHOUSE APPLAUDS $10 MILLION GRANT FOR BROWN STUDY OF LONG-TERM HEALTH CARE QUALITY\n",
      "  U.S. Senator Sheldon Whitehouse (D-R.I.) today congratulated Brown University on its receipt of a $10 million grant from the National Institute on Aging to conduct research on the quality of long-term health care in this country.  \n",
      "  \"Long-term care is a critical part of our health care infrastructure, improving the lives of millions of Americans every day. This grant represents not only an awareness of the importance of long-term care services in our aging society, but also a strong commitment to improving these services moving forward,\" said Whitehouse, a member of the Senate Aging Committee. \"I'm proud that Brown University will have the chance to continue Rhode Island's leading role in improving the quality of health care across the country.\" \n",
      "  The $10 million award, allocated over five years, will support a research project by Brown's Center for Gerontology and Health Care Research to collect data on insurance reimbursement claims, hospitalizations, the health of long-term care facility residents, relevant state policies and a myriad of other topics from nursing homes all over America. When completed, Brown's comprehensive database will be a powerful tool to assist policymakers as they assess ways to improve the quality of Americans' health care.\n",
      "  Whitehouse has worked to improve the quality of health care through his career in public service. As Rhode Island's Attorney General, he founded the Rhode Island Quality Institute, a collaborative effort between health care providers, insurers, and government that has spearheaded initiatives to expand the use of electronic health records and promote evidence-based reforms. \n",
      "  In the Senate, Whitehouse has introduced legislation aimed at encouraging health quality reforms, building a national health information technology infrastructure, and linking health care payments to health care quality. A member of the Senate Budget Committee, Whitehouse succeeded in offering an amendment to Congress's fiscal year 2008 budget resolution creating a reserve fund for the adoption of modern health information technology.\n",
      " \n",
      " \n",
      "\n",
      "\n",
      "THUNDERMIST CEO ADDRESSES SENATE CONFERENCE ON HEALTH INFORMATION TECHNOLOGY\n",
      "  Maria Montanaro, CEO of the Woonsocket-based community health center Thundermist, addressed the Senate Steering Committee on Telehealth and Healthcare Informatics today to discuss her organization's transition to electronic medical records. U.S. Senator Sheldon Whitehouse (D-R.I.) introduced Montanaro at the event, titled \"HIT Projects to Improve Access for Low Income Persons and the Uninsured: Safety Net Providers Step up To the Plate.\" \n",
      "   \"I think there is something truly inspiring about a safety net provider who defies the status quo, even in the face of terrible financial disincentives, to invest in state-of-the-art technology to provide the highest-quality care for those who have fallen through the cracks,\" said Whitehouse, an honorary co-chair of the steering committee. \"And Thundermist was careful to create their new infrastructure the right way - in cooperation with larger statewide projects in health information technology, advancing the goal of a statewide health information data exchange system.\"\n",
      "   Thundermist Health Center is a private, non-profit community health center (CHC) in Rhode Island that serves over 25,000 patients through more than 100,000 comprehensive primary health care visits a year in three communities -- Woonsocket, West Warwick, and South County. A 2007 study published in Health Affairs indicated that only 26 percent of CHCs reported some usage of electronic medical records, many citing lack of capital as a major barrier to adoption. Montanaro is leading Thundermist's transition from paper to electronic health records in order to better serve patients at its eight health center sites throughout Rhode Island.\n",
      "   Last year, Whitehouse introduced legislation to establish a private, non-profit corporation tasked with developing a national, interoperable, secure health IT system (S. 1455). In January, he called on President George W. Bush to increase federal funding for health information technology in the federal budget for Fiscal Year 2009, to help speed the development of a national health IT system.\n",
      " \n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ad in whSampleDF.sort_values(by = 'likelihood')['text'][:5]:\n",
    "    print (ad + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, 4 of the 5 documents with highest likelihood score are about US's war with Iraq, and 1 of them is about tax relief in working families. At the meanwhile, the 5 documents with lowest likelihood to be appeared in Trump's tweets are related to health care and education policy. This pattern is consistent with Trump's preferences for policiies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for phrases corresponding to US-China relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.489081"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adprob([[\"china\", \"trade\"]], trump2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-11.205366"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adprob([[\"china\", \"military\"]], trump2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "China and trade appears to be more likely in the pool of Trump's tweets than China and military. According to my analysis in homework 4, the China issue is more usually related to trade and corporation rather than military and war."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce the Kennedy Senator Press dataset into our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kenSampleDF = pandas.read_csv('../data/senReleasesTraining.csv', index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>download_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>targetSenator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>01Apr2005Kennedy14.txt</td>\n",
       "      <td>raw/Kennedy/01Apr2005Kennedy14.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   FOR IMMEDIATE...</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>01Aug2005Kennedy12.txt</td>\n",
       "      <td>raw/Kennedy/01Aug2005Kennedy12.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   FOR IMMEDIATE...</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>01Aug2006Kennedy10.txt</td>\n",
       "      <td>raw/Kennedy/01Aug2006Kennedy10.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...</td>\n",
       "      <td>Kennedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       download_url  \\\n",
       "0           0  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "1           1  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "2           2  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "\n",
       "                                            html_url                    name  \\\n",
       "0  https://github.com/lintool/GrimmerSenatePressR...  01Apr2005Kennedy14.txt   \n",
       "1  https://github.com/lintool/GrimmerSenatePressR...  01Aug2005Kennedy12.txt   \n",
       "2  https://github.com/lintool/GrimmerSenatePressR...  01Aug2006Kennedy10.txt   \n",
       "\n",
       "                                 path  \\\n",
       "0  raw/Kennedy/01Apr2005Kennedy14.txt   \n",
       "1  raw/Kennedy/01Aug2005Kennedy12.txt   \n",
       "2  raw/Kennedy/01Aug2006Kennedy10.txt   \n",
       "\n",
       "                                                text targetSenator  \n",
       "0           FOR IMMEDIATE RELEASE   FOR IMMEDIATE...       Kennedy  \n",
       "1           FOR IMMEDIATE RELEASE   FOR IMMEDIATE...       Kennedy  \n",
       "2           FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...       Kennedy  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenSampleDF[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>download_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>targetSenator</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>01Apr2005Kennedy14.txt</td>\n",
       "      <td>raw/Kennedy/01Apr2005Kennedy14.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   FOR IMMEDIATE...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...</td>\n",
       "      <td>[immedi, releas, immedi, releas, contact, meli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>101</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>02Feb2006Kennedy8.txt</td>\n",
       "      <td>raw/Kennedy/02Feb2006Kennedy8.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Washington  DC...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Washington, DC, Toda...</td>\n",
       "      <td>[immedi, releas, washington, dc, today, senat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>201</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>04May2006Kennedy7.txt</td>\n",
       "      <td>raw/Kennedy/04May2006Kennedy7.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE      FOR IMMEDI...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...</td>\n",
       "      <td>[immedi, releas, immedi, releas, washington, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>301</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>06Jun2006Kennedy5.txt</td>\n",
       "      <td>raw/Kennedy/06Jun2006Kennedy5.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...</td>\n",
       "      <td>[immedi, releas, immedi, releas, surpris, amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>401</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>08Dec2006Kennedy4.txt</td>\n",
       "      <td>raw/Kennedy/08Dec2006Kennedy4.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Washington  D ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Washington, D, C, To...</td>\n",
       "      <td>[immedi, releas, washington, c, today, senat, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>501</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>09Nov2005Kennedy10.txt</td>\n",
       "      <td>raw/Kennedy/09Nov2005Kennedy10.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Washington, DC, Toda...</td>\n",
       "      <td>[immedi, releas, washington, dc, today, senat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>601</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>11Nov2005Kennedy5.txt</td>\n",
       "      <td>raw/Kennedy/11Nov2005Kennedy5.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     On this Vet...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, On, this, Veteran, s...</td>\n",
       "      <td>[immedi, releas, veteran, day, america, stand,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>701</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>13Jun2006Kennedy0.txt</td>\n",
       "      <td>raw/Kennedy/13Jun2006Kennedy0.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...</td>\n",
       "      <td>[immedi, releas, immedi, releas, mr, chairman,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>801</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>15Dec2005Kennedy4.txt</td>\n",
       "      <td>raw/Kennedy/15Dec2005Kennedy4.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     Washington ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Washington, DC, Toda...</td>\n",
       "      <td>[immedi, releas, washington, dc, today, senat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>901</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>16May2007Kennedy10.txt</td>\n",
       "      <td>raw/Kennedy/16May2007Kennedy10.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  WASHINGTON  D ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, WASHINGTON, D, C, Se...</td>\n",
       "      <td>[immedi, releas, washington, c, senat, edward,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                       download_url  \\\n",
       "0             0  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "100         101  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "200         201  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "300         301  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "400         401  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "500         501  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "600         601  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "700         701  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "800         801  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "900         901  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "\n",
       "                                              html_url  \\\n",
       "0    https://github.com/lintool/GrimmerSenatePressR...   \n",
       "100  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "200  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "300  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "400  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "500  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "600  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "700  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "800  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "900  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "\n",
       "                       name                                path  \\\n",
       "0    01Apr2005Kennedy14.txt  raw/Kennedy/01Apr2005Kennedy14.txt   \n",
       "100   02Feb2006Kennedy8.txt   raw/Kennedy/02Feb2006Kennedy8.txt   \n",
       "200   04May2006Kennedy7.txt   raw/Kennedy/04May2006Kennedy7.txt   \n",
       "300   06Jun2006Kennedy5.txt   raw/Kennedy/06Jun2006Kennedy5.txt   \n",
       "400   08Dec2006Kennedy4.txt   raw/Kennedy/08Dec2006Kennedy4.txt   \n",
       "500  09Nov2005Kennedy10.txt  raw/Kennedy/09Nov2005Kennedy10.txt   \n",
       "600   11Nov2005Kennedy5.txt   raw/Kennedy/11Nov2005Kennedy5.txt   \n",
       "700   13Jun2006Kennedy0.txt   raw/Kennedy/13Jun2006Kennedy0.txt   \n",
       "800   15Dec2005Kennedy4.txt   raw/Kennedy/15Dec2005Kennedy4.txt   \n",
       "900  16May2007Kennedy10.txt  raw/Kennedy/16May2007Kennedy10.txt   \n",
       "\n",
       "                                                  text targetSenator  \\\n",
       "0             FOR IMMEDIATE RELEASE   FOR IMMEDIATE...       Kennedy   \n",
       "100           FOR IMMEDIATE RELEASE  Washington  DC...       Kennedy   \n",
       "200           FOR IMMEDIATE RELEASE      FOR IMMEDI...       Kennedy   \n",
       "300           FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...       Kennedy   \n",
       "400           FOR IMMEDIATE RELEASE  Washington  D ...       Kennedy   \n",
       "500           FOR IMMEDIATE RELEASE     Washington ...       Kennedy   \n",
       "600           FOR IMMEDIATE RELEASE     On this Vet...       Kennedy   \n",
       "700           FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...       Kennedy   \n",
       "800           FOR IMMEDIATE RELEASE     Washington ...       Kennedy   \n",
       "900           FOR IMMEDIATE RELEASE  WASHINGTON  D ...       Kennedy   \n",
       "\n",
       "                                        tokenized_text  \\\n",
       "0    [FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...   \n",
       "100  [FOR, IMMEDIATE, RELEASE, Washington, DC, Toda...   \n",
       "200  [FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...   \n",
       "300  [FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...   \n",
       "400  [FOR, IMMEDIATE, RELEASE, Washington, D, C, To...   \n",
       "500  [FOR, IMMEDIATE, RELEASE, Washington, DC, Toda...   \n",
       "600  [FOR, IMMEDIATE, RELEASE, On, this, Veteran, s...   \n",
       "700  [FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...   \n",
       "800  [FOR, IMMEDIATE, RELEASE, Washington, DC, Toda...   \n",
       "900  [FOR, IMMEDIATE, RELEASE, WASHINGTON, D, C, Se...   \n",
       "\n",
       "                                     normalized_tokens  \n",
       "0    [immedi, releas, immedi, releas, contact, meli...  \n",
       "100  [immedi, releas, washington, dc, today, senat,...  \n",
       "200  [immedi, releas, immedi, releas, washington, c...  \n",
       "300  [immedi, releas, immedi, releas, surpris, amer...  \n",
       "400  [immedi, releas, washington, c, today, senat, ...  \n",
       "500  [immedi, releas, washington, dc, today, senat,...  \n",
       "600  [immedi, releas, veteran, day, america, stand,...  \n",
       "700  [immedi, releas, immedi, releas, mr, chairman,...  \n",
       "800  [immedi, releas, washington, dc, today, senat,...  \n",
       "900  [immedi, releas, washington, c, senat, edward,...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kenSampleDF['tokenized_text'] = kenSampleDF['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "kenSampleDF['normalized_tokens'] = kenSampleDF['tokenized_text'].apply(lambda x: lucem_illud.normalizeTokens(x, \n",
    "                                                                                                                            stopwordLst = lucem_illud.stop_words_basic, \n",
    "                                                                                                                            stemmer = lucem_illud.stemmer_basic))\n",
    "kenSampleDF[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kenSampleDF['likelihood'] = kenSampleDF['normalized_tokens'].apply(lambda x: adprob(x, trump2_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the two dataframes into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [whSampleDF, kenSampleDF]\n",
    "combineDF = pandas.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>download_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>name</th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>targetSenator</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>normalized_tokens</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Apr2007Whitehouse123.txt</td>\n",
       "      <td>raw/Whitehouse/10Apr2007Whitehouse123.txt</td>\n",
       "      <td>SEN. WHITEHOUSE SHARES WESTERLY GIRL'S STORY I...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[SEN., WHITEHOUSE, SHARES, WESTERLY, GIRL, 'S,...</td>\n",
       "      <td>[whitehous, share, wester, girl, stori, push, ...</td>\n",
       "      <td>-26.037243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>28Feb2007Whitehouse143.txt</td>\n",
       "      <td>raw/Whitehouse/28Feb2007Whitehouse143.txt</td>\n",
       "      <td>SEN. WHITEHOUSE PROTESTS FIRINGS OF FEDERAL PR...</td>\n",
       "      <td>Whitehouse</td>\n",
       "      <td>[SEN., WHITEHOUSE, PROTESTS, FIRINGS, OF, FEDE...</td>\n",
       "      <td>[whitehous, protest, fire, feder, prosecutor, ...</td>\n",
       "      <td>-26.885695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>01Jun2006Kennedy8.txt</td>\n",
       "      <td>raw/Kennedy/01Jun2006Kennedy8.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     John Joseph...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, John, Joseph, Moakle...</td>\n",
       "      <td>[immedi, releas, john, joseph, moakley, unit, ...</td>\n",
       "      <td>-26.087322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>03Aug2006Kennedy4.txt</td>\n",
       "      <td>raw/Kennedy/03Aug2006Kennedy4.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...</td>\n",
       "      <td>[immedi, releas, immedi, releas, washington, c...</td>\n",
       "      <td>-26.160362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>239</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>05Dec2007Kennedy0.txt</td>\n",
       "      <td>raw/Kennedy/05Dec2007Kennedy0.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE     BOSTON   Se...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, BOSTON, Senators, Jo...</td>\n",
       "      <td>[immedi, releas, boston, senat, john, kerri, e...</td>\n",
       "      <td>-24.966494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>339</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>07Dec2006Kennedy5.txt</td>\n",
       "      <td>raw/Kennedy/07Dec2006Kennedy5.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Mr  President ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Mr, President, it, w...</td>\n",
       "      <td>[immedi, releas, mr, presid, would, hard, unde...</td>\n",
       "      <td>-25.484913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>439</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>08Nov2007Kennedy11.txt</td>\n",
       "      <td>raw/Kennedy/08Nov2007Kennedy11.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   Last night th...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Last, night, the, Ho...</td>\n",
       "      <td>[immedi, releas, last, night, hous, pass, empl...</td>\n",
       "      <td>-24.341925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>539</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>10Jan2007Kennedy1.txt</td>\n",
       "      <td>raw/Kennedy/10Jan2007Kennedy1.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  WASHINGTON  DC...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, WASHINGTON, DC, Toda...</td>\n",
       "      <td>[immedi, releas, washington, dc, today, senat,...</td>\n",
       "      <td>-26.127432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>639</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>12Feb2007Kennedy2.txt</td>\n",
       "      <td>raw/Kennedy/12Feb2007Kennedy2.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Legislation Wi...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Legislation, Will, B...</td>\n",
       "      <td>[immedi, releas, legisl, build, landmark, pari...</td>\n",
       "      <td>-25.694458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>739</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>14Dec2006Kennedy6.txt</td>\n",
       "      <td>raw/Kennedy/14Dec2006Kennedy6.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Washington  D ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Washington, D, C, To...</td>\n",
       "      <td>[immedi, releas, washington, c, today, senat, ...</td>\n",
       "      <td>-23.214924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>839</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>15May2006Kennedy3.txt</td>\n",
       "      <td>raw/Kennedy/15May2006Kennedy3.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE   FOR IMMEDIATE...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...</td>\n",
       "      <td>[immedi, releas, immedi, releas, contact, meli...</td>\n",
       "      <td>-25.844755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>https://raw.githubusercontent.com/lintool/Grim...</td>\n",
       "      <td>https://github.com/lintool/GrimmerSenatePressR...</td>\n",
       "      <td>17Jan2007Kennedy1.txt</td>\n",
       "      <td>raw/Kennedy/17Jan2007Kennedy1.txt</td>\n",
       "      <td>FOR IMMEDIATE RELEASE  Washington  D ...</td>\n",
       "      <td>Kennedy</td>\n",
       "      <td>[FOR, IMMEDIATE, RELEASE, Washington, D, C, To...</td>\n",
       "      <td>[immedi, releas, washington, c, today, senat, ...</td>\n",
       "      <td>-25.983152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                       download_url  \\\n",
       "0             0  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "100         100  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "38           38  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "138         139  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "238         239  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "338         339  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "438         439  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "538         539  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "638         639  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "738         739  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "838         839  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "938         939  https://raw.githubusercontent.com/lintool/Grim...   \n",
       "\n",
       "                                              html_url  \\\n",
       "0    https://github.com/lintool/GrimmerSenatePressR...   \n",
       "100  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "38   https://github.com/lintool/GrimmerSenatePressR...   \n",
       "138  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "238  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "338  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "438  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "538  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "638  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "738  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "838  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "938  https://github.com/lintool/GrimmerSenatePressR...   \n",
       "\n",
       "                           name                                       path  \\\n",
       "0    10Apr2007Whitehouse123.txt  raw/Whitehouse/10Apr2007Whitehouse123.txt   \n",
       "100  28Feb2007Whitehouse143.txt  raw/Whitehouse/28Feb2007Whitehouse143.txt   \n",
       "38        01Jun2006Kennedy8.txt          raw/Kennedy/01Jun2006Kennedy8.txt   \n",
       "138       03Aug2006Kennedy4.txt          raw/Kennedy/03Aug2006Kennedy4.txt   \n",
       "238       05Dec2007Kennedy0.txt          raw/Kennedy/05Dec2007Kennedy0.txt   \n",
       "338       07Dec2006Kennedy5.txt          raw/Kennedy/07Dec2006Kennedy5.txt   \n",
       "438      08Nov2007Kennedy11.txt         raw/Kennedy/08Nov2007Kennedy11.txt   \n",
       "538       10Jan2007Kennedy1.txt          raw/Kennedy/10Jan2007Kennedy1.txt   \n",
       "638       12Feb2007Kennedy2.txt          raw/Kennedy/12Feb2007Kennedy2.txt   \n",
       "738       14Dec2006Kennedy6.txt          raw/Kennedy/14Dec2006Kennedy6.txt   \n",
       "838       15May2006Kennedy3.txt          raw/Kennedy/15May2006Kennedy3.txt   \n",
       "938       17Jan2007Kennedy1.txt          raw/Kennedy/17Jan2007Kennedy1.txt   \n",
       "\n",
       "                                                  text targetSenator  \\\n",
       "0    SEN. WHITEHOUSE SHARES WESTERLY GIRL'S STORY I...    Whitehouse   \n",
       "100  SEN. WHITEHOUSE PROTESTS FIRINGS OF FEDERAL PR...    Whitehouse   \n",
       "38            FOR IMMEDIATE RELEASE     John Joseph...       Kennedy   \n",
       "138           FOR IMMEDIATE RELEASE  FOR IMMEDIATE ...       Kennedy   \n",
       "238           FOR IMMEDIATE RELEASE     BOSTON   Se...       Kennedy   \n",
       "338           FOR IMMEDIATE RELEASE  Mr  President ...       Kennedy   \n",
       "438           FOR IMMEDIATE RELEASE   Last night th...       Kennedy   \n",
       "538           FOR IMMEDIATE RELEASE  WASHINGTON  DC...       Kennedy   \n",
       "638           FOR IMMEDIATE RELEASE  Legislation Wi...       Kennedy   \n",
       "738           FOR IMMEDIATE RELEASE  Washington  D ...       Kennedy   \n",
       "838           FOR IMMEDIATE RELEASE   FOR IMMEDIATE...       Kennedy   \n",
       "938           FOR IMMEDIATE RELEASE  Washington  D ...       Kennedy   \n",
       "\n",
       "                                        tokenized_text  \\\n",
       "0    [SEN., WHITEHOUSE, SHARES, WESTERLY, GIRL, 'S,...   \n",
       "100  [SEN., WHITEHOUSE, PROTESTS, FIRINGS, OF, FEDE...   \n",
       "38   [FOR, IMMEDIATE, RELEASE, John, Joseph, Moakle...   \n",
       "138  [FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...   \n",
       "238  [FOR, IMMEDIATE, RELEASE, BOSTON, Senators, Jo...   \n",
       "338  [FOR, IMMEDIATE, RELEASE, Mr, President, it, w...   \n",
       "438  [FOR, IMMEDIATE, RELEASE, Last, night, the, Ho...   \n",
       "538  [FOR, IMMEDIATE, RELEASE, WASHINGTON, DC, Toda...   \n",
       "638  [FOR, IMMEDIATE, RELEASE, Legislation, Will, B...   \n",
       "738  [FOR, IMMEDIATE, RELEASE, Washington, D, C, To...   \n",
       "838  [FOR, IMMEDIATE, RELEASE, FOR, IMMEDIATE, RELE...   \n",
       "938  [FOR, IMMEDIATE, RELEASE, Washington, D, C, To...   \n",
       "\n",
       "                                     normalized_tokens  likelihood  \n",
       "0    [whitehous, share, wester, girl, stori, push, ...  -26.037243  \n",
       "100  [whitehous, protest, fire, feder, prosecutor, ...  -26.885695  \n",
       "38   [immedi, releas, john, joseph, moakley, unit, ...  -26.087322  \n",
       "138  [immedi, releas, immedi, releas, washington, c...  -26.160362  \n",
       "238  [immedi, releas, boston, senat, john, kerri, e...  -24.966494  \n",
       "338  [immedi, releas, mr, presid, would, hard, unde...  -25.484913  \n",
       "438  [immedi, releas, last, night, hous, pass, empl...  -24.341925  \n",
       "538  [immedi, releas, washington, dc, today, senat,...  -26.127432  \n",
       "638  [immedi, releas, legisl, build, landmark, pari...  -25.694458  \n",
       "738  [immedi, releas, washington, c, today, senat, ...  -23.214924  \n",
       "838  [immedi, releas, immedi, releas, contact, meli...  -25.844755  \n",
       "938  [immedi, releas, washington, c, today, senat, ...  -25.983152  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combineDF[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the likelihood for different senators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>targetSenator</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kennedy</th>\n",
       "      <td>-25.089513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Whitehouse</th>\n",
       "      <td>-26.141903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               likelihood\n",
       "targetSenator            \n",
       "Kennedy        -25.089513\n",
       "Whitehouse     -26.141903"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combineDF.groupby(\"targetSenator\")[['likelihood']].mean().sort_values('likelihood', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of Kennedy senator is slightly higher than the White House senator. Therefore, we can say that discourses of different senators didn't show significant difference. But the discourse of Kennedy senators are more consistent with Trump's discourse, compare to White house senators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is code that aligns the dimensions of multiple embeddings arrayed over time or some other dimension and allow identification of semantic chanage as the word vectors change their loadings for focal words. This code comes from the approach piloted at Stanford by William Hamilton, Daniel Jurafsky and Jure Lescovec [here](https://arxiv.org/pdf/1605.09096.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_syn0norm(model):\n",
    "    \"\"\"since syn0norm is now depricated\"\"\"\n",
    "    return (model.wv.syn0 / np.sqrt((model.wv.syn0 ** 2).sum(-1))[..., np.newaxis]).astype(np.float32)\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"Procrustes align two gensim word2vec models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "    (With help from William. Thank you!)\n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "    base_embed = copy.copy(base_embed)\n",
    "    other_embed = copy.copy(other_embed)\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "\n",
    "    # get the embedding matrices\n",
    "    base_vecs = calc_syn0norm(in_base_embed)\n",
    "    other_vecs = calc_syn0norm(in_other_embed)\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one\n",
    "    # i.e. multiplying the embedding matrix (syn0norm)by \"ortho\"\n",
    "    other_embed.wv.syn0norm = other_embed.wv.syn0 = (calc_syn0norm(other_embed)).dot(ortho)\n",
    "    return other_embed\n",
    "    \n",
    "def intersection_align_gensim(m1,m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim word2vec models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.vocab.keys())\n",
    "    vocab_m2 = set(m2.wv.vocab.keys())\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1&vocab_m2\n",
    "    if words: common_vocab&=set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1-common_vocab and not vocab_m2-common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.vocab[w].count + m2.wv.vocab[w].count,reverse=True)\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1,m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.vocab[w].index for w in common_vocab]\n",
    "        old_arr = calc_syn0norm(m)\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.syn0norm = m.wv.syn0 = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        m.index2word = common_vocab\n",
    "        old_vocab = m.wv.vocab\n",
    "        new_vocab = {}\n",
    "        for new_index,word in enumerate(common_vocab):\n",
    "            old_vocab_obj=old_vocab[word]\n",
    "            new_vocab[word] = gensim.models.word2vec.Vocab(index=new_index, count=old_vocab_obj.count)\n",
    "        m.wv.vocab = new_vocab\n",
    "\n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explore this, let's get some data that follows a time trend. We'll look at conference proceedings from the American Society for Clinical Oncologists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data/ASCO_abstracts.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4c852513e040>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mascoDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/ASCO_abstracts.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'../data/ASCO_abstracts.csv' does not exist"
     ]
    }
   ],
   "source": [
    "ascoDF = pandas.read_csv(\"../data/ASCO_abstracts.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for wor2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ascoDF['tokenized_sents'] = ascoDF['Body'].apply(lambda x: [nltk.word_tokenize(s) for s in nltk.sent_tokenize(x)])\n",
    "ascoDF['normalized_sents'] = ascoDF['tokenized_sents'].apply(lambda x: [lucem_illud.normalizeTokens(s, stopwordLst = lucem_illud.stop_words_basic) for s in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating many embeddings so we have created this function to do most of the work. It creates two collections of embeddings, one the original and one the aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compareModels(df, category, sort = True):\n",
    "    \"\"\"If you are using time as your category sorting is important\"\"\"\n",
    "    embeddings_raw = {}\n",
    "    cats = sorted(set(df[category]))\n",
    "    for cat in cats:\n",
    "        #This can take a while\n",
    "        print(\"Embedding {}\".format(cat), end = '\\r')\n",
    "        subsetDF = df[df[category] == cat]\n",
    "        #You might want to change the W2V parameters\n",
    "        embeddings_raw[cat] = gensim.models.word2vec.Word2Vec(subsetDF['normalized_sents'].sum())\n",
    "    #These are much quicker\n",
    "    embeddings_aligned = {}\n",
    "    for catOuter in cats:\n",
    "        embeddings_aligned[catOuter] = [embeddings_raw[catOuter]]\n",
    "        for catInner in cats:\n",
    "            embeddings_aligned[catOuter].append(smart_procrustes_align_gensim(embeddings_aligned[catOuter][-1], embeddings_raw[catInner]))\n",
    "    return embeddings_raw, embeddings_aligned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we generate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawEmbeddings, comparedEmbeddings = compareModels(ascoDF, 'Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compare them across all permutions so we will define another function to help, we will be using 1 - cosine similarity as that gives a more intitive range of 0-2 with low values meaning little change and high meaning lots of change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDivergenceDF(word, embeddingsDict):\n",
    "    dists = []\n",
    "    cats = sorted(set(embeddingsDict.keys()))\n",
    "    dists = {}\n",
    "    for cat in cats:\n",
    "        dists[cat] = []\n",
    "        for embed in embeddingsDict[cat][1:]:\n",
    "            dists[cat].append(np.abs(1 - sklearn.metrics.pairwise.cosine_similarity(embeddingsDict[cat][0][word],\n",
    "                                                                             embed[word])[0,0]))\n",
    "    return pandas.DataFrame(dists, index = cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at a couple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetWord = 'breast'\n",
    "\n",
    "pltDF = getDivergenceDF(targetWord, comparedEmbeddings)\n",
    "fig, ax = plt.subplots(figsize = (10, 7))\n",
    "seaborn.heatmap(pltDF, ax = ax, annot = False) #set annot True for a lot more information\n",
    "ax.set_xlabel(\"Starting year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_title(\"Yearly linguistic change for: '{}'\".format(targetWord))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetWord = 'triple'\n",
    "\n",
    "pltDF = getDivergenceDF(targetWord, comparedEmbeddings)\n",
    "fig, ax = plt.subplots(figsize = (10, 7))\n",
    "seaborn.heatmap(pltDF, ax = ax, annot = False) #set annot True for a lot more information\n",
    "ax.set_xlabel(\"Starting year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_title(\"Yearly linguistic change for: '{}'\".format(targetWord))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask which words changed the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findDiverence(word, embeddingsDict):\n",
    "    cats = sorted(set(embeddingsDict.keys()))\n",
    "    \n",
    "    dists = []\n",
    "    for embed in embeddingsDict[cats[0]][1:]:\n",
    "        dists.append(1 - sklearn.metrics.pairwise.cosine_similarity(embeddingsDict[cats[0]][0][word], embed[word])[0,0])\n",
    "    return sum(dists)\n",
    "\n",
    "def findMostDivergent(embeddingsDict):\n",
    "    words = []\n",
    "    for embeds in embeddingsDict.values():\n",
    "        for embed in embeds:\n",
    "            words += list(embed.wv.vocab.keys())\n",
    "    words = set(words)\n",
    "    print(\"Found {} words to compare\".format(len(words)))\n",
    "    return sorted([(w, findDiverence(w, embeddingsDict)) for w in words], key = lambda x: x[1], reverse=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordDivergences = findMostDivergent(comparedEmbeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most divergent words are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordDivergences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordDivergences[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetWord = wordDivergences[0][0]\n",
    "\n",
    "pltDF = getDivergenceDF(targetWord, comparedEmbeddings)\n",
    "fig, ax = plt.subplots(figsize = (10, 7))\n",
    "seaborn.heatmap(pltDF, ax = ax, annot = False) #set annot True for a lot more information\n",
    "ax.set_xlabel(\"Starting year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_title(\"Yearly linguistic change for: '{}'\".format(targetWord))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetWord = wordDivergences[-1][0]\n",
    "\n",
    "pltDF = getDivergenceDF(targetWord, comparedEmbeddings)\n",
    "fig, ax = plt.subplots(figsize = (10, 7))\n",
    "seaborn.heatmap(pltDF, ax = ax, annot = False) #set annot True for a lot more information\n",
    "ax.set_xlabel(\"Starting year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_ylabel(\"Final year\")\n",
    "ax.set_title(\"Yearly linguistic change for: '{}'\".format(targetWord))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 3b*</span>\n",
    "\n",
    "<span style=\"color:red\">**Do only 3a or 3b.** Construct cells immediately below this that align word embeddings over time or across domains/corpora. Interrogate the spaces that result and ask which words changed most and least over the entire period or between contexts/corpora. What does this reveal about the social game underlying your space? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump2_model  = gensim.models.word2vec.Word2Vec.load('../4-Word-Embedding/trumpW2V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = trump2_model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
