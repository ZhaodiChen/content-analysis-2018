{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 - Retreiving and Preparing Text for Machines\n",
    "\n",
    "This week, we begin by \"begging, borrowing and stealing\" text from several\n",
    "contexts of human communication (e.g., PDFs, HTML, Word) and preparing it for\n",
    "machines to \"read\" and analyze. This notebook outlines scraping text from the\n",
    "web, PDF and Word documents. Then we detail \"spidering\" or walking\n",
    "through hyperlinks to build samples of online content, and using APIs,\n",
    "Application Programming Interfaces, provided by webservices to access their\n",
    "content. Along the way, we will use regular expressions, outlined in the\n",
    "reading, to remove unwanted formatting and ornamentation. Finally, we discuss\n",
    "various text encodings, filtering and data structures in which text can be\n",
    "placed for analysis.\n",
    "\n",
    "For this notebook we will be using the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Special module written for this class\n",
    "#This provides access to data and to helper functions from previous weeks\n",
    "import lucem_illud #pip install git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "import requests #for http requests\n",
    "import bs4 #called `beautifulsoup4`, an html parser\n",
    "import pandas #gives us DataFrames\n",
    "import docx #reading MS doc files, install as `python-docx`\n",
    "\n",
    "#Stuff for pdfs\n",
    "#Install as `pdfminer2`\n",
    "import pdfminer.pdfinterp\n",
    "import pdfminer.converter\n",
    "import pdfminer.layout\n",
    "import pdfminer.pdfpage\n",
    "\n",
    "#These come with Python\n",
    "import re #for regexs\n",
    "import urllib.parse #For joining urls\n",
    "import io #for making http requests look like files\n",
    "import json #For Tumblr API responses\n",
    "import os.path #For checking if files exist\n",
    "import os #For making directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be working on the following files/urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "example_text_file = 'sometextfile.txt'\n",
    "information_extraction_pdf = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/Content%20Analysis%2018.pdf'\n",
    "example_docx = 'https://github.com/Computational-Content-Analysis-2018/Data-Files/raw/master/1-intro/macs6000_connecting_to_midway.docx'\n",
    "example_docx_save = 'example.docx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "Before we can start analyzing content we need to obtain it. Sometimes it will be\n",
    "provided to us from a pre-curated text archive, but sometimes we will need to\n",
    "download it. As a starting example we will attempt to download the wikipedia\n",
    "page on content analysis. The page is located at [https://en.wikipedia.org/wiki/\n",
    "Content_analysis](https://en.wikipedia.org/wiki/Content_analysis) so lets start\n",
    "with that.\n",
    "\n",
    "We can do this by making an HTTP GET request to that url, a GET request is\n",
    "simply a request to the server to provide the contents given by some url. The\n",
    "other request we will be using in this class is called a POST request and\n",
    "requests the server to take some content we provide. While the Python standard\n",
    "library does have the ability do make GET requests we will be using the\n",
    "[_requests_](http://docs.python-requests.org/en/master/) package as it is _'the\n",
    "only Non-GMO HTTP library for Python'_...also it provides a nicer interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_content_analysis = 'https://en.wikipedia.org/wiki/Content_analysis'\n",
    "requests.get(wikipedia_content_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`'Response [200]'` means the server responded with what we asked for. If you get\n",
    "another number (e.g. 404) it likely means there was some kind of error, these\n",
    "codes are called HTTP response codes and a list of them can be found\n",
    "[here](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). The response\n",
    "object contains all the data the server sent including the website's contents\n",
    "and the HTTP header. We are interested in the contents which we can access with\n",
    "the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Content analysis - Wikipedia</title>\n",
      "<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n",
      "<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Content_analysis\",\"wgTitle\":\"Content analysis\",\"wgCurRevisionId\":818592713,\"wgRevisionId\":818592713,\"wgArticleId\":473317,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Articles needing cleanup from April 2008\",\"All pages needing cleanup\",\"Cleanup tagged articles without a reason field from April 2008\",\"Wikipedia pages needing cleanup from April 2008\",\"Articles needing expert attention with no reason or talk parameter\",\"Articles needing expert attention from April 2008\",\"All articles\n"
     ]
    }
   ],
   "source": [
    "wikiContentRequest = requests.get(wikipedia_content_analysis)\n",
    "print(wikiContentRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not what we were looking for, because it is the start of the HTML that\n",
    "makes up the website. This is HTML and is meant to be read by computers. Luckily\n",
    "we have a computer to parse it for us. To do the parsing we will use [_Beautiful\n",
    "Soup_](https://www.crummy.com/software/BeautifulSoup/) which is a better parser\n",
    "than the one in the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Content analysis - Wikipedia\n",
      "document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );\n",
      "(window.RLQ=window.RLQ||[]).push(functio\n"
     ]
    }
   ],
   "source": [
    "wikiContentSoup = bs4.BeautifulSoup(wikiContentRequest.text, 'html.parser')\n",
    "print(wikiContentSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better but there's still random whitespace and we have more than just\n",
    "the text of the article. This is because what we requested is the whole webpage,\n",
    "not just the text for the article.\n",
    "\n",
    "We want to extract only the text we care about, and in order to do this we will\n",
    "need to inspect the html. One way to do this is simply to go to the website with\n",
    "a browser and use its inspection or view source tool. If javascript or other\n",
    "dynamic loading occurs on the page, however, it is likely that what Python\n",
    "receives is not what you will see, so we will need to inspect what Python\n",
    "receives. To do this we can save the html `requests` obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#content_analysis_save = 'wikipedia_content_analysis.html'\n",
    "\n",
    "with open(content_analysis_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiContentRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets open the file (`wikipedia_content_analysis.html`) we just created with\n",
    "a web browser. It should look sort of like the original but without the images\n",
    "and formatting.\n",
    "\n",
    "As there is very little standardization on structuring webpages, figuring out\n",
    "how best to extract what you want is an art. Looking at this page it looks like\n",
    "all the main textual content is inside `<p>`(paragraph) tags within the `<body>`\n",
    "tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Content analysis is a research method for studying documents and communication artifacts, which can be texts of various formats, pictures, audio or video. Social scientists use content analysis to quantify patterns in communication, in a replicable and systematic manner.[1] One of the key advantage of this research method is to analyse social phenomena in a non-invasive way, in contrast to simulating social experiences or collecting survey answers.\n",
      "Practices and philosophies of content analysis vary between scholarly communities. They all involve systematic reading or observation of texts or artifacts which are assigned labels (sometimes called codes) to indicate the presence of interesting, meaningful patterns.[2][3] After labeling a large set of media, a researcher is able to statistically estimate the proportions of patterns in the texts, as well as correlations between patterns.\n",
      "Computers are increasingly used in content analysis, to automate the labeling (or coding) of documents. Simple computational techniques can provide descriptive data such as word frequencies and document lengths. Machine learning classifiers can greatly increase the number of texts which can be labeled, but the scientific utility of doing so is a matter of debate.\n"
     ]
    }
   ],
   "source": [
    "contentPTags = wikiContentSoup.body.findAll('p')\n",
    "for pTag in contentPTags[:3]:\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the text from the page, split up by paragraph. If we wanted to\n",
    "get the section headers or references as well it would require a bit more work,\n",
    "but is doable.\n",
    "\n",
    "There is one more thing we might want to do before sending this text to be\n",
    "processed, remove the references indicators (`[2]`, `[3]` , etc). To do this we\n",
    "can use a short regular expression (regex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       paragraph-text\n",
      "0   \\nContent analysis is a research method for st...\n",
      "1   Practices and philosophies of content analysis...\n",
      "2   Computers are increasingly used in content ana...\n",
      "3                                                    \n",
      "4                                                    \n",
      "5   Content analysis is best understood as a broad...\n",
      "6   The simplest and most objective form of conten...\n",
      "7   A further step in analysis is the distinction ...\n",
      "8   More generally, content analysis is research u...\n",
      "9   By having contents of communication available ...\n",
      "10  Robert Weber notes: \"To make valid inferences ...\n",
      "11  There are five types of texts in content analy...\n",
      "12  Over the years, content analysis has been appl...\n",
      "13  In recent times, particularly with the advent ...\n",
      "14  Quantitative content analysis has enjoyed a re...\n",
      "15  Recently, Arash Heydarian Pashakhanlou has arg...\n",
      "16  Content analysis can also be described as stud...\n",
      "17  The method of content analysis enables the res...\n",
      "18  Since the 1980s, content analysis has become a...\n",
      "19  The creation of coding frames is intrinsically...\n",
      "20  Mimetic Convergence aims to show the process o...\n",
      "21  Every content analysis should depart from a hy...\n",
      "22  As an evaluation approach, content analysis is...\n",
      "23  Qualitative content analysis is \"a systematic,...\n",
      "24  Holsti groups fifteen uses of content analysis...\n",
      "25  He also places these uses into the context of ...\n",
      "26  The following table shows fifteen uses of cont...\n",
      "27                                                   \n"
     ]
    }
   ],
   "source": [
    "contentParagraphs = []\n",
    "for pTag in contentPTags:\n",
    "    #strings starting with r are raw so their \\'s are not modifier characters\n",
    "    #If we didn't start with r the string would be: '\\\\[\\\\d+\\\\]'\n",
    "    contentParagraphs.append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "\n",
    "#convert to a DataFrame\n",
    "contentParagraphsDF = pandas.DataFrame({'paragraph-text' : contentParagraphs})\n",
    "print(contentParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataFrame` containing all relevant text from the page ready to be\n",
    "processed\n",
    "\n",
    "If you are not familiar with regex, it is a way of specifying searches in text.\n",
    "A regex engine takes in the search pattern, in the above case `'\\[\\d+\\]'` and\n",
    "some string, the paragraph texts. Then it reads the input string one character\n",
    "at a time checking if it matches the search. Here the regex `'\\d'` matches\n",
    "number characters (while `'\\['` and `'\\]'` capture the braces on either side)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(36, 37), match='2'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findNumber = r'\\d'\n",
    "regexResults = re.search(findNumber, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "regexResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python the regex package (`re`) usually returns `Match` objects (you can have\n",
    "multiple pattern hits in a a single `Match`), to get the string that matched our\n",
    "pattern we can use the `.group()` method, and as we want the first one we will\n",
    "ask for the 0'th group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us the first number, if we wanted the whole block of numbers we can\n",
    "add a wildcard `'+'` which requests 1 or more instances of the preceding\n",
    "character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134567890\n"
     ]
    }
   ],
   "source": [
    "findNumbers = r'\\d+'\n",
    "regexResults = re.search(findNumbers, 'not a number, not a number, numbers 2134567890, not a number')\n",
    "print(regexResults.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the whole block of numbers, there are a huge number of special\n",
    "characters in regex, for the full description of Python's implementation look at\n",
    "the [re docs](https://docs.python.org/3/library/re.html) there is also a short\n",
    "[tutorial](https://docs.python.org/3/howto/regex.html#regex-howto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Section 1</span>\n",
    "<span style=\"color:red\">Construct cells immediately below this that describe and download webcontent relating to your anticipated final project. Use beautiful soup and at least five regular expressions to extract relevant, nontrivial *chunks* of that content (e.g., cleaned sentences, paragraphs, etc.) to a pandas `Dataframe`.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I will download webcontent about Marvel Comics from wikipedia. After extracting substantive textual content from it, I will convert it into pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "wikipedia_marvel_comics = 'https://en.wikipedia.org/wiki/Marvel_Comics'\n",
    "marvel_comics_save = 'wikipedia_marvel_comics.html'\n",
    "globalCity_pdf = 'http://journals.sagepub.com/doi/pdf/10.1177/0042098007085099'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wikipedia_marvel_comics = 'https://en.wikipedia.org/wiki/Marvel_Comics'\n",
    "requests.get(wikipedia_marvel_comics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>Marvel Comics - Wikipedia</title>\n",
      "<script>document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );</script>\n",
      "<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Marvel_Comics\",\"wgTitle\":\"Marvel Comics\",\"wgCurRevisionId\":819605028,\"wgRevisionId\":819605028,\"wgArticleId\":20966,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Webarchive template wayback links\",\"Use mdy dates from October 2012\",\"Pages using deprecated image syntax\",\"All articles with unsourced statements\",\"Articles with unsourced statements from April 2008\",\"Citation overkill\",\"Articles tagged with the inline citation overkill template from January 2018\",\"Articles with unsourced stat\n"
     ]
    }
   ],
   "source": [
    "wikiMarvelRequest = requests.get(wikipedia_marvel_comics)\n",
    "print(wikiMarvelRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request the content that are formatted as text from the target wiki website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Marvel Comics - Wikipedia\n",
      "document.documentElement.className = document.documentElement.className.replace( /(^|\\s)client-nojs(\\s|$)/, \"$1client-js$2\" );\n",
      "(window.RLQ=window.RLQ||[]).push(function()\n"
     ]
    }
   ],
   "source": [
    "wikiMarvelSoup = bs4.BeautifulSoup(wikiMarvelRequest.text, 'html.parser')\n",
    "print(wikiMarvelSoup.text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `BeautifulSoup` to parse the page. But still need to extract only the text I need, and in order to do this I will inspect the html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#marvel_comics_save = 'wikipedia_marvel_comics.html'\n",
    "\n",
    "with open(marvel_comics_save, mode='w', encoding='utf-8') as f:\n",
    "    f.write(wikiMarvelRequest.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the html `requests` obtained.\n",
    "\n",
    "Main textual content in this page are formatted as paragraphs `<p>` within the `<body>` tag. I want to get the content about the overall introduction and timely publications of Marvel Comics, so what I need is exactly paragraphs 1-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marvel Comics is the common name and primary imprint of Marvel Worldwide Inc., formerly Marvel Publishing, Inc. and Marvel Comics Group, a publisher of American comic books and related media. In 2009, The Walt Disney Company acquired Marvel Entertainment, Marvel Worldwide's parent company.\n",
      "Marvel started in 1939 as Timely Publications, and by the early 1950s, had generally become known as Atlas Comics. The Marvel branding began 1961, the year that the company launched The Fantastic Four and other superhero titles created by Stan Lee, Jack Kirby, Steve Ditko, and many others.\n",
      "Marvel counts among its characters such well-known superheroes as Spider-Man, Wolverine, the Hulk, Thor, Iron Man, Captain America and Daredevil, including such teams as the Avengers, the X-Men, the Guardians of the Galaxy, and the Fantastic Four, and antagonists such as Doctor Doom, the Red Skull, the Green Goblin, Magneto, and Loki. Most of Marvel's fictional characters operate in a single reality known as the Marvel Universe, with most locations mirroring real-life places; many major characters are based in New York City.[2][3]\n",
      "\n",
      "\n",
      "Pulp-magazine publisher Martin Goodman founded the company later known as Marvel Comics under the name Timely Publications in 1939.[4][5] Goodman, who had started with a Western pulp in 1933, was expanding into the emerging—and by then already highly popular—new medium of comic books. Launching his new line from his existing company's offices at 330 West 42nd Street, New York City, he officially held the titles of editor, managing editor, and business manager, with Abraham Goodman (Martin's brother)[6] officially listed as publisher.[5]\n",
      "Timely's first publication, Marvel Comics #1 (cover dated Oct. 1939), included the first appearance of Carl Burgos' android superhero the Human Torch, and the first appearances of Bill Everett's anti-hero Namor the Sub-Mariner,[7] among other features.[4] The issue was a great success; it and a second printing the following month sold a combined nearly 900,000 copies.[8] While its contents came from an outside packager, Funnies, Inc.,[4] Timely had its own staff in place by the following year. The company's first true editor, writer-artist Joe Simon, teamed with artist Jack Kirby to create one of the first patriotically themed superhero,[9] Captain America, in Captain America Comics #1 (March 1941). It, too, proved a hit, with sales of nearly one million.[8] Goodman formed Timely Comics, Inc., beginning with comics cover-dated April 1941 or Spring 1941.[10][11]\n",
      "While no other Timely character would achieve the success of these three characters, some notable heroes—many of which continue to appear in modern-day retcon appearances and flashbacks—include the Whizzer, Miss America, the Destroyer, the original Vision, and the Angel. Timely also published one of humor cartoonist Basil Wolverton's best-known features, \"Powerhouse Pepper\",[12][13] as well as a line of children's funny-animal comics featuring characters like Super Rabbit and the duo Ziggy Pig and Silly Seal.\n"
     ]
    }
   ],
   "source": [
    "marvelPTags = wikiMarvelSoup.body.findAll('p')\n",
    "for pTag in marvelPTags[:8]:\n",
    "    #print the first two parts: overall introduction and timely publication\n",
    "    print(pTag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got the substantive content from the page, split up by paragraph.\n",
    "\n",
    "However, this text contains some references indicators ([2],[3],etc) and puncuations (#). In order to extract relevant and nontrivial content, I am going to remove them using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Marvel Comics is the common name and primary imprint of Marvel Worldwide Inc., formerly Marvel Publishing, Inc. and Marvel Comics Group, a publisher of American comic books and related media. In 2009, The Walt Disney Company acquired Marvel Entertainment, Marvel Worldwide's parent company.\", 'Marvel Comics is the common name and primary imprint of Marvel Worldwide Inc   formerly Marvel Publishing  Inc  and Marvel Comics Group  a publisher of American comic books and related media  In 2009  The Walt Disney Company acquired Marvel Entertainment  Marvel Worldwide s parent company ', 'Marvel started in 1939 as Timely Publications, and by the early 1950s, had generally become known as Atlas Comics. The Marvel branding began 1961, the year that the company launched The Fantastic Four and other superhero titles created by Stan Lee, Jack Kirby, Steve Ditko, and many others.', 'Marvel started in 1939 as Timely Publications  and by the early 1950s  had generally become known as Atlas Comics  The Marvel branding began 1961  the year that the company launched The Fantastic Four and other superhero titles created by Stan Lee  Jack Kirby  Steve Ditko  and many others ', \"Marvel counts among its characters such well-known superheroes as Spider-Man, Wolverine, the Hulk, Thor, Iron Man, Captain America and Daredevil, including such teams as the Avengers, the X-Men, the Guardians of the Galaxy, and the Fantastic Four, and antagonists such as Doctor Doom, the Red Skull, the Green Goblin, Magneto, and Loki. Most of Marvel's fictional characters operate in a single reality known as the Marvel Universe, with most locations mirroring real-life places; many major characters are based in New York City.\", 'Marvel counts among its characters such well known superheroes as Spider Man  Wolverine  the Hulk  Thor  Iron Man  Captain America and Daredevil  including such teams as the Avengers  the X Men  the Guardians of the Galaxy  and the Fantastic Four  and antagonists such as Doctor Doom  the Red Skull  the Green Goblin  Magneto  and Loki  Most of Marvel s fictional characters operate in a single reality known as the Marvel Universe  with most locations mirroring real life places  many major characters are based in New York City  2  3 ', '', '', '', '', \"Pulp-magazine publisher Martin Goodman founded the company later known as Marvel Comics under the name Timely Publications in 1939. Goodman, who had started with a Western pulp in 1933, was expanding into the emerging—and by then already highly popular—new medium of comic books. Launching his new line from his existing company's offices at 330 West 42nd Street, New York City, he officially held the titles of editor, managing editor, and business manager, with Abraham Goodman (Martin's brother) officially listed as publisher.\", 'Pulp magazine publisher Martin Goodman founded the company later known as Marvel Comics under the name Timely Publications in 1939  4  5  Goodman  who had started with a Western pulp in 1933  was expanding into the emerging and by then already highly popular new medium of comic books  Launching his new line from his existing company s offices at 330 West 42nd Street  New York City  he officially held the titles of editor  managing editor  and business manager  with Abraham Goodman  Martin s brother  6  officially listed as publisher  5 ', \"Timely's first publication, Marvel Comics #1 (cover dated Oct. 1939), included the first appearance of Carl Burgos' android superhero the Human Torch, and the first appearances of Bill Everett's anti-hero Namor the Sub-Mariner, among other features. The issue was a great success; it and a second printing the following month sold a combined nearly 900,000 copies. While its contents came from an outside packager, Funnies, Inc., Timely had its own staff in place by the following year. The company's first true editor, writer-artist Joe Simon, teamed with artist Jack Kirby to create one of the first patriotically themed superhero, Captain America, in Captain America Comics #1 (March 1941). It, too, proved a hit, with sales of nearly one million. Goodman formed Timely Comics, Inc., beginning with comics cover-dated April 1941 or Spring 1941.\", 'Timely s first publication  Marvel Comics  1  cover dated Oct  1939   included the first appearance of Carl Burgos  android superhero the Human Torch  and the first appearances of Bill Everett s anti hero Namor the Sub Mariner  7  among other features  4  The issue was a great success  it and a second printing the following month sold a combined nearly 900 000 copies  8  While its contents came from an outside packager  Funnies  Inc   4  Timely had its own staff in place by the following year  The company s first true editor  writer artist Joe Simon  teamed with artist Jack Kirby to create one of the first patriotically themed superhero  9  Captain America  in Captain America Comics  1  March 1941   It  too  proved a hit  with sales of nearly one million  8  Goodman formed Timely Comics  Inc   beginning with comics cover dated April 1941 or Spring 1941  10  11 ', 'While no other Timely character would achieve the success of these three characters, some notable heroes—many of which continue to appear in modern-day retcon appearances and flashbacks—include the Whizzer, Miss America, the Destroyer, the original Vision, and the Angel. Timely also published one of humor cartoonist Basil Wolverton\\'s best-known features, \"Powerhouse Pepper\", as well as a line of children\\'s funny-animal comics featuring characters like Super Rabbit and the duo Ziggy Pig and Silly Seal.', 'While no other Timely character would achieve the success of these three characters  some notable heroes many of which continue to appear in modern day retcon appearances and flashbacks include the Whizzer  Miss America  the Destroyer  the original Vision  and the Angel  Timely also published one of humor cartoonist Basil Wolverton s best known features   Powerhouse Pepper   12  13  as well as a line of children s funny animal comics featuring characters like Super Rabbit and the duo Ziggy Pig and Silly Seal ', 'Goodman hired his wife\\'s cousin, Stanley Lieber, as a general office assistant in 1939. When editor Simon left the company in late 1941, Goodman made Lieber—by then writing pseudonymously as \"Stan Lee\"—interim editor of the comics line, a position Lee kept for decades except for three years during his military service in World War II. Lee wrote extensively for Timely, contributing to a number of different titles.', 'Goodman hired his wife s cousin  14  Stanley Lieber  as a general office assistant in 1939  15  When editor Simon left the company in late 1941  16  Goodman made Lieber by then writing pseudonymously as  Stan Lee  interim editor of the comics line  a position Lee kept for decades except for three years during his military service in World War II  Lee wrote extensively for Timely  contributing to a number of different titles ', 'Goodman\\'s business strategy involved having his various magazines and comic books published by a number of corporations all operating out of the same office and with the same staff. One of these shell companies through which Timely Comics was published was named Marvel Comics by at least Marvel Mystery Comics #55 (May 1944). As well, some comics\\' covers, such as All Surprise Comics #12 (Winter 1946–47), were labeled \"A Marvel Magazine\" many years before Goodman would formally adopt the name in 1961.', 'Goodman s business strategy involved having his various magazines and comic books published by a number of corporations all operating out of the same office and with the same staff  11  One of these shell companies through which Timely Comics was published was named Marvel Comics by at least Marvel Mystery Comics  55  May 1944   As well  some comics  covers  such as All Surprise Comics  12  Winter 1946 47   were labeled  A Marvel Magazine  many years before Goodman would formally adopt the name in 1961  17 ', \"The post-war American comic market saw superheroes falling out of fashion. Goodman's comic book line dropped them for the most part and expanded into a wider variety of genres than even Timely had published, featuring horror, Westerns, humor, funny animal, men's adventure-drama, giant monster, crime, and war comics, and later adding jungle books, romance titles, espionage, and even medieval adventure, Bible stories and sports.\", 'The post war American comic market saw superheroes falling out of fashion  18  Goodman s comic book line dropped them for the most part and expanded into a wider variety of genres than even Timely had published  featuring horror  Westerns  humor  funny animal  men s adventure drama  giant monster  crime  and war comics  and later adding jungle books  romance titles  espionage  and even medieval adventure  Bible stories and sports ', 'Goodman began using the globe logo of the Atlas News Company, the newsstand-distribution company he owned, on comics cover-dated November 1951 even though another company, Kable News, continued to distribute his comics through the August 1952 issues. This globe branding united a line put out by the same publisher, staff and freelancers through 59 shell companies, from Animirth Comics to Zenith Publications.', 'Goodman began using the globe logo of the Atlas News Company  the newsstand distribution company he owned  19  on comics cover dated November 1951 even though another company  Kable News  continued to distribute his comics through the August 1952 issues  20  This globe branding united a line put out by the same publisher  staff and freelancers through 59 shell companies  from Animirth Comics to Zenith Publications  21 ', \"Atlas, rather than innovate, took a proven route of following popular trends in television and movies—Westerns and war dramas prevailing for a time, drive-in movie monsters another time—and even other comic books, particularly the EC horror line. Atlas also published a plethora of children's and teen humor titles, including Dan DeCarlo's Homer the Happy Ghost (similar to Casper the Friendly Ghost) and Homer Hooper (à la Archie Andrews). Atlas unsuccessfully attempted to revive superheroes from late 1953 to mid-1954, with the Human Torch (art by Syd Shores and Dick Ayers, variously), the Sub-Mariner (drawn and most stories written by Bill Everett), and Captain America (writer Stan Lee, artist John Romita Sr.). Atlas did not achieve any breakout hits and, according to Stan Lee, Atlas survived chiefly because it produced work quickly, cheaply, and at a passable quality.\", 'Atlas  rather than innovate  took a proven route of following popular trends in television and movies Westerns and war dramas prevailing for a time  drive in movie monsters another time and even other comic books  particularly the EC horror line  22  Atlas also published a plethora of children s and teen humor titles  including Dan DeCarlo s Homer the Happy Ghost  similar to Casper the Friendly Ghost  and Homer Hooper  à la Archie Andrews   Atlas unsuccessfully attempted to revive superheroes from late 1953 to mid 1954  with the Human Torch  art by Syd Shores and Dick Ayers  variously   the Sub Mariner  drawn and most stories written by Bill Everett   and Captain America  writer Stan Lee  artist John Romita Sr    Atlas did not achieve any breakout hits and  according to Stan Lee  Atlas survived chiefly because it produced work quickly  cheaply  and at a passable quality  23 ', 'The first modern comic books under the Marvel Comics brand were the science-fiction anthology Journey into Mystery #69 and the teen-humor title Patsy Walker #95 (both cover dated June 1961), which each displayed an \"MC\" box on its cover. Then, in the wake of DC Comics\\' success in reviving superheroes in the late 1950s and early 1960s, particularly with the Flash, Green Lantern, and other members of the team the Justice League of America, Marvel followed suit.[n 1]', 'The first modern comic books under the Marvel Comics brand were the science fiction anthology Journey into Mystery  69 and the teen humor title Patsy Walker  95  both cover dated June 1961   which each displayed an  MC  box on its cover  24  Then  in the wake of DC Comics  success in reviving superheroes in the late 1950s and early 1960s  particularly with the Flash  Green Lantern  and other members of the team the Justice League of America  Marvel followed suit  n 1 ', \"In 1961, writer-editor Stan Lee revolutionized superhero comics by introducing superheroes designed to appeal to older readers than the predominantly child audiences of the medium. Modern Marvel's first superhero team, the titular stars of The Fantastic Four #1 (Nov. 1961), broke convention with other comic book archetypes of the time by squabbling, holding grudges both deep and petty, and eschewing anonymity or secret identities in favor of celebrity status. Subsequently, Marvel comics developed a reputation for focusing on characterization and adult issues to a greater extent than most superhero comics before them, a quality which the new generation of older readers appreciated. This applied to The Amazing Spider-Man title in particular, which turned out to be Marvel's most successful book. Its young hero suffered from self-doubt and mundane problems like any other teenager, something with which many readers could identify.\", 'In 1961  writer editor Stan Lee revolutionized superhero comics by introducing superheroes designed to appeal to older readers than the predominantly child audiences of the medium  Modern Marvel s first superhero team  the titular stars of The Fantastic Four  1  Nov  1961   25  broke convention with other comic book archetypes of the time by squabbling  holding grudges both deep and petty  and eschewing anonymity or secret identities in favor of celebrity status  Subsequently  Marvel comics developed a reputation for focusing on characterization and adult issues to a greater extent than most superhero comics before them  a quality which the new generation of older readers appreciated  26  This applied to The Amazing Spider Man title in particular  which turned out to be Marvel s most successful book  Its young hero suffered from self doubt and mundane problems like any other teenager  something with which many readers could identify ', 'Lee and freelance artist and eventual co-plotter Jack Kirby\\'s Fantastic Four originated in a Cold War culture that led their creators to revise the superhero conventions of previous eras to better reflect the psychological spirit of their age. Eschewing such comic-book tropes as secret identities and even costumes at first, having a monster as one of the heroes, and having its characters bicker and complain in what was later called a \"superheroes in the real world\" approach, the series represented a change that proved to be a great success.', 'Lee and freelance artist and eventual co plotter Jack Kirby s Fantastic Four originated in a Cold War culture that led their creators to revise the superhero conventions of previous eras to better reflect the psychological spirit of their age  27  Eschewing such comic book tropes as secret identities and even costumes at first  having a monster as one of the heroes  and having its characters bicker and complain in what was later called a  superheroes in the real world  approach  the series represented a change that proved to be a great success  28 ', 'Marvel often presented flawed superheroes, freaks, and misfits—unlike the perfect, handsome, athletic heroes found in previous traditional comic books. Some Marvel heroes looked like villains and monsters such as the Hulk and the Thing. This naturalistic approach even extended into topical politics.', 'Marvel often presented flawed superheroes  freaks  and misfits unlike the perfect  handsome  athletic heroes found in previous traditional comic books  Some Marvel heroes looked like villains and monsters such as the Hulk and the Thing  This naturalistic approach even extended into topical politics ', 'Comics historian Mike Benton also noted:', 'Comics historian Mike Benton also noted ', \"In the world of [rival DC Comics'] Superman comic books, communism did not exist. Superman rarely crossed national borders or involved himself in political disputes. From 1962 to 1965, there were more communists [in Marvel Comics] than on the subscription list of Pravda. Communist agents attack Ant-Man in his laboratory, red henchmen jump the Fantastic Four on the moon, and Viet Cong guerrillas take potshots at Iron Man.\", 'In the world of  rival DC Comics   Superman comic books  communism did not exist  Superman rarely crossed national borders or involved himself in political disputes  29  From 1962 to 1965  there were more communists  in Marvel Comics  than on the subscription list of Pravda  Communist agents attack Ant Man in his laboratory  red henchmen jump the Fantastic Four on the moon  and Viet Cong guerrillas take potshots at Iron Man  30 ', 'All of these elements struck a chord with the older readers, such as college-aged adults. In 1965, Spider-Man and the Hulk were both featured in Esquire magazine\\'s list of 28 college campus heroes, alongside John F. Kennedy and Bob Dylan. In 2009, writer Geoff Boucher reflected that, \"Superman and DC Comics instantly seemed like boring old Pat Boone; Marvel felt like The Beatles and the British Invasion. It was Kirby\\'s artwork with its tension and psychedelia that made it perfect for the times—or was it Lee\\'s bravado and melodrama, which was somehow insecure and brash at the same time?\"', 'All of these elements struck a chord with the older readers  such as college aged adults  In 1965  Spider Man and the Hulk were both featured in Esquire magazine s list of 28 college campus heroes  alongside John F  Kennedy and Bob Dylan  31  In 2009  writer Geoff Boucher reflected that   Superman and DC Comics instantly seemed like boring old Pat Boone  Marvel felt like The Beatles and the British Invasion  It was Kirby s artwork with its tension and psychedelia that made it perfect for the times or was it Lee s bravado and melodrama  which was somehow insecure and brash at the same time   32 ', 'In addition to Spider-Man and the Fantastic Four, Marvel began publishing further superhero titles featuring such heroes and antiheroes as the Hulk, Thor, Ant-Man, Iron Man, the X-Men, Daredevil, the Inhumans, Black Panther, Doctor Strange, Captain Marvel and the Silver Surfer, and such memorable antagonists as Doctor Doom, Magneto, Galactus, Loki, the Green Goblin, and Doctor Octopus, all existing in a shared reality known as the Marvel Universe, with locations that mirror real-life cities such as New York, Los Angeles and Chicago.', 'In addition to Spider Man and the Fantastic Four  Marvel began publishing further superhero titles featuring such heroes and antiheroes as the Hulk  Thor  Ant Man  Iron Man  the X Men  Daredevil  the Inhumans  Black Panther  Doctor Strange  Captain Marvel and the Silver Surfer  and such memorable antagonists as Doctor Doom  Magneto  Galactus  Loki  the Green Goblin  and Doctor Octopus  all existing in a shared reality known as the Marvel Universe  with locations that mirror real life cities such as New York  Los Angeles and Chicago ', 'Marvel even lampooned itself and other comics companies in a parody comic, Not Brand Echh (a play on Marvel\\'s dubbing of other companies as \"Brand Echh\", à la the then-common phrase \"Brand X\").', 'Marvel even lampooned itself and other comics companies in a parody comic  Not Brand Echh  a play on Marvel s dubbing of other companies as  Brand Echh   à la the then common phrase  Brand X    33 ', 'In 1968, while selling 50 million comic books a year, company founder Goodman revised the constraining distribution arrangement with Independent News he had reached under duress during the Atlas years, allowing him now to release as many titles as demand warranted. Late that year, he sold Marvel Comics and its parent company, Magazine Management, to the Perfect Film and Chemical Corporation, with Goodman remaining as publisher. In 1969, Goodman finally ended his distribution deal with Independent by signing with Curtis Circulation Company.', 'In 1968  while selling 50 million comic books a year  company founder Goodman revised the constraining distribution arrangement with Independent News he had reached under duress during the Atlas years  allowing him now to release as many titles as demand warranted  19  Late that year  he sold Marvel Comics and its parent company  Magazine Management  to the Perfect Film and Chemical Corporation  with Goodman remaining as publisher  34  In 1969  Goodman finally ended his distribution deal with Independent by signing with Curtis Circulation Company  19 ', \"In 1971, the United States Department of Health, Education, and Welfare approached Marvel Comics editor-in-chief Stan Lee to do a comic book story about drug abuse. Lee agreed and wrote a three-part Spider-Man story portraying drug use as dangerous and unglamorous. However, the industry's self-censorship board, the Comics Code Authority, refused to approve the story because of the presence of narcotics, deeming the context of the story irrelevant. Lee, with Goodman's approval, published the story regardless in The Amazing Spider-Man #96–98 (May–July 1971), without the Comics Code seal. The market reacted well to the storyline, and the CCA subsequently revised the Code the same year.\", 'In 1971  the United States Department of Health  Education  and Welfare approached Marvel Comics editor in chief Stan Lee to do a comic book story about drug abuse  Lee agreed and wrote a three part Spider Man story portraying drug use as dangerous and unglamorous  However  the industry s self censorship board  the Comics Code Authority  refused to approve the story because of the presence of narcotics  deeming the context of the story irrelevant  Lee  with Goodman s approval  published the story regardless in The Amazing Spider Man  96 98  May July 1971   without the Comics Code seal  The market reacted well to the storyline  and the CCA subsequently revised the Code the same year  35 ', 'Goodman retired as publisher in 1972 and installed his son, Chip, as publisher. Shortly thereafter, Lee succeeded him as publisher and also became Marvel\\'s president for a brief time. During his time as president, he appointed his associate editor, prolific writer Roy Thomas, as editor-in-chief. Thomas added \"Stan Lee Presents\" to the opening page of each comic book.', 'Goodman retired as publisher in 1972 and installed his son  Chip  as publisher  36  Shortly thereafter  Lee succeeded him as publisher and also became Marvel s president 36  for a brief time  37  During his time as president  he appointed his associate editor  prolific writer Roy Thomas  as editor in chief  Thomas added  Stan Lee Presents  to the opening page of each comic book  36 ', 'A series of new editors-in-chief oversaw the company during another slow time for the industry. Once again, Marvel attempted to diversify, and with the updating of the Comics Code published titles themed to horror (The Tomb of Dracula), martial arts (Shang-Chi: Master of Kung Fu), sword-and-sorcery (Conan the Barbarian, Red Sonja), satire (Howard the Duck) and science fiction (2001: A Space Odyssey, \"Killraven\" in Amazing Adventures, Battlestar Galactica, Star Trek, and, late in the decade, the long-running Star Wars series). Some of these were published in larger-format black and white magazines, under its Curtis Magazines imprint.', 'A series of new editors in chief oversaw the company during another slow time for the industry  Once again  Marvel attempted to diversify  and with the updating of the Comics Code published titles themed to horror  The Tomb of Dracula   martial arts  Shang Chi  Master of Kung Fu   sword and sorcery  Conan the Barbarian  Red Sonja   satire  Howard the Duck  and science fiction  2001  A Space Odyssey   Killraven  in Amazing Adventures  Battlestar Galactica  Star Trek  and  late in the decade  the long running Star Wars series   Some of these were published in larger format black and white magazines  under its Curtis Magazines imprint ', \"Marvel was able to capitalize on its successful superhero comics of the previous decade by acquiring a new newsstand distributor and greatly expanding its comics line. Marvel pulled ahead of rival DC Comics in 1972, during a time when the price and format of the standard newsstand comic were in flux. Goodman increased the price and size of Marvel's November 1971 cover-dated comics from 15 cents for 36 pages total to 25 cents for 52 pages. DC followed suit, but Marvel the following month dropped its comics to 20 cents for 36 pages, offering a lower-priced product with a higher distributor discount.\", 'Marvel was able to capitalize on its successful superhero comics of the previous decade by acquiring a new newsstand distributor and greatly expanding its comics line  Marvel pulled ahead of rival DC Comics in 1972  during a time when the price and format of the standard newsstand comic were in flux  38  Goodman increased the price and size of Marvel s November 1971 cover dated comics from 15 cents for 36 pages total to 25 cents for 52 pages  DC followed suit  but Marvel the following month dropped its comics to 20 cents for 36 pages  offering a lower priced product with a higher distributor discount  39 ', \"In 1973, Perfect Film and Chemical renamed itself as Cadence Industries and renamed Magazine Management as Marvel Comics Group. Goodman, now disconnected from Marvel, set up a new company called Seaboard Periodicals in 1974, reviving Marvel's old Atlas name for a new Atlas Comics line, but this lasted only a year and a half. In the mid-1970s a decline of the newsstand distribution network affected Marvel. Cult hits such as Howard the Duck fell victim to the distribution problems, with some titles reporting low sales when in fact the first specialty comic book stores resold them at a later date.[citation needed] But by the end of the decade, Marvel's fortunes were reviving, thanks to the rise of direct market distribution—selling through those same comics-specialty stores instead of newsstands.\", 'In 1973  Perfect Film and Chemical renamed itself as Cadence Industries and renamed Magazine Management as Marvel Comics Group  40  Goodman  now disconnected from Marvel  set up a new company called Seaboard Periodicals in 1974  reviving Marvel s old Atlas name for a new Atlas Comics line  but this lasted only a year and a half  41  In the mid 1970s a decline of the newsstand distribution network affected Marvel  Cult hits such as Howard the Duck fell victim to the distribution problems  with some titles reporting low sales when in fact the first specialty comic book stores resold them at a later date  citation needed  But by the end of the decade  Marvel s fortunes were reviving  thanks to the rise of direct market distribution selling through those same comics specialty stores instead of newsstands ', 'Marvel ventured into audio in 1975 with a radio series and a record, both had Stan Lee as narrator. The radio series was Fantastic Four. The record was Spider-Man: Rock Reflections of a Superhero concept album for music fans.', 'Marvel ventured into audio in 1975 with a radio series and a record  both had Stan Lee as narrator  The radio series was Fantastic Four  The record was Spider Man  Rock Reflections of a Superhero concept album for music fans  42 ', \"Marvel held its own comic book convention, Marvelcon '75, in spring 1975, and promised a Marvelcon '76. At the 1975 event, Stan Lee used a Fantastic Four panel discussion to announce that Jack Kirby, the artist co-creator of most of Marvel's signature characters, was returning to Marvel after having left in 1970 to work for rival DC Comics. In October 1976, Marvel, which already licensed reprints in different countries, including the UK, created a superhero specifically for the British market. Captain Britain debuted exclusively in the UK, and later appeared in American comics. During this time, Marvel and the Iowa-based Register and Tribune Syndicate launched a number of syndicated comic strips — The Amazing Spider-Man, Howard the Duck, Conan the Barbarian, and The Incredible Hulk. None of the strips lasted past 1982, except for The Amazing Spider-Man, which is still being published.\", 'Marvel held its own comic book convention  Marvelcon  75  in spring 1975  and promised a Marvelcon  76  At the 1975 event  Stan Lee used a Fantastic Four panel discussion to announce that Jack Kirby  the artist co creator of most of Marvel s signature characters  was returning to Marvel after having left in 1970 to work for rival DC Comics  44  In October 1976  Marvel  which already licensed reprints in different countries  including the UK  created a superhero specifically for the British market  Captain Britain debuted exclusively in the UK  and later appeared in American comics  45  During this time  Marvel and the Iowa based Register and Tribune Syndicate launched a number of syndicated comic strips   The Amazing Spider Man  Howard the Duck  Conan the Barbarian  and The Incredible Hulk  None of the strips lasted past 1982  except for The Amazing Spider Man  which is still being published ', \"In 1978, Jim Shooter became Marvel's editor-in-chief. Although a controversial personality, Shooter cured many of the procedural ills at Marvel, including repeatedly missed deadlines. During Shooter's nine-year tenure as editor-in-chief, Chris Claremont and John Byrne's run on the Uncanny X-Men and Frank Miller's run on Daredevil became critical and commercial successes. Shooter brought Marvel into the rapidly evolving direct market, institutionalized creator royalties, starting with the Epic Comics imprint for creator-owned material in 1982; introduced company-wide crossover story arcs with Contest of Champions and Secret Wars; and in 1986 launched the ultimately unsuccessful New Universe line to commemorate the 25th anniversary of the Marvel Comics imprint. Star Comics, a children-oriented line differing from the regular Marvel titles, was briefly successful during this period.\", 'In 1978  Jim Shooter became Marvel s editor in chief  Although a controversial personality  Shooter cured many of the procedural ills at Marvel  including repeatedly missed deadlines  During Shooter s nine year tenure as editor in chief  Chris Claremont and John Byrne s run on the Uncanny X Men and Frank Miller s run on Daredevil became critical and commercial successes  46  Shooter brought Marvel into the rapidly evolving direct market  47  institutionalized creator royalties  starting with the Epic Comics imprint for creator owned material in 1982  introduced company wide crossover story arcs with Contest of Champions and Secret Wars  and in 1986 launched the ultimately unsuccessful New Universe line to commemorate the 25th anniversary of the Marvel Comics imprint  Star Comics  a children oriented line differing from the regular Marvel titles  was briefly successful during this period ', \"Despite Marvel's successes in the early 1980s, it lost ground to rival DC in the latter half of the decade as many former Marvel stars defected to the competitor. DC scored critical and sales victories with titles and limited series such as Watchmen, Batman: The Dark Knight Returns, Crisis on Infinite Earths, Byrne's revamp of Superman, and Alan Moore's Swamp Thing.\", 'Despite Marvel s successes in the early 1980s  it lost ground to rival DC in the latter half of the decade as many former Marvel stars defected to the competitor  DC scored critical and sales victories 48  with titles and limited series such as Watchmen  Batman  The Dark Knight Returns  Crisis on Infinite Earths  Byrne s revamp of Superman  and Alan Moore s Swamp Thing ', \"In 1986, Marvel's parent, Marvel Entertainment Group, was sold to New World Entertainment, which within three years sold it to MacAndrews and Forbes, owned by Revlon executive Ronald Perelman in 1989. In 1991 Perelman took MEG public. Following the rapid rise of this stock, Perelman issued a series of junk bonds that he used to acquire other entertainment companies, secured by MEG stock.\", 'In 1986  Marvel s parent  Marvel Entertainment Group  was sold to New World Entertainment  which within three years sold it to MacAndrews and Forbes  owned by Revlon executive Ronald Perelman in 1989  In 1991 Perelman took MEG public  Following the rapid rise of this stock  Perelman issued a series of junk bonds that he used to acquire other entertainment companies  secured by MEG stock  49 ', \"Marvel earned a great deal of money with their 1980s children's comics imprint Star Comics and they earned a great deal more money and worldwide success during the comic book boom of the early 1990s, launching the successful 2099 line of comics set in the future (Spider-Man 2099, etc.) and the creatively daring though commercially unsuccessful Razorline imprint of superhero comics created by novelist and filmmaker Clive Barker. In 1990, Marvel began selling Marvel Universe Cards with trading card maker SkyBox International. These were collectible trading cards that featured the characters and events of the Marvel Universe. The 1990s saw the rise of variant covers, cover enhancements, swimsuit issues, and company-wide crossovers that affected the overall continuity of the Marvel Universe.\", 'Marvel earned a great deal of money with their 1980s children s comics imprint Star Comics and they earned a great deal more money and worldwide success during the comic book boom of the early 1990s  launching the successful 2099 line of comics set in the future  Spider Man 2099  etc   and the creatively daring though commercially unsuccessful Razorline imprint of superhero comics created by novelist and filmmaker Clive Barker  50  51  In 1990  Marvel began selling Marvel Universe Cards with trading card maker SkyBox International  These were collectible trading cards that featured the characters and events of the Marvel Universe  The 1990s saw the rise of variant covers  cover enhancements  swimsuit issues  and company wide crossovers that affected the overall continuity of the Marvel Universe ', \"Marvel suffered a blow in early 1992, when seven of its most prized artists — Todd McFarlane (known for his work on Spider-Man), Jim Lee (X-Men), Rob Liefeld (X-Force), Marc Silvestri (Wolverine), Erik Larsen (The Amazing Spider-Man), Jim Valentino (Guardians of the Galaxy), and Whilce Portacio (Uncanny X-Men) — left to form Image Comics in a deal brokered by Malibu Comics' owner Scott Mitchell Rosenberg. Three years later Rosenberg sold Malibu to Marvel on November 3, 1994,[excessive citations] who acquired the then-leading standard for computer coloring of comic books (developed by Rosenberg) in the process, but also integrating the Genesis Universe (Earth-1136) and the Ultraverse (Earth-93060) into Marvel's multiverse.\", 'Marvel suffered a blow in early 1992  when seven of its most prized artists   Todd McFarlane  known for his work on Spider Man   Jim Lee  X Men   Rob Liefeld  X Force   Marc Silvestri  Wolverine   Erik Larsen  The Amazing Spider Man   Jim Valentino  Guardians of the Galaxy   and Whilce Portacio  Uncanny X Men    left to form Image Comics 52  in a deal brokered by Malibu Comics  owner Scott Mitchell Rosenberg  53  Three years later Rosenberg sold Malibu to Marvel on November 3  1994  53  54  55  56  56  57  58  excessive citations  who acquired the then leading standard for computer coloring of comic books  developed by Rosenberg  in the process  59  but also integrating the Genesis Universe  Earth 1136  and the Ultraverse  Earth 93060  into Marvel s multiverse ', \"In late 1994, Marvel acquired the comic book distributor Heroes World Distribution to use as its own exclusive distributor. As the industry's other major publishers made exclusive distribution deals with other companies, the ripple effect resulted in the survival of only one other major distributor in North America, Diamond Comic Distributors Inc. Then, by the middle of the decade, the industry had slumped, and in December 1996 MEG filed for Chapter 11 bankruptcy protection. In early 1997, when Marvel's Heroes World endeavor failed, Diamond also forged an exclusive deal with Marvel—giving the company its own section of its comics catalog Previews.\", 'In late 1994  Marvel acquired the comic book distributor Heroes World Distribution to use as its own exclusive distributor  60  As the industry s other major publishers made exclusive distribution deals with other companies  the ripple effect resulted in the survival of only one other major distributor in North America  Diamond Comic Distributors Inc  61  62  Then  by the middle of the decade  the industry had slumped  and in December 1996 MEG filed for Chapter 11 bankruptcy protection  49  In early 1997  when Marvel s Heroes World endeavor failed  Diamond also forged an exclusive deal with Marvel 63  giving the company its own section of its comics catalog Previews  64 ', 'In 1996, Marvel had some of its titles participate in \"Heroes Reborn\", a crossover that allowed Marvel to relaunch some of its flagship characters such as the Avengers and the Fantastic Four, and outsource them to the studios of two of the former Marvel artists turned Image Comics founders, Jim Lee and Rob Liefeld. The relaunched titles, which saw the characters transported to a parallel universe with a history distinct from the mainstream Marvel Universe, were a solid success amidst a generally struggling industry, but Marvel discontinued the experiment after a one-year run and returned the characters to the Marvel Universe proper.', 'In 1996  Marvel had some of its titles participate in  Heroes Reborn   a crossover that allowed Marvel to relaunch some of its flagship characters such as the Avengers and the Fantastic Four  and outsource them to the studios of two of the former Marvel artists turned Image Comics founders  Jim Lee and Rob Liefeld  The relaunched titles  which saw the characters transported to a parallel universe with a history distinct from the mainstream Marvel Universe  were a solid success amidst a generally struggling industry  65  but Marvel discontinued the experiment after a one year run and returned the characters to the Marvel Universe proper ', 'In 1997, Toy Biz bought Marvel Entertainment Group to end the bankruptcy, forming a new corporation, Marvel Enterprises. With his business partner Avi Arad, publisher Bill Jemas, and editor-in-chief Bob Harras, Toy Biz co-owner Isaac Perlmutter helped stabilize the comics line.', 'In 1997  Toy Biz bought Marvel Entertainment Group to end the bankruptcy  forming a new corporation  Marvel Enterprises  49  With his business partner Avi Arad  publisher Bill Jemas  and editor in chief Bob Harras  Toy Biz co owner Isaac Perlmutter helped stabilize the comics line  66 ', 'In 1998, the company launched the imprint Marvel Knights, taking place just outside Marvel continuity with better production qualtity. The imprint was helmed by soon-to-become editor-in-chief Joe Quesada; it featured tough, gritty stories showcasing such characters as the Daredevil, Inhumans and Black Panther.', 'In 1998  the company launched the imprint Marvel Knights  taking place just outside Marvel continuity with better production qualtity  The imprint was helmed by soon to become editor in chief Joe Quesada  it featured tough  gritty stories showcasing such characters as the Daredevil  67  Inhumans and Black Panther ', 'With the new millennium, Marvel Comics emerged from bankruptcy and again began diversifying its offerings. In 2001, Marvel withdrew from the Comics Code Authority and established its own Marvel Rating System for comics. The first title from this era to not have the code was X-Force #119 (October 2001). Marvel also created new imprints, such as MAX (an explicit-content line) and Marvel Adventures (developed for child audiences). In addition, the company created an alternate universe imprint, Ultimate Marvel, that allowed the company to reboot its major titles by revising and updating its characters to introduce to a new generation.', 'With the new millennium  Marvel Comics emerged from bankruptcy and again began diversifying its offerings  In 2001  Marvel withdrew from the Comics Code Authority and established its own Marvel Rating System for comics  The first title from this era to not have the code was X Force  119  October 2001   Marvel also created new imprints  such as MAX  an explicit content line  and Marvel Adventures  developed for child audiences   In addition  the company created an alternate universe imprint  Ultimate Marvel  that allowed the company to reboot its major titles by revising and updating its characters to introduce to a new generation ', 'Some of its characters have been turned into successful film franchises, such as the Men in Black movie series, starting in 1997, Blade movie series, starting in 1998, X-Men movie series, starting in 2000, and the highest grossing series Spider-Man, beginning in 2002.', 'Some of its characters have been turned into successful film franchises  such as the Men in Black movie series  starting in 1997  Blade movie series  starting in 1998  X Men movie series  starting in 2000  and the highest grossing series Spider Man  beginning in 2002  68 ', 'In a cross-promotion, the November 1, 2006, episode of the CBS soap opera The Guiding Light, titled \"She\\'s a Marvel\", featured the character Harley Davidson Cooper (played by Beth Ehlers) as a superheroine named the Guiding Light. The character\\'s story continued in an eight-page backup feature, \"A New Light\", that appeared in several Marvel titles published November 1 and 8. Also that year, Marvel created a wiki on its Web site.', 'In a cross promotion  the November 1  2006  episode of the CBS soap opera The Guiding Light  titled  She s a Marvel   featured the character Harley Davidson Cooper  played by Beth Ehlers  as a superheroine named the Guiding Light  69  The character s story continued in an eight page backup feature   A New Light   that appeared in several Marvel titles published November 1 and 8  70  Also that year  Marvel created a wiki on its Web site  71 ', 'In late 2007 the company launched Marvel Digital Comics Unlimited, a digital archive of over 2,500 back issues available for viewing, for a monthly or annual subscription fee.', 'In late 2007 the company launched Marvel Digital Comics Unlimited  a digital archive of over 2 500 back issues available for viewing  for a monthly or annual subscription fee  72 ', 'In 2009 Marvel Comics closed its Open Submissions Policy, in which the company had accepted unsolicited samples from aspiring comic book artists, saying the time-consuming review process had produced no suitably professional work. The same year, the company commemorated its 70th anniversary, dating to its inception as Timely Comics, by issuing the one-shot Marvel Mystery Comics 70th Anniversary Special #1 and a variety of other special issues.', 'In 2009 Marvel Comics closed its Open Submissions Policy  in which the company had accepted unsolicited samples from aspiring comic book artists  saying the time consuming review process had produced no suitably professional work  73  The same year  the company commemorated its 70th anniversary  dating to its inception as Timely Comics  by issuing the one shot Marvel Mystery Comics 70th Anniversary Special  1 and a variety of other special issues  74  75 ', \"On August 31, 2009, The Walt Disney Company announced a deal to acquire Marvel Comics' parent corporation, Marvel Entertainment, for $4 billion or $4.2 billion, with Marvel shareholders to receive $30 and 0.745 Disney shares for each share of Marvel they own. As of 2008, Marvel and its major, longtime competitor DC Comics shared over 80% of the American comic-book market. As of September 2010, Marvel switched its bookstores distribution company from Diamond Book Distributors to Hachette Distribution Services.\", 'On August 31  2009  The Walt Disney Company announced a deal to acquire Marvel Comics  parent corporation  Marvel Entertainment  for  4 billion 76  or  4 2 billion  77  with Marvel shareholders to receive  30 and 0 745 Disney shares for each share of Marvel they own  76  As of 2008  Marvel and its major  longtime competitor DC Comics shared over 80  of the American comic book market  78  As of September 2010  Marvel switched its bookstores distribution company from Diamond Book Distributors to Hachette Distribution Services  79 ', 'Marvel relaunched the CrossGen imprint, owned by Disney Publishing Worldwide, in March 2011. Marvel and Disney Publishing began jointly publishing Disney/Pixar Presents magazine that May.', 'Marvel relaunched the CrossGen imprint  owned by Disney Publishing Worldwide  in March 2011  80  Marvel and Disney Publishing began jointly publishing Disney Pixar Presents magazine that May  81 ', \"Marvel discontinued its Marvel Adventures imprint in March 2012, and replaced them with a line of two titles connected to the Marvel Universe TV block. Also in March, Marvel announced its Marvel ReEvolution initiative that included Infinite Comics, a line of digital comics, Marvel AR, an application software that provides an augmented reality experience to readers and Marvel NOW!, a relaunch of most of the company's major titles with different creative teams. Marvel NOW! also saw the debut of new flagship titles including Uncanny Avengers and All-New X-Men.\", 'Marvel discontinued its Marvel Adventures imprint in March 2012  82  and replaced them with a line of two titles connected to the Marvel Universe TV block  83  Also in March  Marvel announced its Marvel ReEvolution initiative that included Infinite Comics  84  a line of digital comics  Marvel AR  an application software that provides an augmented reality experience to readers and Marvel NOW   a relaunch of most of the company s major titles with different creative teams  85  86  Marvel NOW  also saw the debut of new flagship titles including Uncanny Avengers and All New X Men  87 ', 'In April 2013, Marvel and other Disney conglomerate components began announcing joint projects. With ABC, a Once Upon a Time graphic novel was announced for publication in September. With Disney, Marvel announced in October 2013 that in January 2014 it would release its first title under their joint \"Disney Kingdoms\" imprint \"Seekers of the Weird\", a five-issue miniseries. On January 3, 2014, fellow Disney subsidiary Lucasfilm announced that as of 2015, Star Wars comics would once again be published by Marvel.', 'In April 2013  Marvel and other Disney conglomerate components began announcing joint projects  With ABC  a Once Upon a Time graphic novel was announced for publication in September  88  With Disney  Marvel announced in October 2013 that in January 2014 it would release its first title under their joint  Disney Kingdoms  imprint  Seekers of the Weird   a five issue miniseries  77  On January 3  2014  fellow Disney subsidiary Lucasfilm announced that as of 2015  Star Wars comics would once again be published by Marvel  89 ', 'Following the events of the company-wide crossover \"Secret Wars\" in 2015, a relaunched Marvel universe began in September 2015, called the All-New, All-Different Marvel.', 'Following the events of the company wide crossover  Secret Wars  in 2015  a relaunched Marvel universe began in September 2015  called the All New  All Different Marvel  90 ', \"Marvel Legacy was the company's Fall 2017 relaunch banner starting in September. The banner had comics with lenticular variant covers which required comic book stores to double their regular issue order to be able to order the variants. The owner of two Comix Experience stores complained about the set up of forcing retailers to be stuck with copies they can not sell for the variant that they can sell. With other complaints too, Marvel did adjust down requirements for new titles no adjustment was made for any other. Thus MyComicShop.com and at least 70 other comic book stores were boycotting these variant covers. With a handful of Marvel movies, Guardians of the Galaxy Vol. 2, Logan, Thor: Ragnarok and Spider-Man: Homecoming, in theaters, none of those characters' titles were in the top 10 and even the Guardians of the Galaxy comic book series was canceled. Thus films do not have an impact on comic book sales.\", 'Marvel Legacy was the company s Fall 2017 relaunch banner starting in September  The banner had comics with lenticular variant covers which required comic book stores to double their regular issue order to be able to order the variants  The owner of two Comix Experience stores complained about the set up of forcing retailers to be stuck with copies they can not sell for the variant that they can sell  With other complaints too  Marvel did adjust down requirements for new titles no adjustment was made for any other  Thus MyComicShop com and at least 70 other comic book stores were boycotting these variant covers  91  With a handful of Marvel movies  Guardians of the Galaxy Vol  2  Logan  Thor  Ragnarok and Spider Man  Homecoming  in theaters  none of those characters  titles were in the top 10 and even the Guardians of the Galaxy comic book series was canceled  Thus films do not have an impact on comic book sales  92 ', 'Marvel\\'s chief editor originally held the title of \"editor\". This head editor\\'s title later became \"editor-in-chief\". Joe Simon was the company\\'s first true chief-editor, with publisher Martin Goodman, who had served as titular editor only and outsourced editorial operations.', 'Marvel s chief editor originally held the title of  editor   This head editor s title later became  editor in chief   Joe Simon was the company s first true chief editor  with publisher Martin Goodman  who had served as titular editor only and outsourced editorial operations ', 'In 1994 Marvel briefly abolished the position of editor-in-chief, replacing Tom DeFalco with five group editors-in-chief. As Carl Potts described the 1990s editorial arrangement:', 'In 1994 Marvel briefly abolished the position of editor in chief  replacing Tom DeFalco with five group editors in chief  As Carl Potts described the 1990s editorial arrangement ', \"In the early '90s, Marvel had so many titles that there were three Executive Editors, each overseeing approximately 1/3 of the line. Bob Budiansky was the third Executive Editor [following the previously appointed Mark Gruenwald and Potts]. We all answered to Editor-in-Chief Tom DeFalco and Publisher Mike Hobson. All three Executive Editors decided not to add our names to the already crowded credits on the Marvel titles. Therefore it wasn't easy for readers to tell which titles were produced by which Executive Editor … In late '94, Marvel reorganized into a number of different publishing divisions, each with its own Editor-in-Chief.\", 'In the early  90s  Marvel had so many titles that there were three Executive Editors  each overseeing approximately 1 3 of the line  Bob Budiansky was the third Executive Editor  following the previously appointed Mark Gruenwald and Potts   We all answered to Editor in Chief Tom DeFalco and Publisher Mike Hobson  All three Executive Editors decided not to add our names to the already crowded credits on the Marvel titles  Therefore it wasn t easy for readers to tell which titles were produced by which Executive Editor   In late  94  Marvel reorganized into a number of different publishing divisions  each with its own Editor in Chief  96 ', 'Marvel reinstated the overall editor-in-chief position in 1995 with Bob Harras.', 'Marvel reinstated the overall editor in chief position in 1995 with Bob Harras ', \"Originally called associate editor when Marvel's chief editor just carried the title of editor, the title of the next highest editorial position became executive editor under the chief editor title of editor-in-chief. The title of associate editor later was revived under the editor-in-chief as an editorial position in charge of few titles under the direction of an editor and without an assistant editor.\", 'Originally called associate editor when Marvel s chief editor just carried the title of editor  the title of the next highest editorial position became executive editor under the chief editor title of editor in chief  The title of associate editor later was revived under the editor in chief as an editorial position in charge of few titles under the direction of an editor and without an assistant editor ', 'Located in New York City, Marvel has had successive headquarters:', 'Located in New York City  Marvel has had successive headquarters ', \"For the single month of August 2016, Marvel held a 30.78% share of the comics market, compared to its competitor DC Comics' 39.27% share, which launched its Rebirth promotion that month with all #1 issues. By comparison, the companies respectively held 33.50% and 30.33% shares in 2013, and 40.81% and 29.94% shares in 2008.\", 'For the single month of August 2016  Marvel held a 30 78  share of the comics market  compared to its competitor DC Comics  39 27  share  which launched its Rebirth promotion that month with all  1 issues  104  By comparison  the companies respectively held 33 50  and 30 33  shares in 2013  and 40 81  and 29 94  shares in 2008  105 ', 'Marvel characters and stories have been adapted to many other media. Some of these adaptations were produced by Marvel Comics and its sister company, Marvel Studios, while others were produced by companies licensing Marvel material.', 'Marvel characters and stories have been adapted to many other media  Some of these adaptations were produced by Marvel Comics and its sister company  Marvel Studios  while others were produced by companies licensing Marvel material ', 'In June 1993, Marvel issued its collectable caps for milk caps game under the Hero Caps brand. In 2014, the Marvel Disk Wars: The Avengers Japanese TV series was launched together with a collectible game called Bachicombat, a game similar to the milk caps game, by Bandai.', 'In June 1993  Marvel issued its collectable caps for milk caps game under the Hero Caps brand  106  In 2014  the Marvel Disk Wars  The Avengers Japanese TV series was launched together with a collectible game called Bachicombat  a game similar to the milk caps game  by Bandai  107 ', \"The RPG industry brought the development of the collectible card game (CCG) in the early 1990s which there were soon Marvel characters were featured in CCG of their own starting in 1995 with Fleer's OverPower (1995–1999). Later collectible card game were:\", 'The RPG industry brought the development of the collectible card game  CCG  in the early 1990s which there were soon Marvel characters were featured in CCG of their own starting in 1995 with Fleer s OverPower  1995 1999   Later collectible card game were ', 'TSR published the pen-and-paper role-playing game Marvel Super Heroes in 1984. TSR then released in 1998 the Marvel Super Heroes Adventure Game which used a different system, the card-based SAGA system, than their first game. In 2003 Marvel Publishing published its own role-playing game, the Marvel Universe Roleplaying Game, that used a diceless stone pool system. In August 2011 Margaret Weis Productions announced it was developing a tabletop role-playing game based on the Marvel universe, set for release in February 2012 using its house Cortex Plus RPG system.', 'TSR published the pen and paper role playing game Marvel Super Heroes in 1984  TSR then released in 1998 the Marvel Super Heroes Adventure Game which used a different system  the card based SAGA system  than their first game  In 2003 Marvel Publishing published its own role playing game  the Marvel Universe Roleplaying Game  that used a diceless stone pool system  108  In August 2011 Margaret Weis Productions announced it was developing a tabletop role playing game based on the Marvel universe  set for release in February 2012 using its house Cortex Plus RPG system  109 ', 'Video games based on Marvel characters go back to 1984 and the Atari game, Spider-Man. Since then several dozen video games have been released and all have been produced by outside licensees. In 2014, Disney Infinity 2.0: Marvel Super Heroes was released that brought Marvel characters to the existing Disney sandbox video game.', 'Video games based on Marvel characters go back to 1984 and the Atari game  Spider Man  Since then several dozen video games have been released and all have been produced by outside licensees  In 2014  Disney Infinity 2 0  Marvel Super Heroes was released that brought Marvel characters to the existing Disney sandbox video game ', \"As of the start of September 2015, films based on Marvel's properties represent the highest-grossing U.S. franchise, having grossed over $7.7 billion  as part of a worldwide gross of over $18 billion.\", 'As of the start of September 2015  films based on Marvel s properties represent the highest grossing U S  franchise  having grossed over  7 7 billion  110  as part of a worldwide gross of over  18 billion ', 'Marvel first licensed two prose novels to Bantam Books, who printed The Avengers Battle the Earth Wrecker by Otto Binder (1967) and Captain America: The Great Gold Steal by Ted White (1968). Various publishers took up the licenses from 1978 to 2002. Also, with the various licensed films being released beginning in 1997, various publishers put out movie novelizations. In 2003, following publication of the prose young adult novel Mary Jane, starring Mary Jane Watson from the Spider-Man mythos, Marvel announced the formation of the publishing imprint Marvel Press. However, Marvel moved back to licensing with Pocket Books from 2005 to 2008. With few books issued under the imprint, Marvel and Disney Books Group relaunched Marvel Press in 2011 with the Marvel Origin Storybooks line.', 'Marvel first licensed two prose novels to Bantam Books  who printed The Avengers Battle the Earth Wrecker by Otto Binder  1967  and Captain America  The Great Gold Steal by Ted White  1968   Various publishers took up the licenses from 1978 to 2002  Also  with the various licensed films being released beginning in 1997  various publishers put out movie novelizations  111  In 2003  following publication of the prose young adult novel Mary Jane  starring Mary Jane Watson from the Spider Man mythos  Marvel announced the formation of the publishing imprint Marvel Press  112  However  Marvel moved back to licensing with Pocket Books from 2005 to 2008  111  With few books issued under the imprint  Marvel and Disney Books Group relaunched Marvel Press in 2011 with the Marvel Origin Storybooks line  113 ', 'Many television series, both live-action and animated, have based their productions on Marvel Comics characters. These include series for popular characters such as Spider-Man, Iron Man, the Hulk, the Avengers, the X-Men, Fantastic Four, the Guardians of the Galaxy, Daredevil, Jessica Jones, Luke Cage, Iron Fist, the Punisher, the Defenders, S.H.I.E.L.D., Peggy Carter, Deadpool, Legion, and others. Additionally, a handful of television movies, usually also pilots, based on Marvel Comics characters have been made.', 'Many television series  both live action and animated  have based their productions on Marvel Comics characters  These include series for popular characters such as Spider Man  Iron Man  the Hulk  the Avengers  the X Men  Fantastic Four  the Guardians of the Galaxy  Daredevil  Jessica Jones  Luke Cage  Iron Fist  the Punisher  the Defenders  S H I E L D   Peggy Carter  Deadpool  Legion  and others  Additionally  a handful of television movies  usually also pilots  based on Marvel Comics characters have been made ', \"Marvel has licensed its characters for theme parks and attractions, including Marvel Super Hero Island at Universal Orlando's Islands of Adventure in Orlando, Florida, which includes rides based on their iconic characters and costumed performers, as well as The Amazing Adventures of Spider-Man ride cloned from Islands of Adventure to Universal Studios Japan.\", 'Marvel has licensed its characters for theme parks and attractions  including Marvel Super Hero Island at Universal Orlando s Islands of Adventure 114  in Orlando  Florida  which includes rides based on their iconic characters and costumed performers  as well as The Amazing Adventures of Spider Man ride cloned from Islands of Adventure to Universal Studios Japan  115 ', 'Years after Disney purchased Marvel in late 2009, Walt Disney Parks and Resorts plans on creating original Marvel attractions at their theme parks, with Hong Kong Disneyland becoming the first Disney theme park to feature a Marvel attraction. Due to the licensing agreement with Universal Studios, signed prior to Disney\\'s purchase of Marvel, Walt Disney World and Tokyo Disney are barred from having Marvel characters in their parks. However, this only includes characters Universal is currently using, other characters in their \"families\" (X-Men, Avengers, Fantastic Four, etc.), and the villains associated with said characters. This clause has allowed Walt Disney World to have meet and greets, merchandise, attractions and more with other Marvel characters not associated with the characters at Islands of Adventures, such as Star-Lord and Gamora from Guardians of the Galaxy', 'Years after Disney purchased Marvel in late 2009  Walt Disney Parks and Resorts plans on creating original Marvel attractions at their theme parks  116  117  with Hong Kong Disneyland becoming the first Disney theme park to feature a Marvel attraction  118  119  Due to the licensing agreement with Universal Studios  signed prior to Disney s purchase of Marvel  Walt Disney World and Tokyo Disney are barred from having Marvel characters in their parks  120  However  this only includes characters Universal is currently using  other characters in their  families   X Men  Avengers  Fantastic Four  etc    and the villains associated with said characters  114  This clause has allowed Walt Disney World to have meet and greets  merchandise  attractions and more with other Marvel characters not associated with the characters at Islands of Adventures  such as Star Lord and Gamora from Guardians of the Galaxy 121  122 ', \"Irwin said he never played golf with Goodman, so the story is untrue. I heard this story more than a couple of times while sitting in the lunchroom at DC's 909 Third Avenue and 75 Rockefeller Plaza office as Sol Harrison and [production chief] Jack Adler were schmoozing with some of us … who worked for DC during our college summers.... [T]he way I heard the story from Sol was that Goodman was playing with one of the heads of Independent News, not DC Comics (though DC owned Independent News). … As the distributor of DC Comics, this man certainly knew all the sales figures and was in the best position to tell this tidbit to Goodman. … Of course, Goodman would want to be playing golf with this fellow and be in his good graces. … Sol worked closely with Independent News' top management over the decades and would have gotten this story straight from the horse's mouth.\", 'Irwin said he never played golf with Goodman  so the story is untrue  I heard this story more than a couple of times while sitting in the lunchroom at DC s 909 Third Avenue and 75 Rockefeller Plaza office as Sol Harrison and  production chief  Jack Adler were schmoozing with some of us   who worked for DC during our college summers      T he way I heard the story from Sol was that Goodman was playing with one of the heads of Independent News  not DC Comics  though DC owned Independent News     As the distributor of DC Comics  this man certainly knew all the sales figures and was in the best position to tell this tidbit to Goodman    Of course  Goodman would want to be playing golf with this fellow and be in his good graces    Sol worked closely with Independent News  top management over the decades and would have gotten this story straight from the horse s mouth ', 'Goodman, a publishing trend-follower aware of the JLA\\'s strong sales, confirmably directed his comics editor, Stan Lee, to create a comic-book series about a team of superheroes. According to Lee in Origins of Marvel Comics (Simon and Schuster/Fireside Books, 1974), p. 16: \"Martin mentioned that he had noticed one of the titles published by National Comics seemed to be selling better than most. It was a book called The  [sic] Justice League of America and it was composed of a team of superheroes. … \\' If the Justice League is selling \\', spoke he, \\'why don\\'t we put out a comic book that features a team of superheroes?\\'\"', 'Goodman  a publishing trend follower aware of the JLA s strong sales  confirmably directed his comics editor  Stan Lee  to create a comic book series about a team of superheroes  According to Lee in Origins of Marvel Comics  Simon and Schuster Fireside Books  1974   p  16   Martin mentioned that he had noticed one of the titles published by National Comics seemed to be selling better than most  It was a book called The   sic  Justice League of America and it was composed of a team of superheroes      If the Justice League is selling    spoke he   why don t we put out a comic book that features a team of superheroes   ']\n"
     ]
    }
   ],
   "source": [
    "marvelParagraphs = []\n",
    "for pTag in marvelPTags:\n",
    "    #replace indicators with ''\n",
    "    marvelParagraphs.append(re.sub(r'\\[\\d+\\]','',pTag.text))\n",
    "    #replace punctuations (e.g. #, &) with whitespace\n",
    "    marvelParagraphs.append(re.sub(r'\\W',' ',pTag.text))\n",
    "print(marvelParagraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning text using regex, we are ready to convert this text into pandas `Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        paragraph-text\n",
      "0    Marvel Comics is the common name and primary i...\n",
      "1    Marvel Comics is the common name and primary i...\n",
      "2    Marvel started in 1939 as Timely Publications,...\n",
      "3    Marvel started in 1939 as Timely Publications ...\n",
      "4    Marvel counts among its characters such well-k...\n",
      "5    Marvel counts among its characters such well k...\n",
      "6                                                     \n",
      "7                                                     \n",
      "8                                                     \n",
      "9                                                     \n",
      "10   Pulp-magazine publisher Martin Goodman founded...\n",
      "11   Pulp magazine publisher Martin Goodman founded...\n",
      "12   Timely's first publication, Marvel Comics #1 (...\n",
      "13   Timely s first publication  Marvel Comics  1  ...\n",
      "14   While no other Timely character would achieve ...\n",
      "15   While no other Timely character would achieve ...\n",
      "16   Goodman hired his wife's cousin, Stanley Liebe...\n",
      "17   Goodman hired his wife s cousin  14  Stanley L...\n",
      "18   Goodman's business strategy involved having hi...\n",
      "19   Goodman s business strategy involved having hi...\n",
      "20   The post-war American comic market saw superhe...\n",
      "21   The post war American comic market saw superhe...\n",
      "22   Goodman began using the globe logo of the Atla...\n",
      "23   Goodman began using the globe logo of the Atla...\n",
      "24   Atlas, rather than innovate, took a proven rou...\n",
      "25   Atlas  rather than innovate  took a proven rou...\n",
      "26   The first modern comic books under the Marvel ...\n",
      "27   The first modern comic books under the Marvel ...\n",
      "28   In 1961, writer-editor Stan Lee revolutionized...\n",
      "29   In 1961  writer editor Stan Lee revolutionized...\n",
      "..                                                 ...\n",
      "108  Originally called associate editor when Marvel...\n",
      "109  Originally called associate editor when Marvel...\n",
      "110  Located in New York City, Marvel has had succe...\n",
      "111  Located in New York City  Marvel has had succe...\n",
      "112  For the single month of August 2016, Marvel he...\n",
      "113  For the single month of August 2016  Marvel he...\n",
      "114  Marvel characters and stories have been adapte...\n",
      "115  Marvel characters and stories have been adapte...\n",
      "116  In June 1993, Marvel issued its collectable ca...\n",
      "117  In June 1993  Marvel issued its collectable ca...\n",
      "118  The RPG industry brought the development of th...\n",
      "119  The RPG industry brought the development of th...\n",
      "120  TSR published the pen-and-paper role-playing g...\n",
      "121  TSR published the pen and paper role playing g...\n",
      "122  Video games based on Marvel characters go back...\n",
      "123  Video games based on Marvel characters go back...\n",
      "124  As of the start of September 2015, films based...\n",
      "125  As of the start of September 2015  films based...\n",
      "126  Marvel first licensed two prose novels to Bant...\n",
      "127  Marvel first licensed two prose novels to Bant...\n",
      "128  Many television series, both live-action and a...\n",
      "129  Many television series  both live action and a...\n",
      "130  Marvel has licensed its characters for theme p...\n",
      "131  Marvel has licensed its characters for theme p...\n",
      "132  Years after Disney purchased Marvel in late 20...\n",
      "133  Years after Disney purchased Marvel in late 20...\n",
      "134  Irwin said he never played golf with Goodman, ...\n",
      "135  Irwin said he never played golf with Goodman  ...\n",
      "136  Goodman, a publishing trend-follower aware of ...\n",
      "137  Goodman  a publishing trend follower aware of ...\n",
      "\n",
      "[138 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "marvelParagraphsDF = pandas.DataFrame({'paragraph-text': marvelParagraphs})\n",
    "print(marvelParagraphsDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a `DataFrame` containing all relevant text about Marvel Comics from wikipedia ready to be processed into analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Spidering\n",
    "\n",
    "What if we want to to get a bunch of different pages from wikipedia. We would\n",
    "need to get the url for each of the pages we want. Typically, we want pages that\n",
    "are linked to by other pages and so we will need to parse pages and identify the\n",
    "links. Right now we will be retrieving all links in the body of the content\n",
    "analysis page.\n",
    "\n",
    "To do this we will need to find all the `<a>` (anchor) tags with `href`s\n",
    "(hyperlink references) inside of `<p>` tags. `href` can have many\n",
    "[different](http://stackoverflow.com/questions/4855168/what-is-href-and-why-is-\n",
    "it-used) [forms](https://en.wikipedia.org/wiki/Hyperlink#Hyperlinks_in_HTML) so\n",
    "dealing with them can be tricky, but generally, you will want to extract\n",
    "absolute or relative links. An absolute link is one you can follow without\n",
    "modification, while a relative link requires a base url that you will then\n",
    "append. Wikipedia uses relative urls for its internal links: below is an example\n",
    "for dealing with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://en.wikipedia.org/wiki/Document', 0, 'documents'), ('https://en.wikipedia.org/wiki/Text_(literary_theory)', 1, 'texts'), ('https://en.wikipedia.org/wiki/Semantics', 1, 'meaningful'), ('https://en.wikipedia.org/wiki/Machine_learning', 2, 'Machine learning'), ('https://en.wikipedia.org/wiki/Klaus_Krippendorff', 5, 'Klaus Krippendorff'), ('https://en.wikipedia.org/wiki/Radio', 6, 'radio'), ('https://en.wikipedia.org/wiki/Television', 6, 'television'), ('https://en.wikipedia.org/wiki/Key_Word_in_Context', 6, 'Keyword In Context'), ('https://en.wikipedia.org/wiki/Synonym', 6, 'synonyms'), ('https://en.wikipedia.org/wiki/Homonym', 6, 'homonyms')]\n"
     ]
    }
   ],
   "source": [
    "#wikipedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "otherPAgeURLS = []\n",
    "#We also want to know where the links come from so we also will get:\n",
    "#the paragraph number\n",
    "#the word the link is in\n",
    "for paragraphNum, pTag in enumerate(contentPTags):\n",
    "    #we only want hrefs that link to wiki pages\n",
    "    tagLinks = pTag.findAll('a', href=re.compile('/wiki/'), class_=False)\n",
    "    for aTag in tagLinks:\n",
    "        #We need to extract the url from the <a> tag\n",
    "        relurl = aTag.get('href')\n",
    "        linkText = aTag.text\n",
    "        #wikipedia_base_url is the base we can use the urllib joining function to merge them\n",
    "        #Giving a nice structured tupe like this means we can use tuple expansion later\n",
    "        otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            paragraphNum,\n",
    "            linkText,\n",
    "        ))\n",
    "print(otherPAgeURLS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be adding these new texts to our DataFrame `contentParagraphsDF` so we\n",
    "will need to add 2 more columns to keep track of paragraph numbers and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>paragraph-number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nContent analysis is a research method for st...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Practices and philosophies of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computers are increasingly used in content ana...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Content analysis is best understood as a broad...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The simplest and most objective form of conten...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>More generally, content analysis is research u...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>By having contents of communication available ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Robert Weber notes: \"To make valid inferences ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>There are five types of texts in content analy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Recently, Arash Heydarian Pashakhanlou has arg...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The method of content analysis enables the res...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Since the 1980s, content analysis has become a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The creation of coding frames is intrinsically...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mimetic Convergence aims to show the process o...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Every content analysis should depart from a hy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>As an evaluation approach, content analysis is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Qualitative content analysis is \"a systematic,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       paragraph-text  \\\n",
       "0   \\nContent analysis is a research method for st...   \n",
       "1   Practices and philosophies of content analysis...   \n",
       "2   Computers are increasingly used in content ana...   \n",
       "3                                                       \n",
       "4                                                       \n",
       "5   Content analysis is best understood as a broad...   \n",
       "6   The simplest and most objective form of conten...   \n",
       "7   A further step in analysis is the distinction ...   \n",
       "8   More generally, content analysis is research u...   \n",
       "9   By having contents of communication available ...   \n",
       "10  Robert Weber notes: \"To make valid inferences ...   \n",
       "11  There are five types of texts in content analy...   \n",
       "12  Over the years, content analysis has been appl...   \n",
       "13  In recent times, particularly with the advent ...   \n",
       "14  Quantitative content analysis has enjoyed a re...   \n",
       "15  Recently, Arash Heydarian Pashakhanlou has arg...   \n",
       "16  Content analysis can also be described as stud...   \n",
       "17  The method of content analysis enables the res...   \n",
       "18  Since the 1980s, content analysis has become a...   \n",
       "19  The creation of coding frames is intrinsically...   \n",
       "20  Mimetic Convergence aims to show the process o...   \n",
       "21  Every content analysis should depart from a hy...   \n",
       "22  As an evaluation approach, content analysis is...   \n",
       "23  Qualitative content analysis is \"a systematic,...   \n",
       "24  Holsti groups fifteen uses of content analysis...   \n",
       "25  He also places these uses into the context of ...   \n",
       "26  The following table shows fifteen uses of cont...   \n",
       "27                                                      \n",
       "\n",
       "                                            source  paragraph-number  \n",
       "0   https://en.wikipedia.org/wiki/Content_analysis                 0  \n",
       "1   https://en.wikipedia.org/wiki/Content_analysis                 1  \n",
       "2   https://en.wikipedia.org/wiki/Content_analysis                 2  \n",
       "3   https://en.wikipedia.org/wiki/Content_analysis                 3  \n",
       "4   https://en.wikipedia.org/wiki/Content_analysis                 4  \n",
       "5   https://en.wikipedia.org/wiki/Content_analysis                 5  \n",
       "6   https://en.wikipedia.org/wiki/Content_analysis                 6  \n",
       "7   https://en.wikipedia.org/wiki/Content_analysis                 7  \n",
       "8   https://en.wikipedia.org/wiki/Content_analysis                 8  \n",
       "9   https://en.wikipedia.org/wiki/Content_analysis                 9  \n",
       "10  https://en.wikipedia.org/wiki/Content_analysis                10  \n",
       "11  https://en.wikipedia.org/wiki/Content_analysis                11  \n",
       "12  https://en.wikipedia.org/wiki/Content_analysis                12  \n",
       "13  https://en.wikipedia.org/wiki/Content_analysis                13  \n",
       "14  https://en.wikipedia.org/wiki/Content_analysis                14  \n",
       "15  https://en.wikipedia.org/wiki/Content_analysis                15  \n",
       "16  https://en.wikipedia.org/wiki/Content_analysis                16  \n",
       "17  https://en.wikipedia.org/wiki/Content_analysis                17  \n",
       "18  https://en.wikipedia.org/wiki/Content_analysis                18  \n",
       "19  https://en.wikipedia.org/wiki/Content_analysis                19  \n",
       "20  https://en.wikipedia.org/wiki/Content_analysis                20  \n",
       "21  https://en.wikipedia.org/wiki/Content_analysis                21  \n",
       "22  https://en.wikipedia.org/wiki/Content_analysis                22  \n",
       "23  https://en.wikipedia.org/wiki/Content_analysis                23  \n",
       "24  https://en.wikipedia.org/wiki/Content_analysis                24  \n",
       "25  https://en.wikipedia.org/wiki/Content_analysis                25  \n",
       "26  https://en.wikipedia.org/wiki/Content_analysis                26  \n",
       "27  https://en.wikipedia.org/wiki/Content_analysis                27  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentParagraphsDF['source'] = [wikipedia_content_analysis] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['paragraph-number'] = range(len(contentParagraphsDF['paragraph-text']))\n",
    "\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can add two more columns to our `Dataframe` and define a function to\n",
    "parse\n",
    "each linked page and add its text to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contentParagraphsDF['source-paragraph-number'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "contentParagraphsDF['source-paragraph-text'] = [None] * len(contentParagraphsDF['paragraph-text'])\n",
    "\n",
    "def getTextFromWikiPage(targetURL, sourceParNum, sourceText):\n",
    "    #Make a dict to store data before adding it to the DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : [], 'source-paragraph-number' : [],  'source-paragraph-text' : []}\n",
    "    #Now we get the page\n",
    "    r = requests.get(targetURL)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #enumerating gives use the paragraph number\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #same regex as before\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]', '', pTag.text))\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        parsDict['source'].append(targetURL)\n",
    "        parsDict['source-paragraph-number'].append(sourceParNum)\n",
    "        parsDict['source-paragraph-text'].append(sourceText)\n",
    "    return pandas.DataFrame(parsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run it on our list of link tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-number</th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>source-paragraph-number</th>\n",
       "      <th>source-paragraph-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nContent analysis is a research method for st...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Practices and philosophies of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Computers are increasingly used in content ana...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Content analysis is best understood as a broad...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The simplest and most objective form of conten...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>A further step in analysis is the distinction ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>More generally, content analysis is research u...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>By having contents of communication available ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Robert Weber notes: \"To make valid inferences ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>There are five types of texts in content analy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Over the years, content analysis has been appl...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>In recent times, particularly with the advent ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Quantitative content analysis has enjoyed a re...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Recently, Arash Heydarian Pashakhanlou has arg...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Content analysis can also be described as stud...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>The method of content analysis enables the res...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Since the 1980s, content analysis has become a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>The creation of coding frames is intrinsically...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Mimetic Convergence aims to show the process o...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Every content analysis should depart from a hy...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>As an evaluation approach, content analysis is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Qualitative content analysis is \"a systematic,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Holsti groups fifteen uses of content analysis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>He also places these uses into the context of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>The following table shows fifteen uses of cont...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Content_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>A document is a written, drawn, presented, or ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Document</td>\n",
       "      <td>0</td>\n",
       "      <td>documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6</td>\n",
       "      <td>Relying on literary theory, the notion of text...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Text_(literary_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>texts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>Semantics (from Ancient Greek: σημαντικός sēma...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>In international scientific vocabulary semanti...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>The formal study of semantics intersects with ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>Semantics contrasts with syntax, the study of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>In linguistics, semantics is the subfield that...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7</td>\n",
       "      <td>In the late 1960s, Richard Montague proposed a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>8</td>\n",
       "      <td>Despite its elegance, Montague grammar was lim...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>9</td>\n",
       "      <td>In Chomskyan linguistics there was no mechanis...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10</td>\n",
       "      <td>This view of semantics, as an innate finite me...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11</td>\n",
       "      <td>A concrete example of the latter phenomenon is...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>12</td>\n",
       "      <td>Each of a set of synonyms like redouter ('to d...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>13</td>\n",
       "      <td>and may go back to earlier Indian views on lan...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>14</td>\n",
       "      <td>An attempt to defend a system based on proposi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>15</td>\n",
       "      <td>Another set of concepts related to fuzziness i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>16</td>\n",
       "      <td>Systems of categories are not objectively out ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>17</td>\n",
       "      <td>Originates from Montague's work (see above). A...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>18</td>\n",
       "      <td>Pioneered by the philosopher Donald Davidson, ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>19</td>\n",
       "      <td>This theory is an effort to explain properties...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>20</td>\n",
       "      <td>A linguistic theory that investigates word mea...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>21</td>\n",
       "      <td>Computational semantics is focused on the proc...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22</td>\n",
       "      <td>In computer science, the term semantics refers...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>23</td>\n",
       "      <td>The semantics of programming languages and oth...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>24</td>\n",
       "      <td>For instance, the following statements use dif...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>25</td>\n",
       "      <td>Various ways have been developed to describe t...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>26</td>\n",
       "      <td>The Semantic Web refers to the extension of th...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>27</td>\n",
       "      <td>In psychology, semantic memory is memory for m...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>28</td>\n",
       "      <td>Ideasthesia is a psychological phenomenon in w...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Semantics</td>\n",
       "      <td>1</td>\n",
       "      <td>meaningful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    paragraph-number                                     paragraph-text  \\\n",
       "0                  0  \\nContent analysis is a research method for st...   \n",
       "1                  1  Practices and philosophies of content analysis...   \n",
       "2                  2  Computers are increasingly used in content ana...   \n",
       "3                  3                                                      \n",
       "4                  4                                                      \n",
       "5                  5  Content analysis is best understood as a broad...   \n",
       "6                  6  The simplest and most objective form of conten...   \n",
       "7                  7  A further step in analysis is the distinction ...   \n",
       "8                  8  More generally, content analysis is research u...   \n",
       "9                  9  By having contents of communication available ...   \n",
       "10                10  Robert Weber notes: \"To make valid inferences ...   \n",
       "11                11  There are five types of texts in content analy...   \n",
       "12                12  Over the years, content analysis has been appl...   \n",
       "13                13  In recent times, particularly with the advent ...   \n",
       "14                14  Quantitative content analysis has enjoyed a re...   \n",
       "15                15  Recently, Arash Heydarian Pashakhanlou has arg...   \n",
       "16                16  Content analysis can also be described as stud...   \n",
       "17                17  The method of content analysis enables the res...   \n",
       "18                18  Since the 1980s, content analysis has become a...   \n",
       "19                19  The creation of coding frames is intrinsically...   \n",
       "20                20  Mimetic Convergence aims to show the process o...   \n",
       "21                21  Every content analysis should depart from a hy...   \n",
       "22                22  As an evaluation approach, content analysis is...   \n",
       "23                23  Qualitative content analysis is \"a systematic,...   \n",
       "24                24  Holsti groups fifteen uses of content analysis...   \n",
       "25                25  He also places these uses into the context of ...   \n",
       "26                26  The following table shows fifteen uses of cont...   \n",
       "27                27                                                      \n",
       "28                 0  A document is a written, drawn, presented, or ...   \n",
       "29                 1                                                      \n",
       "..               ...                                                ...   \n",
       "49                 6  Relying on literary theory, the notion of text...   \n",
       "50                 0  Semantics (from Ancient Greek: σημαντικός sēma...   \n",
       "51                 1  In international scientific vocabulary semanti...   \n",
       "52                 2  The formal study of semantics intersects with ...   \n",
       "53                 3  Semantics contrasts with syntax, the study of ...   \n",
       "54                 4                                                      \n",
       "55                 5                                                      \n",
       "56                 6  In linguistics, semantics is the subfield that...   \n",
       "57                 7  In the late 1960s, Richard Montague proposed a...   \n",
       "58                 8  Despite its elegance, Montague grammar was lim...   \n",
       "59                 9  In Chomskyan linguistics there was no mechanis...   \n",
       "60                10  This view of semantics, as an innate finite me...   \n",
       "61                11  A concrete example of the latter phenomenon is...   \n",
       "62                12  Each of a set of synonyms like redouter ('to d...   \n",
       "63                13  and may go back to earlier Indian views on lan...   \n",
       "64                14  An attempt to defend a system based on proposi...   \n",
       "65                15  Another set of concepts related to fuzziness i...   \n",
       "66                16  Systems of categories are not objectively out ...   \n",
       "67                17  Originates from Montague's work (see above). A...   \n",
       "68                18  Pioneered by the philosopher Donald Davidson, ...   \n",
       "69                19  This theory is an effort to explain properties...   \n",
       "70                20  A linguistic theory that investigates word mea...   \n",
       "71                21  Computational semantics is focused on the proc...   \n",
       "72                22  In computer science, the term semantics refers...   \n",
       "73                23  The semantics of programming languages and oth...   \n",
       "74                24  For instance, the following statements use dif...   \n",
       "75                25  Various ways have been developed to describe t...   \n",
       "76                26  The Semantic Web refers to the extension of th...   \n",
       "77                27  In psychology, semantic memory is memory for m...   \n",
       "78                28  Ideasthesia is a psychological phenomenon in w...   \n",
       "\n",
       "                                               source source-paragraph-number  \\\n",
       "0      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "1      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "2      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "3      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "4      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "5      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "6      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "7      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "8      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "9      https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "10     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "11     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "12     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "13     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "14     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "15     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "16     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "17     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "18     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "19     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "20     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "21     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "22     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "23     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "24     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "25     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "26     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "27     https://en.wikipedia.org/wiki/Content_analysis                    None   \n",
       "28             https://en.wikipedia.org/wiki/Document                       0   \n",
       "29             https://en.wikipedia.org/wiki/Document                       0   \n",
       "..                                                ...                     ...   \n",
       "49  https://en.wikipedia.org/wiki/Text_(literary_t...                       1   \n",
       "50            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "51            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "52            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "53            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "54            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "55            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "56            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "57            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "58            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "59            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "60            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "61            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "62            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "63            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "64            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "65            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "66            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "67            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "68            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "69            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "70            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "71            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "72            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "73            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "74            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "75            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "76            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "77            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "78            https://en.wikipedia.org/wiki/Semantics                       1   \n",
       "\n",
       "   source-paragraph-text  \n",
       "0                   None  \n",
       "1                   None  \n",
       "2                   None  \n",
       "3                   None  \n",
       "4                   None  \n",
       "5                   None  \n",
       "6                   None  \n",
       "7                   None  \n",
       "8                   None  \n",
       "9                   None  \n",
       "10                  None  \n",
       "11                  None  \n",
       "12                  None  \n",
       "13                  None  \n",
       "14                  None  \n",
       "15                  None  \n",
       "16                  None  \n",
       "17                  None  \n",
       "18                  None  \n",
       "19                  None  \n",
       "20                  None  \n",
       "21                  None  \n",
       "22                  None  \n",
       "23                  None  \n",
       "24                  None  \n",
       "25                  None  \n",
       "26                  None  \n",
       "27                  None  \n",
       "28             documents  \n",
       "29             documents  \n",
       "..                   ...  \n",
       "49                 texts  \n",
       "50            meaningful  \n",
       "51            meaningful  \n",
       "52            meaningful  \n",
       "53            meaningful  \n",
       "54            meaningful  \n",
       "55            meaningful  \n",
       "56            meaningful  \n",
       "57            meaningful  \n",
       "58            meaningful  \n",
       "59            meaningful  \n",
       "60            meaningful  \n",
       "61            meaningful  \n",
       "62            meaningful  \n",
       "63            meaningful  \n",
       "64            meaningful  \n",
       "65            meaningful  \n",
       "66            meaningful  \n",
       "67            meaningful  \n",
       "68            meaningful  \n",
       "69            meaningful  \n",
       "70            meaningful  \n",
       "71            meaningful  \n",
       "72            meaningful  \n",
       "73            meaningful  \n",
       "74            meaningful  \n",
       "75            meaningful  \n",
       "76            meaningful  \n",
       "77            meaningful  \n",
       "78            meaningful  \n",
       "\n",
       "[79 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for urlTuple in otherPAgeURLS[:3]:\n",
    "    #ignore_index means the indices will not be reset after each append\n",
    "    contentParagraphsDF = contentParagraphsDF.append(getTextFromWikiPage(*urlTuple),ignore_index=True)\n",
    "contentParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">Section 2</span>\n",
    "<span style=\"color:red\">Construct cells immediately below this that spider webcontent from another site with content relating to your anticipated final project. Specifically, identify urls on a core page, then follow and extract content from them into a pandas `Dataframe`. In addition, demonstrate a *recursive* spider, which follows more than one level of links (i.e., follows links from a site, then follows links on followed sites to new sites, etc.), making sure to define a reasonable endpoint so that you do not wander the web forever :-).</span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the Marvel Comics wiki page as the core page, I will identify urls on this page, in order to get contents from other pages that are linked to the core page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('https://en.wikipedia.org/wiki/American_comic_book', 0, 'American comic books'), ('https://en.wikipedia.org/wiki/The_Walt_Disney_Company', 0, 'The Walt Disney Company'), ('https://en.wikipedia.org/wiki/Marvel_Entertainment', 0, 'Marvel Entertainment'), ('https://en.wikipedia.org/wiki/Timely_Comics', 1, 'Timely Publications'), ('https://en.wikipedia.org/wiki/Atlas_Comics_(1950s)', 1, 'Atlas Comics'), ('https://en.wikipedia.org/wiki/Stan_Lee', 1, 'Stan Lee'), ('https://en.wikipedia.org/wiki/Jack_Kirby', 1, 'Jack Kirby'), ('https://en.wikipedia.org/wiki/Steve_Ditko', 1, 'Steve Ditko'), ('https://en.wikipedia.org/wiki/List_of_Marvel_Comics_characters', 2, 'its characters'), ('https://en.wikipedia.org/wiki/Spider-Man', 2, 'Spider-Man')]\n"
     ]
    }
   ],
   "source": [
    "#wikepedia_base_url = 'https://en.wikipedia.org'\n",
    "\n",
    "otherPAgeURLS = []\n",
    "#Also get the paragraph number and the word the link is in\n",
    "for paragraphNum, pTag in enumerate(marvelPTags):\n",
    "    #First, find all <a> tags with hrefs inside <p> tags\n",
    "    #Second, find only hrefs that link to wiki pages using re.compile\n",
    "    tagLinks = pTag.findAll('a',href=re.compile('/wiki/'),class_=False)\n",
    "    for aTag in tagLinks:\n",
    "        #Extract the url from the <a> tag\n",
    "        relurl = aTag.get('href')\n",
    "        linkText = aTag.text\n",
    "        otherPAgeURLS.append((\n",
    "            urllib.parse.urljoin(wikipedia_base_url, relurl),\n",
    "            paragraphNum,\n",
    "            linkText,\n",
    "        ))\n",
    "#Show the first 10 urls\n",
    "print(otherPAgeURLS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function of recursive spider to, which follows 4 levels of links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define a function of recursive spider with 4 levels of links\n",
    "def recursive(reurl,depth = 4):\n",
    "    if depth == 0:\n",
    "        return []\n",
    "        for paragraphNum, pTag in enumerate(marvelPTags):\n",
    "            tagLinks = pTag.findAll('a', href=re.compile('/wiki/'),class_=False)\n",
    "            for aTag in tagLinks:\n",
    "                reurl = aTag.get('href')\n",
    "                returnlist = recursive(reurl,depth = depth - 1)\n",
    "                return returnlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add these new texts to the DataFrame marvelParagraphsDF. To this end, I will add 2 more columns to keep track of paragraph numbers and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph-text</th>\n",
       "      <th>source</th>\n",
       "      <th>paragraph-number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marvel Comics is the common name and primary i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marvel Comics is the common name and primary i...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marvel started in 1939 as Timely Publications,...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marvel started in 1939 as Timely Publications ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marvel counts among its characters such well-k...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Marvel counts among its characters such well k...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pulp-magazine publisher Martin Goodman founded...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pulp magazine publisher Martin Goodman founded...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Timely's first publication, Marvel Comics #1 (...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timely s first publication  Marvel Comics  1  ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>While no other Timely character would achieve ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>While no other Timely character would achieve ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Goodman hired his wife's cousin, Stanley Liebe...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Goodman hired his wife s cousin  14  Stanley L...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Goodman's business strategy involved having hi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Goodman s business strategy involved having hi...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The post-war American comic market saw superhe...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The post war American comic market saw superhe...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Goodman began using the globe logo of the Atla...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Goodman began using the globe logo of the Atla...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Atlas, rather than innovate, took a proven rou...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Atlas  rather than innovate  took a proven rou...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The first modern comic books under the Marvel ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The first modern comic books under the Marvel ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>In 1961, writer-editor Stan Lee revolutionized...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>In 1961  writer editor Stan Lee revolutionized...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Originally called associate editor when Marvel...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Originally called associate editor when Marvel...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Located in New York City, Marvel has had succe...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Located in New York City  Marvel has had succe...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>For the single month of August 2016, Marvel he...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>For the single month of August 2016  Marvel he...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Marvel characters and stories have been adapte...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Marvel characters and stories have been adapte...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>In June 1993, Marvel issued its collectable ca...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>In June 1993  Marvel issued its collectable ca...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>The RPG industry brought the development of th...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>The RPG industry brought the development of th...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>TSR published the pen-and-paper role-playing g...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>TSR published the pen and paper role playing g...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Video games based on Marvel characters go back...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Video games based on Marvel characters go back...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>As of the start of September 2015, films based...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>As of the start of September 2015  films based...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Marvel first licensed two prose novels to Bant...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Marvel first licensed two prose novels to Bant...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Many television series, both live-action and a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Many television series  both live action and a...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Marvel has licensed its characters for theme p...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Marvel has licensed its characters for theme p...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Years after Disney purchased Marvel in late 20...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Years after Disney purchased Marvel in late 20...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Irwin said he never played golf with Goodman, ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Irwin said he never played golf with Goodman  ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Goodman, a publishing trend-follower aware of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Goodman  a publishing trend follower aware of ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Marvel_Comics</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        paragraph-text  \\\n",
       "0    Marvel Comics is the common name and primary i...   \n",
       "1    Marvel Comics is the common name and primary i...   \n",
       "2    Marvel started in 1939 as Timely Publications,...   \n",
       "3    Marvel started in 1939 as Timely Publications ...   \n",
       "4    Marvel counts among its characters such well-k...   \n",
       "5    Marvel counts among its characters such well k...   \n",
       "6                                                        \n",
       "7                                                        \n",
       "8                                                        \n",
       "9                                                        \n",
       "10   Pulp-magazine publisher Martin Goodman founded...   \n",
       "11   Pulp magazine publisher Martin Goodman founded...   \n",
       "12   Timely's first publication, Marvel Comics #1 (...   \n",
       "13   Timely s first publication  Marvel Comics  1  ...   \n",
       "14   While no other Timely character would achieve ...   \n",
       "15   While no other Timely character would achieve ...   \n",
       "16   Goodman hired his wife's cousin, Stanley Liebe...   \n",
       "17   Goodman hired his wife s cousin  14  Stanley L...   \n",
       "18   Goodman's business strategy involved having hi...   \n",
       "19   Goodman s business strategy involved having hi...   \n",
       "20   The post-war American comic market saw superhe...   \n",
       "21   The post war American comic market saw superhe...   \n",
       "22   Goodman began using the globe logo of the Atla...   \n",
       "23   Goodman began using the globe logo of the Atla...   \n",
       "24   Atlas, rather than innovate, took a proven rou...   \n",
       "25   Atlas  rather than innovate  took a proven rou...   \n",
       "26   The first modern comic books under the Marvel ...   \n",
       "27   The first modern comic books under the Marvel ...   \n",
       "28   In 1961, writer-editor Stan Lee revolutionized...   \n",
       "29   In 1961  writer editor Stan Lee revolutionized...   \n",
       "..                                                 ...   \n",
       "108  Originally called associate editor when Marvel...   \n",
       "109  Originally called associate editor when Marvel...   \n",
       "110  Located in New York City, Marvel has had succe...   \n",
       "111  Located in New York City  Marvel has had succe...   \n",
       "112  For the single month of August 2016, Marvel he...   \n",
       "113  For the single month of August 2016  Marvel he...   \n",
       "114  Marvel characters and stories have been adapte...   \n",
       "115  Marvel characters and stories have been adapte...   \n",
       "116  In June 1993, Marvel issued its collectable ca...   \n",
       "117  In June 1993  Marvel issued its collectable ca...   \n",
       "118  The RPG industry brought the development of th...   \n",
       "119  The RPG industry brought the development of th...   \n",
       "120  TSR published the pen-and-paper role-playing g...   \n",
       "121  TSR published the pen and paper role playing g...   \n",
       "122  Video games based on Marvel characters go back...   \n",
       "123  Video games based on Marvel characters go back...   \n",
       "124  As of the start of September 2015, films based...   \n",
       "125  As of the start of September 2015  films based...   \n",
       "126  Marvel first licensed two prose novels to Bant...   \n",
       "127  Marvel first licensed two prose novels to Bant...   \n",
       "128  Many television series, both live-action and a...   \n",
       "129  Many television series  both live action and a...   \n",
       "130  Marvel has licensed its characters for theme p...   \n",
       "131  Marvel has licensed its characters for theme p...   \n",
       "132  Years after Disney purchased Marvel in late 20...   \n",
       "133  Years after Disney purchased Marvel in late 20...   \n",
       "134  Irwin said he never played golf with Goodman, ...   \n",
       "135  Irwin said he never played golf with Goodman  ...   \n",
       "136  Goodman, a publishing trend-follower aware of ...   \n",
       "137  Goodman  a publishing trend follower aware of ...   \n",
       "\n",
       "                                          source  paragraph-number  \n",
       "0    https://en.wikipedia.org/wiki/Marvel_Comics                 0  \n",
       "1    https://en.wikipedia.org/wiki/Marvel_Comics                 1  \n",
       "2    https://en.wikipedia.org/wiki/Marvel_Comics                 2  \n",
       "3    https://en.wikipedia.org/wiki/Marvel_Comics                 3  \n",
       "4    https://en.wikipedia.org/wiki/Marvel_Comics                 4  \n",
       "5    https://en.wikipedia.org/wiki/Marvel_Comics                 5  \n",
       "6    https://en.wikipedia.org/wiki/Marvel_Comics                 6  \n",
       "7    https://en.wikipedia.org/wiki/Marvel_Comics                 7  \n",
       "8    https://en.wikipedia.org/wiki/Marvel_Comics                 8  \n",
       "9    https://en.wikipedia.org/wiki/Marvel_Comics                 9  \n",
       "10   https://en.wikipedia.org/wiki/Marvel_Comics                10  \n",
       "11   https://en.wikipedia.org/wiki/Marvel_Comics                11  \n",
       "12   https://en.wikipedia.org/wiki/Marvel_Comics                12  \n",
       "13   https://en.wikipedia.org/wiki/Marvel_Comics                13  \n",
       "14   https://en.wikipedia.org/wiki/Marvel_Comics                14  \n",
       "15   https://en.wikipedia.org/wiki/Marvel_Comics                15  \n",
       "16   https://en.wikipedia.org/wiki/Marvel_Comics                16  \n",
       "17   https://en.wikipedia.org/wiki/Marvel_Comics                17  \n",
       "18   https://en.wikipedia.org/wiki/Marvel_Comics                18  \n",
       "19   https://en.wikipedia.org/wiki/Marvel_Comics                19  \n",
       "20   https://en.wikipedia.org/wiki/Marvel_Comics                20  \n",
       "21   https://en.wikipedia.org/wiki/Marvel_Comics                21  \n",
       "22   https://en.wikipedia.org/wiki/Marvel_Comics                22  \n",
       "23   https://en.wikipedia.org/wiki/Marvel_Comics                23  \n",
       "24   https://en.wikipedia.org/wiki/Marvel_Comics                24  \n",
       "25   https://en.wikipedia.org/wiki/Marvel_Comics                25  \n",
       "26   https://en.wikipedia.org/wiki/Marvel_Comics                26  \n",
       "27   https://en.wikipedia.org/wiki/Marvel_Comics                27  \n",
       "28   https://en.wikipedia.org/wiki/Marvel_Comics                28  \n",
       "29   https://en.wikipedia.org/wiki/Marvel_Comics                29  \n",
       "..                                           ...               ...  \n",
       "108  https://en.wikipedia.org/wiki/Marvel_Comics               108  \n",
       "109  https://en.wikipedia.org/wiki/Marvel_Comics               109  \n",
       "110  https://en.wikipedia.org/wiki/Marvel_Comics               110  \n",
       "111  https://en.wikipedia.org/wiki/Marvel_Comics               111  \n",
       "112  https://en.wikipedia.org/wiki/Marvel_Comics               112  \n",
       "113  https://en.wikipedia.org/wiki/Marvel_Comics               113  \n",
       "114  https://en.wikipedia.org/wiki/Marvel_Comics               114  \n",
       "115  https://en.wikipedia.org/wiki/Marvel_Comics               115  \n",
       "116  https://en.wikipedia.org/wiki/Marvel_Comics               116  \n",
       "117  https://en.wikipedia.org/wiki/Marvel_Comics               117  \n",
       "118  https://en.wikipedia.org/wiki/Marvel_Comics               118  \n",
       "119  https://en.wikipedia.org/wiki/Marvel_Comics               119  \n",
       "120  https://en.wikipedia.org/wiki/Marvel_Comics               120  \n",
       "121  https://en.wikipedia.org/wiki/Marvel_Comics               121  \n",
       "122  https://en.wikipedia.org/wiki/Marvel_Comics               122  \n",
       "123  https://en.wikipedia.org/wiki/Marvel_Comics               123  \n",
       "124  https://en.wikipedia.org/wiki/Marvel_Comics               124  \n",
       "125  https://en.wikipedia.org/wiki/Marvel_Comics               125  \n",
       "126  https://en.wikipedia.org/wiki/Marvel_Comics               126  \n",
       "127  https://en.wikipedia.org/wiki/Marvel_Comics               127  \n",
       "128  https://en.wikipedia.org/wiki/Marvel_Comics               128  \n",
       "129  https://en.wikipedia.org/wiki/Marvel_Comics               129  \n",
       "130  https://en.wikipedia.org/wiki/Marvel_Comics               130  \n",
       "131  https://en.wikipedia.org/wiki/Marvel_Comics               131  \n",
       "132  https://en.wikipedia.org/wiki/Marvel_Comics               132  \n",
       "133  https://en.wikipedia.org/wiki/Marvel_Comics               133  \n",
       "134  https://en.wikipedia.org/wiki/Marvel_Comics               134  \n",
       "135  https://en.wikipedia.org/wiki/Marvel_Comics               135  \n",
       "136  https://en.wikipedia.org/wiki/Marvel_Comics               136  \n",
       "137  https://en.wikipedia.org/wiki/Marvel_Comics               137  \n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add column named as 'source' and 'paragraph-number'. Then define them.\n",
    "marvelParagraphsDF['source'] = [wikipedia_marvel_comics] * len(marvelParagraphsDF['paragraph-text'])\n",
    "marvelParagraphsDF['paragraph-number'] = range(len(marvelParagraphsDF['paragraph-text']))\n",
    "\n",
    "marvelParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will add two more columns to my `DataFrame` and define a function to parse each linked page and add its text to the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'returnlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1ab03eda4cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0murlTuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreturnlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mmarvelParagraphsDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarvelParagraphsDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetTextFromWikiPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0murlTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmarvelParagraphsDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'returnlist' is not defined"
     ]
    }
   ],
   "source": [
    "#Add two more columns to the Dataframe and define\n",
    "marvelParagraphsDF['source-paragraph-number'] = [None] * len(marvelParagraphsDF['paragraph-text'])\n",
    "marvelParagraphsDF['source-paragraph-text'] = [None] * len(marvelParagraphsDF['paragraph-text'])\n",
    "\n",
    "#Define a function to parse each linked page and add it to the Dataframe\n",
    "def getTextFromWikiPage(targetURL, sourceParNum, sourceText):\n",
    "    #Create a dict to store data before adding to the DataFrame\n",
    "    parsDict = {'source' : [], 'paragraph-number' : [], 'paragraph-text' : [], 'source-paragraph-number' : [], 'source-paragraph-text' : []}\n",
    "    #Use requests.get to get the page we want\n",
    "    r = requests.get(targetURL)\n",
    "    #Use BeautifulSoup to make it better parsing\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    #enumerating gives use the paragraph number (?)\n",
    "    #count the paragraph number?\n",
    "    for parNum, pTag in enumerate(soup.body.findAll('p')):\n",
    "        #same regex as before, replace indicators with ''\n",
    "        #append pTag.text to the column 'paragraph-text'\n",
    "        parsDict['paragraph-text'].append(re.sub(r'\\[\\d+\\]','',pTag.text))\n",
    "        #append parNum to the column 'paragraph-number'\n",
    "        parsDict['paragraph-number'].append(parNum)\n",
    "        #append targetURL to the column 'source'\n",
    "        parsDict['source'].append(targetURL)\n",
    "        #append sourceParNum to the column 'source-paragraph-number'\n",
    "        parsDict['source-paragraph-number'].append(sourceParNum)\n",
    "        #append sourceText to the column 'source-paragraph-text'\n",
    "        parsDict['source-paragraph-text'].append(sourceText)\n",
    "    return pandas.DataFrame(parsDict)\n",
    "\n",
    "for urlTuple in returnlist:\n",
    "    marvelParagraphsDF = marvelParagraphsDF.append(getTextFromWikiPage(*urlTuple),ignore_index=True)\n",
    "marvelParagraphsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API (Tumblr)\n",
    "\n",
    "Generally website owners do not like you scraping their sites. If done badly,\n",
    "scarping can act like a DOS attack so you should be careful how often you make\n",
    "calls to a site. Some sites want automated tools to access their data, so they\n",
    "create [application programming interface\n",
    "(APIs)](https://en.wikipedia.org/wiki/Application_programming_interface). An API\n",
    "specifies a procedure for an application (or script) to access their data. Often\n",
    "this is though a [representational state transfer\n",
    "(REST)](https://en.wikipedia.org/wiki/Representational_state_transfer) web\n",
    "service, which just means if you make correctly formatted HTTP requests they\n",
    "will return nicely formatted data.\n",
    "\n",
    "A nice example for us to study is [Tumblr](https://www.tumblr.com), they have a\n",
    "[simple RESTful API](https://www.tumblr.com/docs/en/api/v1) that allows you to\n",
    "read posts without any complicated html parsing.\n",
    "\n",
    "We can get the first 20 posts from a blog by making an http GET request to\n",
    "`'http://{blog}.tumblr.com/api/read/json'`, were `{blog}` is the name of the\n",
    "target blog. Lets try and get the posts from [http://lolcats-lol-\n",
    "cat.tumblr.com/](http://lolcats-lol-cat.tumblr.com/) (Note the blog says at the\n",
    "top 'One hour one pic lolcats', but the canonical name that Tumblr uses is in\n",
    "the URL 'lolcats-lol-cat')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var tumblr_api_read = {\"tumblelog\":{\"title\":\"One hour one pic lolcats\",\"description\":\"\",\"name\":\"lolcats-lol-cat\",\"timezone\":\"Europe\\/Paris\",\"cname\":false,\"feeds\":[]},\"posts-start\":0,\"posts-total\":2964,\"posts-type\":false,\"posts\":[{\"id\":\"169306612050\",\"url\":\"http:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/169306612050\",\"url-with-slug\":\"http:\\/\\/lolcats-lol-cat.tumblr.com\\/post\\/169306612050\\/kitty-mind-blown\",\"type\":\"photo\",\"date-gmt\":\"2018-01-04 15:00:13 GMT\",\"date\":\"Thu, 04 Jan 2018 16:00:13\",\"bookmarklet\":0,\"mobile\":0,\"feed-item\":\"\",\"from-feed-id\":0,\"unix-timestamp\":1515078013,\"format\":\"html\",\"reblog-key\":\"TZzKhxon\",\"slug\":\"kitty-mind-blown\",\"is-submission\":false,\"like-button\":\"<div class=\\\"like_button\\\" data-post-id=\\\"169306612050\\\" data-blog-name=\\\"lolcats-lol-cat\\\" id=\\\"like_button_169306612050\\\"><iframe id=\\\"like_iframe_169306612050\\\" src=\\\"http:\\/\\/assets.tumblr.com\\/assets\\/html\\/like_iframe.html?_v=fc298e85f978b8662a643fe0a6b8c638#name=lolcats-lol-cat&amp;post_id=169306612050&amp;co\n"
     ]
    }
   ],
   "source": [
    "tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'))\n",
    "\n",
    "print(r.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might not look very good on first inspection, but it has far fewer angle\n",
    "braces than html, which makes it easier to parse. What we have is\n",
    "[JSON](https://en.wikipedia.org/wiki/JSON) a 'human readable' text based data\n",
    "transmission format based on javascript. Luckily, we can readily convert it to a\n",
    "python `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tumblelog', 'posts-start', 'posts-total', 'posts-type', 'posts'])\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#We need to load only the stuff between the curly braces\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "print(d.keys())\n",
    "print(len(d['posts']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we read the [API specification](https://www.tumblr.com/docs/en/api/v1), we\n",
    "will see there are a lot of things we can get if we add things to our GET\n",
    "request. First we can retrieve posts by their id number. Let's first get post\n",
    "`146020177084`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(tumblrAPItarget.format('lolcats-lol-cat'), params = {'id' : 146020177084})\n",
    "d = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "d['posts'][0].keys()\n",
    "d['posts'][0]['photo-url-1280']\n",
    "\n",
    "with open('lolcat.gif', 'wb') as f:\n",
    "    gifRequest = requests.get(d['posts'][0]['photo-url-1280'], stream = True)\n",
    "    f.write(gifRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='lolcat.gif'>\n",
    "\n",
    "Such beauty; such vigor (If you can't see it you have to refresh the page). Now\n",
    "we could retrieve the text from all posts as well\n",
    "as related metadata, like the post date, caption or tags. We could also get\n",
    "links to all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>photo-type</th>\n",
       "      <th>photo-url</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu, 04 Jan 2018 16:00:13</td>\n",
       "      <td>169306612050</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/704a681944a94a1fac1...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thu, 04 Jan 2018 14:00:41</td>\n",
       "      <td>169303827051</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/1ec2cc33b059d657351...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thu, 04 Jan 2018 12:00:34</td>\n",
       "      <td>169301536211</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/80dc7c42c35a2dbce58...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, 02 Jan 2018 04:00:09</td>\n",
       "      <td>169209300706</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/94b8dbe91683bd01551...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue, 02 Jan 2018 02:00:42</td>\n",
       "      <td>169205268941</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/e3bbb26992ac10e0234...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun, 31 Dec 2017 08:00:10</td>\n",
       "      <td>169141076975</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/5ef1ee635831085377d...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sun, 31 Dec 2017 06:00:35</td>\n",
       "      <td>169137806653</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/9dc91b972231d1e6250...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sun, 31 Dec 2017 04:00:38</td>\n",
       "      <td>169134323015</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/f62a86855bb0ed8bf1e...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sun, 31 Dec 2017 02:00:42</td>\n",
       "      <td>169130694997</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/760cd9b9017708c90d5...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sun, 24 Dec 2017 08:00:08</td>\n",
       "      <td>168883132580</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/c078fc21432061a41ec...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sun, 24 Dec 2017 06:00:08</td>\n",
       "      <td>168880019803</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/4c15fa80a9693e21cd2...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sun, 24 Dec 2017 04:00:37</td>\n",
       "      <td>168876801090</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/41e768a2598ceff3589...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sun, 24 Dec 2017 02:00:46</td>\n",
       "      <td>168873615432</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/be75972f1c67a08a617...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wed, 20 Dec 2017 16:00:18</td>\n",
       "      <td>168752469243</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/00f9975dfb0fefcc17f...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wed, 20 Dec 2017 14:00:31</td>\n",
       "      <td>168749896972</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/8210828c1144bff07d0...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wed, 20 Dec 2017 12:00:37</td>\n",
       "      <td>168747789963</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/263e3e9a5416485ce12...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wed, 20 Dec 2017 10:00:30</td>\n",
       "      <td>168745836988</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/7da179e266179512629...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wed, 20 Dec 2017 08:00:27</td>\n",
       "      <td>168743505623</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/452a57d8576fa652d4b...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wed, 20 Dec 2017 06:00:25</td>\n",
       "      <td>168740395058</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/a5e6c94f65fb71e75b4...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wed, 20 Dec 2017 04:00:27</td>\n",
       "      <td>168736855161</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/ffac83e4af480b33c91...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Thu, 14 Dec 2017 08:00:17</td>\n",
       "      <td>168529363372</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/79fb3620a0fcc58b945...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Thu, 14 Dec 2017 06:00:10</td>\n",
       "      <td>168526308691</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/031b538d73b86cd7d2e...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Thu, 14 Dec 2017 04:00:13</td>\n",
       "      <td>168522893885</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/0da9dfd02dfe53c865e...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Thu, 14 Dec 2017 02:00:15</td>\n",
       "      <td>168519442371</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/62dc277cc5b667833eb...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sat, 09 Dec 2017 20:00:23</td>\n",
       "      <td>168364451223</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/50ab257f3405612a14a...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sat, 09 Dec 2017 18:00:24</td>\n",
       "      <td>168361168241</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/f88052384b7580650e6...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sat, 09 Dec 2017 16:00:39</td>\n",
       "      <td>168358136361</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/bf923d1a4b17f98439b...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sat, 09 Dec 2017 14:00:19</td>\n",
       "      <td>168355590755</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/49c3f5ba6ba4e479a74...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sat, 09 Dec 2017 12:00:17</td>\n",
       "      <td>168353555383</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/f842d7761f5c117e672...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sat, 09 Dec 2017 10:00:13</td>\n",
       "      <td>168351653830</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/43d75634d94069c7137...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sat, 09 Dec 2017 08:00:11</td>\n",
       "      <td>168349411113</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/d025e5c20c1988cc0ce...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sat, 09 Dec 2017 06:00:11</td>\n",
       "      <td>168346531295</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/555af6d416083a47906...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mon, 04 Dec 2017 22:00:40</td>\n",
       "      <td>168195598603</td>\n",
       "      <td>gif</td>\n",
       "      <td>http://78.media.tumblr.com/25e88dde076cbc1c970...</td>\n",
       "      <td>[gif, lolcat, lolcats, cat, funny, 90s, vaporw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sun, 03 Dec 2017 20:00:23</td>\n",
       "      <td>168155503393</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/497bf2459417cff68ed...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Sun, 03 Dec 2017 18:00:31</td>\n",
       "      <td>168151885936</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/183183694ee7c69f83e...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Fri, 01 Dec 2017 10:00:34</td>\n",
       "      <td>168073544580</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/504f0f2a046c5f50788...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Fri, 01 Dec 2017 08:00:32</td>\n",
       "      <td>168071375123</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/a2f9da10bba1d62da49...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Fri, 01 Dec 2017 04:00:33</td>\n",
       "      <td>168065028458</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/6a4266d994e5fdc443f...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Thu, 30 Nov 2017 18:00:39</td>\n",
       "      <td>168048588399</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/dcd00e008f3b004ff7e...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Thu, 30 Nov 2017 02:00:20</td>\n",
       "      <td>168027714962</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/41114219abdabd67401...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Wed, 29 Nov 2017 22:00:52</td>\n",
       "      <td>168020830712</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/b93757bd30a75d72194...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Wed, 29 Nov 2017 20:00:41</td>\n",
       "      <td>168017539355</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/15c96d570c09534f110...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Wed, 29 Nov 2017 18:00:44</td>\n",
       "      <td>168014439902</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/8b322c4b6c082e10b92...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Wed, 29 Nov 2017 10:00:33</td>\n",
       "      <td>168005156728</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/de3485e2b6a476f6c14...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Wed, 29 Nov 2017 08:00:31</td>\n",
       "      <td>168002971885</td>\n",
       "      <td>png</td>\n",
       "      <td>http://78.media.tumblr.com/127ec0a380edc6a927e...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Tue, 28 Nov 2017 08:00:11</td>\n",
       "      <td>167968422430</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/0ff6d016269ffe480e2...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Mon, 27 Nov 2017 22:00:46</td>\n",
       "      <td>167951611533</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/260a690dd41167d5cfb...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mon, 27 Nov 2017 18:00:41</td>\n",
       "      <td>167945064894</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/182f0314ab24b11c0df...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Mon, 27 Nov 2017 06:00:24</td>\n",
       "      <td>167930309171</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/f29fe0a3b656b808200...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sun, 26 Nov 2017 12:00:26</td>\n",
       "      <td>167900284395</td>\n",
       "      <td>jpg</td>\n",
       "      <td>http://78.media.tumblr.com/3ed49d55ba8dcec08f0...</td>\n",
       "      <td>[cat, cats, lol, lolcat, lolcats]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date            id photo-type  \\\n",
       "0   Thu, 04 Jan 2018 16:00:13  169306612050        jpg   \n",
       "1   Thu, 04 Jan 2018 14:00:41  169303827051        png   \n",
       "2   Thu, 04 Jan 2018 12:00:34  169301536211        png   \n",
       "3   Tue, 02 Jan 2018 04:00:09  169209300706        jpg   \n",
       "4   Tue, 02 Jan 2018 02:00:42  169205268941        jpg   \n",
       "5   Sun, 31 Dec 2017 08:00:10  169141076975        png   \n",
       "6   Sun, 31 Dec 2017 06:00:35  169137806653        jpg   \n",
       "7   Sun, 31 Dec 2017 04:00:38  169134323015        png   \n",
       "8   Sun, 31 Dec 2017 02:00:42  169130694997        jpg   \n",
       "9   Sun, 24 Dec 2017 08:00:08  168883132580        jpg   \n",
       "10  Sun, 24 Dec 2017 06:00:08  168880019803        jpg   \n",
       "11  Sun, 24 Dec 2017 04:00:37  168876801090        jpg   \n",
       "12  Sun, 24 Dec 2017 02:00:46  168873615432        jpg   \n",
       "13  Wed, 20 Dec 2017 16:00:18  168752469243        jpg   \n",
       "14  Wed, 20 Dec 2017 14:00:31  168749896972        jpg   \n",
       "15  Wed, 20 Dec 2017 12:00:37  168747789963        jpg   \n",
       "16  Wed, 20 Dec 2017 10:00:30  168745836988        jpg   \n",
       "17  Wed, 20 Dec 2017 08:00:27  168743505623        jpg   \n",
       "18  Wed, 20 Dec 2017 06:00:25  168740395058        jpg   \n",
       "19  Wed, 20 Dec 2017 04:00:27  168736855161        jpg   \n",
       "20  Thu, 14 Dec 2017 08:00:17  168529363372        jpg   \n",
       "21  Thu, 14 Dec 2017 06:00:10  168526308691        jpg   \n",
       "22  Thu, 14 Dec 2017 04:00:13  168522893885        jpg   \n",
       "23  Thu, 14 Dec 2017 02:00:15  168519442371        jpg   \n",
       "24  Sat, 09 Dec 2017 20:00:23  168364451223        jpg   \n",
       "25  Sat, 09 Dec 2017 18:00:24  168361168241        png   \n",
       "26  Sat, 09 Dec 2017 16:00:39  168358136361        jpg   \n",
       "27  Sat, 09 Dec 2017 14:00:19  168355590755        jpg   \n",
       "28  Sat, 09 Dec 2017 12:00:17  168353555383        jpg   \n",
       "29  Sat, 09 Dec 2017 10:00:13  168351653830        jpg   \n",
       "30  Sat, 09 Dec 2017 08:00:11  168349411113        jpg   \n",
       "31  Sat, 09 Dec 2017 06:00:11  168346531295        jpg   \n",
       "32  Mon, 04 Dec 2017 22:00:40  168195598603        gif   \n",
       "33  Sun, 03 Dec 2017 20:00:23  168155503393        jpg   \n",
       "34  Sun, 03 Dec 2017 18:00:31  168151885936        png   \n",
       "35  Fri, 01 Dec 2017 10:00:34  168073544580        jpg   \n",
       "36  Fri, 01 Dec 2017 08:00:32  168071375123        jpg   \n",
       "37  Fri, 01 Dec 2017 04:00:33  168065028458        jpg   \n",
       "38  Thu, 30 Nov 2017 18:00:39  168048588399        jpg   \n",
       "39  Thu, 30 Nov 2017 02:00:20  168027714962        jpg   \n",
       "40  Wed, 29 Nov 2017 22:00:52  168020830712        jpg   \n",
       "41  Wed, 29 Nov 2017 20:00:41  168017539355        jpg   \n",
       "42  Wed, 29 Nov 2017 18:00:44  168014439902        jpg   \n",
       "43  Wed, 29 Nov 2017 10:00:33  168005156728        jpg   \n",
       "44  Wed, 29 Nov 2017 08:00:31  168002971885        png   \n",
       "45  Tue, 28 Nov 2017 08:00:11  167968422430        jpg   \n",
       "46  Mon, 27 Nov 2017 22:00:46  167951611533        jpg   \n",
       "47  Mon, 27 Nov 2017 18:00:41  167945064894        jpg   \n",
       "48  Mon, 27 Nov 2017 06:00:24  167930309171        jpg   \n",
       "49  Sun, 26 Nov 2017 12:00:26  167900284395        jpg   \n",
       "\n",
       "                                            photo-url  \\\n",
       "0   http://78.media.tumblr.com/704a681944a94a1fac1...   \n",
       "1   http://78.media.tumblr.com/1ec2cc33b059d657351...   \n",
       "2   http://78.media.tumblr.com/80dc7c42c35a2dbce58...   \n",
       "3   http://78.media.tumblr.com/94b8dbe91683bd01551...   \n",
       "4   http://78.media.tumblr.com/e3bbb26992ac10e0234...   \n",
       "5   http://78.media.tumblr.com/5ef1ee635831085377d...   \n",
       "6   http://78.media.tumblr.com/9dc91b972231d1e6250...   \n",
       "7   http://78.media.tumblr.com/f62a86855bb0ed8bf1e...   \n",
       "8   http://78.media.tumblr.com/760cd9b9017708c90d5...   \n",
       "9   http://78.media.tumblr.com/c078fc21432061a41ec...   \n",
       "10  http://78.media.tumblr.com/4c15fa80a9693e21cd2...   \n",
       "11  http://78.media.tumblr.com/41e768a2598ceff3589...   \n",
       "12  http://78.media.tumblr.com/be75972f1c67a08a617...   \n",
       "13  http://78.media.tumblr.com/00f9975dfb0fefcc17f...   \n",
       "14  http://78.media.tumblr.com/8210828c1144bff07d0...   \n",
       "15  http://78.media.tumblr.com/263e3e9a5416485ce12...   \n",
       "16  http://78.media.tumblr.com/7da179e266179512629...   \n",
       "17  http://78.media.tumblr.com/452a57d8576fa652d4b...   \n",
       "18  http://78.media.tumblr.com/a5e6c94f65fb71e75b4...   \n",
       "19  http://78.media.tumblr.com/ffac83e4af480b33c91...   \n",
       "20  http://78.media.tumblr.com/79fb3620a0fcc58b945...   \n",
       "21  http://78.media.tumblr.com/031b538d73b86cd7d2e...   \n",
       "22  http://78.media.tumblr.com/0da9dfd02dfe53c865e...   \n",
       "23  http://78.media.tumblr.com/62dc277cc5b667833eb...   \n",
       "24  http://78.media.tumblr.com/50ab257f3405612a14a...   \n",
       "25  http://78.media.tumblr.com/f88052384b7580650e6...   \n",
       "26  http://78.media.tumblr.com/bf923d1a4b17f98439b...   \n",
       "27  http://78.media.tumblr.com/49c3f5ba6ba4e479a74...   \n",
       "28  http://78.media.tumblr.com/f842d7761f5c117e672...   \n",
       "29  http://78.media.tumblr.com/43d75634d94069c7137...   \n",
       "30  http://78.media.tumblr.com/d025e5c20c1988cc0ce...   \n",
       "31  http://78.media.tumblr.com/555af6d416083a47906...   \n",
       "32  http://78.media.tumblr.com/25e88dde076cbc1c970...   \n",
       "33  http://78.media.tumblr.com/497bf2459417cff68ed...   \n",
       "34  http://78.media.tumblr.com/183183694ee7c69f83e...   \n",
       "35  http://78.media.tumblr.com/504f0f2a046c5f50788...   \n",
       "36  http://78.media.tumblr.com/a2f9da10bba1d62da49...   \n",
       "37  http://78.media.tumblr.com/6a4266d994e5fdc443f...   \n",
       "38  http://78.media.tumblr.com/dcd00e008f3b004ff7e...   \n",
       "39  http://78.media.tumblr.com/41114219abdabd67401...   \n",
       "40  http://78.media.tumblr.com/b93757bd30a75d72194...   \n",
       "41  http://78.media.tumblr.com/15c96d570c09534f110...   \n",
       "42  http://78.media.tumblr.com/8b322c4b6c082e10b92...   \n",
       "43  http://78.media.tumblr.com/de3485e2b6a476f6c14...   \n",
       "44  http://78.media.tumblr.com/127ec0a380edc6a927e...   \n",
       "45  http://78.media.tumblr.com/0ff6d016269ffe480e2...   \n",
       "46  http://78.media.tumblr.com/260a690dd41167d5cfb...   \n",
       "47  http://78.media.tumblr.com/182f0314ab24b11c0df...   \n",
       "48  http://78.media.tumblr.com/f29fe0a3b656b808200...   \n",
       "49  http://78.media.tumblr.com/3ed49d55ba8dcec08f0...   \n",
       "\n",
       "                                                 tags  \n",
       "0                   [cat, cats, lol, lolcat, lolcats]  \n",
       "1                   [cat, cats, lol, lolcat, lolcats]  \n",
       "2                   [cat, cats, lol, lolcat, lolcats]  \n",
       "3                   [cat, cats, lol, lolcat, lolcats]  \n",
       "4                   [cat, cats, lol, lolcat, lolcats]  \n",
       "5                   [cat, cats, lol, lolcat, lolcats]  \n",
       "6                   [cat, cats, lol, lolcat, lolcats]  \n",
       "7                   [cat, cats, lol, lolcat, lolcats]  \n",
       "8                   [cat, cats, lol, lolcat, lolcats]  \n",
       "9                   [cat, cats, lol, lolcat, lolcats]  \n",
       "10                  [cat, cats, lol, lolcat, lolcats]  \n",
       "11                  [cat, cats, lol, lolcat, lolcats]  \n",
       "12                  [cat, cats, lol, lolcat, lolcats]  \n",
       "13                  [cat, cats, lol, lolcat, lolcats]  \n",
       "14                  [cat, cats, lol, lolcat, lolcats]  \n",
       "15                  [cat, cats, lol, lolcat, lolcats]  \n",
       "16                  [cat, cats, lol, lolcat, lolcats]  \n",
       "17                  [cat, cats, lol, lolcat, lolcats]  \n",
       "18                  [cat, cats, lol, lolcat, lolcats]  \n",
       "19                  [cat, cats, lol, lolcat, lolcats]  \n",
       "20                  [cat, cats, lol, lolcat, lolcats]  \n",
       "21                  [cat, cats, lol, lolcat, lolcats]  \n",
       "22                  [cat, cats, lol, lolcat, lolcats]  \n",
       "23                  [cat, cats, lol, lolcat, lolcats]  \n",
       "24                  [cat, cats, lol, lolcat, lolcats]  \n",
       "25                  [cat, cats, lol, lolcat, lolcats]  \n",
       "26                  [cat, cats, lol, lolcat, lolcats]  \n",
       "27                  [cat, cats, lol, lolcat, lolcats]  \n",
       "28                  [cat, cats, lol, lolcat, lolcats]  \n",
       "29                  [cat, cats, lol, lolcat, lolcats]  \n",
       "30                  [cat, cats, lol, lolcat, lolcats]  \n",
       "31                  [cat, cats, lol, lolcat, lolcats]  \n",
       "32  [gif, lolcat, lolcats, cat, funny, 90s, vaporw...  \n",
       "33                  [cat, cats, lol, lolcat, lolcats]  \n",
       "34                  [cat, cats, lol, lolcat, lolcats]  \n",
       "35                  [cat, cats, lol, lolcat, lolcats]  \n",
       "36                  [cat, cats, lol, lolcat, lolcats]  \n",
       "37                  [cat, cats, lol, lolcat, lolcats]  \n",
       "38                  [cat, cats, lol, lolcat, lolcats]  \n",
       "39                  [cat, cats, lol, lolcat, lolcats]  \n",
       "40                  [cat, cats, lol, lolcat, lolcats]  \n",
       "41                  [cat, cats, lol, lolcat, lolcats]  \n",
       "42                  [cat, cats, lol, lolcat, lolcats]  \n",
       "43                  [cat, cats, lol, lolcat, lolcats]  \n",
       "44                  [cat, cats, lol, lolcat, lolcats]  \n",
       "45                  [cat, cats, lol, lolcat, lolcats]  \n",
       "46                  [cat, cats, lol, lolcat, lolcats]  \n",
       "47                  [cat, cats, lol, lolcat, lolcats]  \n",
       "48                  [cat, cats, lol, lolcat, lolcats]  \n",
       "49                  [cat, cats, lol, lolcat, lolcats]  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting a max in case the blog has millions of images\n",
    "#The given max will be rounded up to the nearest multiple of 50\n",
    "def tumblrImageScrape(blogName, maxImages = 200):\n",
    "    #Restating this here so the function isn't dependent on any external variables\n",
    "    tumblrAPItarget = 'http://{}.tumblr.com/api/read/json'\n",
    "\n",
    "    #There are a bunch of possible locations for the photo url\n",
    "    possiblePhotoSuffixes = [1280, 500, 400, 250, 100]\n",
    "\n",
    "    #These are the pieces of information we will be gathering,\n",
    "    #at the end we will convert this to a DataFrame.\n",
    "    #There are a few other datums we could gather like the captions\n",
    "    #you can read the Tumblr documentation to learn how to get them\n",
    "    #https://www.tumblr.com/docs/en/api/v1\n",
    "    postsData = {\n",
    "        'id' : [],\n",
    "        'photo-url' : [],\n",
    "        'date' : [],\n",
    "        'tags' : [],\n",
    "        'photo-type' : []\n",
    "    }\n",
    "\n",
    "    #Tumblr limits us to a max of 50 posts per request\n",
    "    for requestNum in range(maxImages // 50):\n",
    "        requestParams = {\n",
    "            'start' : requestNum * 50,\n",
    "            'num' : 50,\n",
    "            'type' : 'photo'\n",
    "        }\n",
    "        r = requests.get(tumblrAPItarget.format(blogName), params = requestParams)\n",
    "        requestDict = json.loads(r.text[len('var tumblr_api_read = '):-2])\n",
    "        for postDict in requestDict['posts']:\n",
    "            #We are dealing with uncleaned data, we can't trust it.\n",
    "            #Specifically, not all posts are guaranteed to have the fields we want\n",
    "            try:\n",
    "                postsData['id'].append(postDict['id'])\n",
    "                postsData['date'].append(postDict['date'])\n",
    "                postsData['tags'].append(postDict['tags'])\n",
    "            except KeyError as e:\n",
    "                raise KeyError(\"Post {} from {} is missing: {}\".format(postDict['id'], blogName, e))\n",
    "\n",
    "            foundSuffix = False\n",
    "            for suffix in possiblePhotoSuffixes:\n",
    "                try:\n",
    "                    photoURL = postDict['photo-url-{}'.format(suffix)]\n",
    "                    postsData['photo-url'].append(photoURL)\n",
    "                    postsData['photo-type'].append(photoURL.split('.')[-1])\n",
    "                    foundSuffix = True\n",
    "                    break\n",
    "                except KeyError:\n",
    "                    pass\n",
    "            if not foundSuffix:\n",
    "                #Make sure your error messages are useful\n",
    "                #You will be one of the users\n",
    "                raise KeyError(\"Post {} from {} is missing a photo url\".format(postDict['id'], blogName))\n",
    "\n",
    "    return pandas.DataFrame(postsData)\n",
    "tumblrImageScrape('lolcats-lol-cat', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the urls of a bunch of images and can run OCR on them to gather\n",
    "compelling meme narratives, accompanied by cats.\n",
    "\n",
    "# Files\n",
    "\n",
    "What if the text we want isn't on a webpage? There are a many other sources of\n",
    "text available, typically organized into *files*.\n",
    "\n",
    "## Raw text (and encoding)\n",
    "\n",
    "The most basic form of storing text is as a _raw text_ document. Source code\n",
    "(`.py`, `.r`, etc) is usually raw text as are text files (`.txt`) and those with\n",
    "many other extension (e.g., .csv, .dat, etc.). Opening an unknown file with a\n",
    "text editor is often a great way of learning what the file is.\n",
    "\n",
    "We can create a text file in python with the `open()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#example_text_file = 'sometextfile.txt'\n",
    "#stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols \\u2421 \\u241B \\u20A0 \\u20A1 \\u20A2 \\u20A3 \\u0D60\\n'\n",
    "stringToWrite = 'A line\\nAnother line\\nA line with a few unusual symbols ␡ ␛ ₠ ₡ ₢ ₣ ൠ\\n'\n",
    "\n",
    "with open(example_text_file, mode = 'w', encoding='utf-8') as f:\n",
    "    f.write(stringToWrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `encoding='utf-8'` argument, which specifies how we map the bits from\n",
    "the file to the glyphs (and whitespace characters like tab (`'\\t'`) or newline\n",
    "(`'\\n'`)) on the screen. When dealing only with latin letters, arabic numerals\n",
    "and the other symbols on America keyboards you usually do not have to worry\n",
    "about encodings as the ones used today are backwards compatible with\n",
    "[ASCII](https://en.wikipedia.org/wiki/ASCII), which gives the binary\n",
    "representation of 128 characters.\n",
    "\n",
    "Some of you, however, will want to use other characters (e.g., Chinese\n",
    "characters). To solve this there is\n",
    "[Unicode](https://en.wikipedia.org/wiki/Unicode) which assigns numbers to\n",
    "symbols, e.g., 041 is `'A'` and 03A3 is `'Σ'` (numbers starting with 0 are\n",
    "hexadecimal). Often non/beyond-ASCII characters are called Unicode characters.\n",
    "Unicode contains 1,114,112 characters, about 10\\% of which have been assigned.\n",
    "Unfortunately there are many ways used to map combinations of bits to Unicode\n",
    "symbols. The ones you are likely to encounter are called by Python _utf-8_,\n",
    "_utf-16_ and _latin-1_. _utf-8_ is the standard for Linux and Mac OS while both\n",
    "_utf-16_ and _latin-1_ are used by windows. If you use the wrong encoding,\n",
    "characters can appear wrong, sometimes change in number or Python could raise an\n",
    "exception. Lets see what happens when we open the file we just created with\n",
    "different encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(example_text_file, encoding='utf-8') as f:\n",
    "    print(\"This is with the correct encoding:\")\n",
    "    print(f.read())\n",
    "\n",
    "with open(example_text_file, encoding='latin-1') as f:\n",
    "    print(\"This is with the wrong encoding:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that with _latin-1_ the unicode characters are mixed up and there are too\n",
    "many of them. You need to keep in mind encoding when obtaining text files.\n",
    "Determining the encoding can sometime involve substantial work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load many text files at once. LEts tart by looking at the Shakespeare files in the `data` directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", and Train.]\n",
      "\n",
      "PUCK\n",
      "  If we shadows have offended,\n",
      "  Think but this,--and all is mended,--\n",
      "  That you have but slumber'd here\n",
      "  While these visions did appear.\n",
      "  And this weak and idle theme,\n",
      "  No more yielding but a dream,\n",
      "  Gentles, do not reprehend;\n",
      "  If you pardon, we will mend.\n",
      "  And, as I am an honest Puck,\n",
      "  If we have unearned luck\n",
      "  Now to 'scape the serpent's tongue,\n",
      "  We will make amends ere long;\n",
      "  Else the Puck a liar call:\n",
      "  So, good night unto you all.\n",
      "  Give me your hands, if we be friends,\n",
      "  And Robin shall restore amends.\n",
      "\n",
      "[Exit.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "End of Project Gutenberg Etext of A Midsummer Night's Dream by Shakespeare\n",
      "PG has multiple editions of William Shakespeare's Complete Works\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/Shakespeare/midsummer_nights_dream.txt') as f:\n",
    "    midsummer = f.read()\n",
    "print(midsummer[-700:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to load all the files in `../data/Shakespeare` we can use a for loop with `scandir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetDir = '../data/Shakespeare' #Change this to your own directory of texts\n",
    "shakespearText = []\n",
    "shakespearFileName = []\n",
    "\n",
    "for file in (file for file in os.scandir(targetDir) if file.is_file() and not file.name.startswith('.')):\n",
    "    with open(file.path) as f:\n",
    "        shakespearText.append(f.read())\n",
    "    shakespearFileName.append(file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can put them all in pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alls_well_that_ends_well.txt</th>\n",
       "      <td>All's Well, that Ends Well\\n\\nActus primus. Sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthonie_and_cleopatra.txt</th>\n",
       "      <td>The Tragedie of Anthonie, and Cleopatra\\n\\nAct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as_you_like_it.txt</th>\n",
       "      <td>AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy_of_errors.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coriolanus.txt</th>\n",
       "      <td>THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cymbeline.txt</th>\n",
       "      <td>The Tragedie of Cymbeline\\n\\nActus Primus. Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamlet.txt</th>\n",
       "      <td>The Tragedie of Hamlet\\n\\nActus Primus. Scoena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>julius_caesar.txt</th>\n",
       "      <td>Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p1.txt</th>\n",
       "      <td>The First Part of Henry the Fourth\\n\\nwith the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_4_p2.txt</th>\n",
       "      <td>KING HENRY IV, SECOND PART\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_5.txt</th>\n",
       "      <td>THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p1.txt</th>\n",
       "      <td>Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p2.txt</th>\n",
       "      <td>The second Part of Henry the Sixt\\n\\nwith the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_6_p3.txt</th>\n",
       "      <td>The third Part of Henry the Sixt\\n\\nwith the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_henry_8.txt</th>\n",
       "      <td>KING HENRY THE EIGHTH\\n\\nby William Shakespear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_john.txt</th>\n",
       "      <td>The life and death of King John\\n\\nActus Primu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_lear.txt</th>\n",
       "      <td>The Tragedie of King Lear\\n\\n\\nActus Primus. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_2.txt</th>\n",
       "      <td>DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king_richard_3.txt</th>\n",
       "      <td>KING RICHARD III\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lovers_complaint.txt</th>\n",
       "      <td>A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loves_labors_lost.txt</th>\n",
       "      <td>LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macbeth.txt</th>\n",
       "      <td>MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>measure_for_measure.txt</th>\n",
       "      <td>MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_of_venice.txt</th>\n",
       "      <td>The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merry_wives_of_windsor.txt</th>\n",
       "      <td>THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>midsummer_nights_dream.txt</th>\n",
       "      <td>A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much_ado_about_nothing.txt</th>\n",
       "      <td>MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>othello.txt</th>\n",
       "      <td>THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passionate_pilgrim.txt</th>\n",
       "      <td>THE PASSIONATE PILGRIM\\n\\nby William Shakespea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pericles_prince_of_tyre.txt</th>\n",
       "      <td>PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phoenix_and_the_turtle.txt</th>\n",
       "      <td>THE PHOENIX AND THE TURTLE\\n\\nby William Shake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rape_of_lucrece.txt</th>\n",
       "      <td>THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romeo_and_juliet.txt</th>\n",
       "      <td>ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonnets.txt</th>\n",
       "      <td>THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taming_of_the_shrew.txt</th>\n",
       "      <td>THE TAMING OF THE SHREW\\n\\nby William Shakespe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tempest.txt</th>\n",
       "      <td>The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timon_of_athens.txt</th>\n",
       "      <td>THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titus_andronicus.txt</th>\n",
       "      <td>The Tragedie of Titus Andronicus\\n\\nActus Prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troilus_and_cressida.txt</th>\n",
       "      <td>THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twelth_night.txt</th>\n",
       "      <td>TWELFTH NIGHT;\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two_gentlemen_of_verona.txt</th>\n",
       "      <td>THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>venus_and_adonis.txt</th>\n",
       "      <td>VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>winters_tale.txt</th>\n",
       "      <td>THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           text\n",
       "alls_well_that_ends_well.txt  All's Well, that Ends Well\\n\\nActus primus. Sc...\n",
       "anthonie_and_cleopatra.txt    The Tragedie of Anthonie, and Cleopatra\\n\\nAct...\n",
       "as_you_like_it.txt            AS YOU LIKE IT\\n\\nby William Shakespeare\\n\\n\\n...\n",
       "comedy_of_errors.txt          DRAMATIS PERSONAE\\n\\nSOLINUS, Duke of Ephesus\\...\n",
       "coriolanus.txt                THE TRAGEDY OF CORIOLANUS\\n\\nby William Shakes...\n",
       "cymbeline.txt                 The Tragedie of Cymbeline\\n\\nActus Primus. Sco...\n",
       "hamlet.txt                    The Tragedie of Hamlet\\n\\nActus Primus. Scoena...\n",
       "julius_caesar.txt             Dramatis Personae\\n\\n  JULIUS CAESAR, Roman st...\n",
       "king_henry_4_p1.txt           The First Part of Henry the Fourth\\n\\nwith the...\n",
       "king_henry_4_p2.txt           KING HENRY IV, SECOND PART\\n\\nby William Shake...\n",
       "king_henry_5.txt              THE LIFE OF KING HENRY THE FIFTH\\n\\nby William...\n",
       "king_henry_6_p1.txt           Dramatis Personae\\n\\nKING HENRY the Sixth\\nDUK...\n",
       "king_henry_6_p2.txt           The second Part of Henry the Sixt\\n\\nwith the ...\n",
       "king_henry_6_p3.txt           The third Part of Henry the Sixt\\n\\nwith the d...\n",
       "king_henry_8.txt              KING HENRY THE EIGHTH\\n\\nby William Shakespear...\n",
       "king_john.txt                 The life and death of King John\\n\\nActus Primu...\n",
       "king_lear.txt                 The Tragedie of King Lear\\n\\n\\nActus Primus. S...\n",
       "king_richard_2.txt            DRAMATIS PERSONAE\\n\\n  KING RICHARD THE SECOND...\n",
       "king_richard_3.txt            KING RICHARD III\\n\\nby William Shakespeare\\n\\n...\n",
       "lovers_complaint.txt          A LOVER'S COMPLAINT\\n\\nby William Shakespeare\\...\n",
       "loves_labors_lost.txt         LOVE'S LABOUR'S LOST\\n\\nby William Shakespeare...\n",
       "macbeth.txt                   MACBETH\\n\\nby William Shakespeare\\n\\n\\n\\n\\nPer...\n",
       "measure_for_measure.txt       MEASURE FOR MEASURE\\n\\nby William Shakespeare\\...\n",
       "merchant_of_venice.txt        The Merchant of Venice\\n\\nActus primus.\\n\\nEnt...\n",
       "merry_wives_of_windsor.txt    THE MERRY WIVES OF WINDSOR\\n\\nby William Shake...\n",
       "midsummer_nights_dream.txt    A MIDSUMMER NIGHT'S DREAM\\n\\nby William Shakes...\n",
       "much_ado_about_nothing.txt    MUCH ADO ABOUT NOTHING\\n\\nby William Shakspere...\n",
       "othello.txt                   THE TRAGEDY OF OTHELLO, MOOR OF VENICE\\n\\nby W...\n",
       "passionate_pilgrim.txt        THE PASSIONATE PILGRIM\\n\\nby William Shakespea...\n",
       "pericles_prince_of_tyre.txt   PERICLES PRINCE OF TYRE\\n\\nby William Shakespe...\n",
       "phoenix_and_the_turtle.txt    THE PHOENIX AND THE TURTLE\\n\\nby William Shake...\n",
       "rape_of_lucrece.txt           THE RAPE OF LUCRECE\\n\\nby William Shakespeare\\...\n",
       "romeo_and_juliet.txt          ROMEO AND JULIET\\n\\nby William Shakespeare\\n\\n...\n",
       "sonnets.txt                   THE SONNETS\\n\\nby William Shakespeare\\n\\n\\n\\n ...\n",
       "taming_of_the_shrew.txt       THE TAMING OF THE SHREW\\n\\nby William Shakespe...\n",
       "tempest.txt                   The Tempest\\n\\nActus primus, Scena prima.\\n\\nA...\n",
       "timon_of_athens.txt           THE LIFE OF TIMON OF ATHENS\\n\\nby William Shak...\n",
       "titus_andronicus.txt          The Tragedie of Titus Andronicus\\n\\nActus Prim...\n",
       "troilus_and_cressida.txt      THE HISTORY OF TROILUS AND CRESSIDA\\n\\nby Will...\n",
       "twelth_night.txt                                           TWELFTH NIGHT;\\n ...\n",
       "two_gentlemen_of_verona.txt   THE TWO GENTLEMEN OF VERONA\\n\\nby William Shak...\n",
       "venus_and_adonis.txt          VENUS AND ADONIS\\n\\nby William Shakespeare\\n\\n...\n",
       "winters_tale.txt              THE WINTER'S TALE\\n\\nby William Shakespeare\\n\\..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespear_df = pandas.DataFrame({'text' : shakespearText}, index = shakespearFileName)\n",
    "shakespear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting your text in a format like this is the first step of most analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF\n",
    "\n",
    "Another common way text will be stored is in a PDF file. First we will download\n",
    "a pdf in Python. To do that lets grab a chapter from\n",
    "_Speech and Language Processing_, chapter 21 is on Information Extraction which\n",
    "seems apt. It is stored as a pdf at [https://web.stanford.edu/~jurafsky/slp3/21.\n",
    "pdf](https://web.stanford.edu/~jurafsky/slp3/21.pdf) although we are downloading\n",
    "from a copy just in case Jurafsky changes their website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.3\n",
      "%���������\n",
      "4 0 obj\n",
      "<< /Length 5 0 R /Filter /FlateDecode >>\n",
      "stream\n",
      "x\u0001�]۶�F�}�W�c����T���\u0017C\u000f�i�\u0019<t\u001f�b\u0001\u000fM�f\n",
      "Tn�\u0006<3_�\u000b",
      "�CDf�\u001d",
      "�J�N�i�\u000f�#�%.;.\u0019���\t?\u000f߄��7�]8������ux��}\u001b޾\u000fm����y��bǾ���\u0010�!\u001c",
      "\u000e���$�Ǯ���C�\u0007�F\u0006�����p�\u000f��5��1��1�P<�{�\u0010$�\u001a�/$�P�\f",
      "s�v��P\u001e",
      "gH?�����Q�~�*�:l��ˇ�m�ǰ��C�l����܊\u0017��E��\u001e",
      "���\u000f!�^�y��\u001am�$�Ý���wۡل׼�6w���ī�K�~؞���r��\u0010~\u001b\u001e",
      "?�ˡkO�;6IH�9{ԡ���\u0000]?�E�E�\u0012�~���.l������+��\u001c",
      "W�\u000e\u0002_�\u000e��\u0002\u0002��C��S�|�~\u0005C��N�3ӛB`8�ޚ\b\u0001j9���AZ�\u0004�\u00110�d�l^�\u000e�����SY\u0012\t�Ƨ��>\u000b",
      "q�ۇ&\n",
      "����.�����0���\u0015�;\u0000��>a8�$\f",
      "w�p��p����ST���\u000b",
      ".\u0000�7��@�\u0012���)�\u0013�&1�|���\u0002\u0004WՃ jOv�G2b�L8I��N�@\u0001\u001e",
      "gǍ�\u0004����\u0019�O�C��������IN@@���\u0002��\u0013}�8��+L����a�\u0005&ү\b�o\u0005\u0013�V(\u0019���0\f",
      "���+5\u001b�\n",
      "S\u001d",
      "fS&��<�2���\u001e",
      "��>l�V��&��=4⇤\u0019=\u001a�W��<�J\u0013Mo�\u001c",
      "���\"����d�C����[vY�|K\u001c",
      "{_ܔ\\��\u0017��%\u0001H�/@'�QA�+D�l��c��L�G�.��\t�̎�V�:f>���Aw\u0010K���o$`D\u0007��\u000b",
      "bE45�\u000b",
      "0\b�\u0015%th6h��\u0005���>*�2vQd\u0010\u0015�+M��Y}�Q���u�[���N�o'b\u0010��/u�.r'Z�\u0017��J�\u0019e8�v\u0013\u000b",
      "��;�\u001d",
      "�{T�\t\f",
      "�����^8�\u0014 \u001a\u0018 l<�E�<���b�����C8\f",
      "j��f��xB>\u0001K\u0010���\u0019��|\u001f\u0004w��f�|?�\u0001s̭\u0018��Y�'�Ip&�\"�\u000b",
      "A���f�?�\b!IYi���U�\"��y;�\u0007��#�\u000b",
      "\u000f�e3)�+B�&���\u001d",
      "�<\bE9I�g�/]\"D��yfC;e����Y^�z ��s'�)/�X�-HY��<ˬ�ݰ\n"
     ]
    }
   ],
   "source": [
    "#information_extraction_pdf = 'https://github.com/KnowledgeLab/content_analysis/raw/data/21.pdf'\n",
    "\n",
    "infoExtractionRequest = requests.get(information_extraction_pdf, stream=True)\n",
    "print(infoExtractionRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It says `'pdf'`, so thats a good sign. The rest though looks like we are having\n",
    "issues with an encoding. The random characters are not caused by our encoding\n",
    "being wrong, however. They are cause by there not being an encoding for those\n",
    "parts at all. PDFs are nominally binary files, meaning there are sections of\n",
    "binary that are specific to pdf and nothing else so you need something that\n",
    "knows about pdf to read them. To do that we will be using\n",
    "[`PyPDF2`](https://github.com/mstamy2/PyPDF2), a PDF processing library for\n",
    "Python 3.\n",
    "\n",
    "\n",
    "Because PDFs are a very complicated file format pdfminer requires a large amount\n",
    "of boilerplate code to extract text, we have written a function that takes in an\n",
    "open PDF file and returns the text so you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readPDF(pdfFile):\n",
    "    #Based on code from http://stackoverflow.com/a/20905381/4955164\n",
    "    #Using utf-8, if there are a bunch of random symbols try changing this\n",
    "    codec = 'utf-8'\n",
    "    rsrcmgr = pdfminer.pdfinterp.PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    layoutParams = pdfminer.layout.LAParams()\n",
    "    device = pdfminer.converter.TextConverter(rsrcmgr, retstr, laparams = layoutParams, codec = codec)\n",
    "    #We need a device and an interpreter\n",
    "    interpreter = pdfminer.pdfinterp.PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = ''\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in pdfminer.pdfpage.PDFPage.get_pages(pdfFile, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    device.close()\n",
    "    returnedString = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return returnedString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to take the response object and convert it into a 'file like'\n",
    "object so that pdfminer can read it. To do this we will use `io`'s `BytesIO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infoExtractionBytes = io.BytesIO(infoExtractionRequest.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can give it to pdfminer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department of  Sociology \n",
      "\n",
      "THE UNIVERSITY OF CHICAGO \n",
      "\n",
      "SOCIOLOGY 40133 \n",
      "\n",
      "Computational Content Analysis \n",
      "\n",
      "Friday 1:00 – 3:50pm \n",
      "Winter 2017-2018 \n",
      "Classroom: Harper Memorial 130       \n",
      "http://chalk.uchicago.edu/ \n",
      "\n",
      " \n",
      "\n",
      "                                                                                           \n",
      "\n",
      "          Office: McGiffert 210 \n",
      "                                                    Tel.: 834-3612; jevans@uchicago.edu \n",
      "                                  Office Hours: Thursday 12:30-2:30pm \n",
      "\n",
      "     \n",
      "\n",
      "        James A. Evans            \n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(readPDF(infoExtractionBytes)[:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can either look at the full text or fiddle with our PDF reader and\n",
    "get more information about individual blocks of text.\n",
    "\n",
    "## Word Docs\n",
    "\n",
    "The other type of document you are likely to encounter is the `.docx`, these are\n",
    "actually a version of [XML](https://en.wikipedia.org/wiki/Office_Open_XML), just\n",
    "like HTML, and like HTML we will use a specialized parser.\n",
    "\n",
    "For this class we will use [`python-docx`](https://python-\n",
    "docx.readthedocs.io/en/latest/) which provides a nice simple interface for\n",
    "reading `.docx` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "#example_docx = 'https://github.com/KnowledgeLab/content_analysis/raw/data/example_doc.docx'\n",
    "\n",
    "r = requests.get(example_docx, stream=True)\n",
    "d = docx.Document(io.BytesIO(r.content))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This procedure uses the `io.BytesIO` class again, since `docx.Document` expects\n",
    "a file. Another way to do it is to save the document to a file and then read it\n",
    "like any other file. If we do this we can either delete the file afterwords, or\n",
    "save it and avoid downloading the following time.\n",
    "\n",
    "This function is useful as a part of many different tasks so it and others like it will be added to the helper package `lucem_illud` so we can use it later without having to retype it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def downloadIfNeeded(targetURL, outputFile, **openkwargs):\n",
    "    if not os.path.isfile(outputFile):\n",
    "        outputDir = os.path.dirname(outputFile)\n",
    "        #This function is a more general os.mkdir()\n",
    "        if len(outputDir) > 0:\n",
    "            os.makedirs(outputDir, exist_ok = True)\n",
    "        r = requests.get(targetURL, stream=True)\n",
    "        #Using a closure like this is generally better than having to\n",
    "        #remember to close the file. There are ways to make this function\n",
    "        #work as a closure too\n",
    "        with open(outputFile, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "    return open(outputFile, **openkwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will download, save and open `outputFile` as `outputFile` or just\n",
    "open it if `outputFile` exists. By default `open()` will open the file as read\n",
    "only text with the local encoding, which may cause issues if its not a text\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is not a zip file\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    d = docx.Document(downloadIfNeeded(example_docx, example_docx_save))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell `open()` to read in binary mode (`'rb'`), this is why we added\n",
    "`**openkwargs`, this allows us to pass any keyword arguments (kwargs) from\n",
    "`downloadIfNeeded` to `open()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      "\n",
      "Accessing the Research Computing Center Resources\n",
      "\n",
      "To connect to the midway compute cluster to access your home directory and the macs60000 storage space, and utilize the HPC resources, you will either use a terminal client (with or without X11 forwarding capabilities) or the Linux remote desktop server software client (Thinlinc) to connect to the midway cluster. To submit jobs, monitor jobs, browse directories or do other computing you will need to connect through either the terminal or remote desktop. Setup and utilization of these clients will be discussed below in the context of your local platform’s architecture.\n",
      "SSH Client Setup & Remote Desktop Server\n"
     ]
    }
   ],
   "source": [
    "d = docx.Document(downloadIfNeeded(example_docx, example_docx_save, mode = 'rb'))\n",
    "for paragraph in d.paragraphs[:7]:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the file with `docx.Document` and not have to wait for it to be\n",
    "downloaded every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <span style=\"color:red\">Section 3</span>\n",
    "<span style=\"color:red\">Construct cells immediately below this that extract and organize textual content from text, PDF or Word into a pandas dataframe.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, I will extract content from the sociological paper named \"A Multiple-Perspectives Construct of the American Global Cities\", which is a pdf document. \n",
    "\n",
    "First of all, I will download it from the original website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%PDF-1.5\n",
      "%����\n",
      "1 0 obj\n",
      "<</Subtype/XML/Type/Metadata/Length 3442>>stream\n",
      "<?xpacket begin=\"﻿\" id=\"W5M0MpCehiHzreSzNTczkc9d\"?>\n",
      "<x:xmpmeta x:xmptk=\"XMP toolkit 2.9.1-13, framework 1.6\" xmlns:x=\"adobe:ns:meta/\">\n",
      "<rdf:RDF xmlns:iX=\"http://ns.adobe.com/iX/1.0/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
      "<rdf:Description pdf:Producer=\"Acrobat Distiller 6.0 (Windows)\" rdf:about=\"uuid:89f116ba-9dd1-4609-9ad6-9c873c0bd267\" xmlns:pdf=\"http://ns.adobe.com/pdf/1.3/\"><pdf:Producer>Acrobat Distiller 6.0 (Windows); modified using iText 4.2.0 by 1T3XT</pdf:Producer></rdf:Description>\n",
      "<rdf:Description rdf:about=\"uuid:89f116ba-9dd1-4609-9ad6-9c873c0bd267\" xap:CreateDate=\"2007-11-27T10:08:41+05:30\" xap:CreatorTool=\"Adobe InDesign CS (3.0)\" xap:MetadataDate=\"2007-11-27T10:22:36Z\" xap:ModifyDate=\"2007-11-27T10:22:36Z\" xmlns:xap=\"http://ns.adobe.com/xap/1.0/\"><xmp:ModifyDate>2018-01-08T17:30:22-08:00</xmp:ModifyDate></rdf:Description>\n",
      "<rdf:Description rdf:about=\"uuid:89f116ba-9dd1-4609-9ad6-9c87\n"
     ]
    }
   ],
   "source": [
    "#globalCity_pdf = 'http://journals.sagepub.com/doi/pdf/10.1177/0042098007085099'\n",
    "\n",
    "globalCityRequest = requests.get(globalCity_pdf, stream=True)\n",
    "print(globalCityRequest.text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that takes in an open PDF file as the input and returns the text as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readPDF(pdfFile):\n",
    "    #Based on code from http://stackoverflow.com/a/20905381/4955164\n",
    "    #Using utf-8, if there are a bunch of random symbols try changing this\n",
    "    codec = 'utf-8'\n",
    "    rsrcmgr = pdfminer.pdfinterp.PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    layoutParams = pdfminer.layout.LAParams()\n",
    "    device = pdfminer.converter.TextConverter(rsrcmgr, retstr, laparams = layoutParams, codec = codec)\n",
    "    #We need a device and an interpreter\n",
    "    interpreter = pdfminer.pdfinterp.PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = ''\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in pdfminer.pdfpage.PDFPage.get_pages(pdfFile, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    device.close()\n",
    "    returnedString = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return returnedString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use io's BytesIO to convert the `returnString` into a readable \"file like\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45(1)  3–28, January 2008 \n",
      "\n",
      "A Multiple-perspectives Construct \n",
      "of the American Global City\n",
      "Herman L. Boschken\n",
      "\n",
      "[Paper first received, December 2005; in final form, February 2007]\n",
      "\n",
      "Abstract\n",
      "\n",
      "The  term ‘global  city’  bestows  an  image  of  an  urban  place  that  is  contemporary, \n",
      "international, multicultural, ‘wired’, cosmopolitan, polarising and having geographically \n",
      "boundless power. Nevertheless, the literature fails to produce a common identity for \n",
      "setting the global city apart empirically and in analysing policy issues related to it. \n",
      "T\n"
     ]
    }
   ],
   "source": [
    "globalCityBytes = io.BytesIO(globalCityRequest.content)\n",
    "print(readPDF(globalCityBytes)[:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can read the text from this pdf document. Before converting it into `DataFrame`, I will convert the text into a list of sentences for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globalCityContent = readPDF(globalCityBytes)\n",
    "#Merge every row into one paragraph, then split it by sentences ('.')\n",
    "globalCitySentences = globalCityContent.replace('\\n','').split('.')\n",
    "#Use 'type' to check the data type of globalCitySentences\n",
    "type(globalCitySentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert this text into pandas `DataFrame` with the column named as 'content'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45(1)  3–28, January 2008 A Multiple-perspecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boschken[Paper first received, December 2005;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nevertheless, the literature fails to produce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This paper argues and tests the proposition t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To do this, it: identiﬁ es seven  global  cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The results identify signiﬁ cant clusters tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Since  Hall’s  brilliant  treatise  (1966),  t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It  bestows  an  image  that  is contemporar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>However, even though the term is often banter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>, 1999;  Soja,  2000,  ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7;  Smith,  2001,  ch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3; Derudder, 2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Confounding a collective understanding of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Likewise, differing  individual  perspective...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Although some Herman  L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Boschken  is  in  the  Department  of  Organ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fax: 530 758 5557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E-mail: boschken_h@cob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sjsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0042-0980 Print/1360-063X  Online © 2008 Urban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1177/0042098007085099\f",
       "4   HERMAN L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BOSCHKENperspectives garner a greater followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The plethora of terminology and disparity in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Even though these competing terms and dispara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Instead, they often present obstacles to pro-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Invoking the  elephant  metaphor,  does  the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How can one tell signiﬁ cant dimensions from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>To address these questions, this paper urges a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>It sees the global city as a reﬂ ection of hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>(2005) U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>cities in the ‘world city network’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Survey Series, Metropolitan Policy  Program, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>February</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Thrift,  N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>(1994)  Globalisation,  regulation, urbanisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>365–381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Timberlake, M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>(2006) A global city hypothesis: an  empirica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>cities, 1990–2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Paper  presented  at  the  World Congress  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>US Army Corps of Engineers (2000) Waterborne c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Waterborne Commerce Statistics Center, New Or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>US Bureau of the Census (1997) Economic census...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>US  Department  of  Commerce, Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>US  Bureau  of  the  Census  (2002)  Census  o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>US Department of Commerce, Washington, DC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>28   HERMAN L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>BOSCHKENUS  Department  of  Transportation,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>Bureau of Transportation Statistics, Washingt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>bts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>gov/publications/airactstats2000/)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Walks, R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>(2001) The social ecology of the post-Fordist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>407–447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content\n",
       "0     45(1)  3–28, January 2008 A Multiple-perspecti...\n",
       "1      Boschken[Paper first received, December 2005;...\n",
       "2      Nevertheless, the literature fails to produce...\n",
       "3      This paper argues and tests the proposition t...\n",
       "4      To do this, it: identiﬁ es seven  global  cit...\n",
       "5      The results identify signiﬁ cant clusters tha...\n",
       "6     Since  Hall’s  brilliant  treatise  (1966),  t...\n",
       "7       It  bestows  an  image  that  is contemporar...\n",
       "8      However, even though the term is often banter...\n",
       "9                             , 1999;  Soja,  2000,  ch\n",
       "10                                7;  Smith,  2001,  ch\n",
       "11                                   3; Derudder, 2006)\n",
       "12    Confounding a collective understanding of the ...\n",
       "13      Likewise, differing  individual  perspective...\n",
       "14                              Although some Herman  L\n",
       "15      Boschken  is  in  the  Department  of  Organ...\n",
       "16                                    Fax: 530 758 5557\n",
       "17                               E-mail: boschken_h@cob\n",
       "18                                                 sjsu\n",
       "19                                                  edu\n",
       "20    0042-0980 Print/1360-063X  Online © 2008 Urban...\n",
       "21                   1177/0042098007085099\n",
       "4   HERMAN L\n",
       "22     BOSCHKENperspectives garner a greater followi...\n",
       "23     The plethora of terminology and disparity in ...\n",
       "24     Even though these competing terms and dispara...\n",
       "25     Instead, they often present obstacles to pro-...\n",
       "26      Invoking the  elephant  metaphor,  does  the...\n",
       "27     How can one tell signiﬁ cant dimensions from ...\n",
       "28    To address these questions, this paper urges a...\n",
       "29     It sees the global city as a reﬂ ection of hi...\n",
       "...                                                 ...\n",
       "978                                                   E\n",
       "979                                            (2005) U\n",
       "980                                                   S\n",
       "981                  cities in the ‘world city network’\n",
       "982    Survey Series, Metropolitan Policy  Program, ...\n",
       "983                                            February\n",
       "984                                          Thrift,  N\n",
       "985     (1994)  Globalisation,  regulation, urbanisa...\n",
       "986                                             365–381\n",
       "987                                       Timberlake, M\n",
       "988                                                   F\n",
       "989    (2006) A global city hypothesis: an  empirica...\n",
       "990                                                   S\n",
       "991                                   cities, 1990–2000\n",
       "992     Paper  presented  at  the  World Congress  o...\n",
       "993   US Army Corps of Engineers (2000) Waterborne c...\n",
       "994    Waterborne Commerce Statistics Center, New Or...\n",
       "995   US Bureau of the Census (1997) Economic census...\n",
       "996        US  Department  of  Commerce, Washington, DC\n",
       "997   US  Bureau  of  the  Census  (2002)  Census  o...\n",
       "998           US Department of Commerce, Washington, DC\n",
       "999                                      \n",
       "28   HERMAN L\n",
       "1000   BOSCHKENUS  Department  of  Transportation,  ...\n",
       "1001   Bureau of Transportation Statistics, Washingt...\n",
       "1002                                                bts\n",
       "1003                 gov/publications/airactstats2000/)\n",
       "1004                                           Walks, R\n",
       "1005   (2001) The social ecology of the post-Fordist...\n",
       "1006                                            407–447\n",
       "1007                                                  \n",
       "\n",
       "\n",
       "[1008 rows x 1 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(globalCitySentences,columns=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the textual content from the paper about global cities in our dataframe, ready for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
